{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "sys.path.append(os.path.abspath('../../'))\n",
    "sys.path.append(os.path.abspath('../../extra_files'))\n",
    "import helper as hp\n",
    "from imageio import imwrite, imread\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "data_path = '/home/aldo/Documents/data-cic/'\n",
    "preprocess_path = data_path + 'preprocess_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training SSD300 trained with mobilenet backbone trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/aldo/Documents/ssd/data_generator/object_detection_2d_data_generator.py:43: UserWarning: 'BeautifulSoup' module is missing. The XML-parser will be unavailable.\n",
      "  warnings.warn(\"'BeautifulSoup' module is missing. The XML-parser will be unavailable.\")\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TerminateOnNaN, CSVLogger, EarlyStopping, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from light_models.keras_ssd300_shufflenetv2_ssdlayers_light_relu6_se_no_shuffle import ssd_300\n",
    "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
    "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
    "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
    "from keras_layers.keras_layer_L2Normalization import L2Normalization\n",
    "\n",
    "from ssd_encoder_decoder.ssd_input_encoder import SSDInputEncoder\n",
    "from ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast\n",
    "\n",
    "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
    "from data_generator.object_detection_2d_geometric_ops import Resize\n",
    "from data_generator.object_detection_2d_photometric_ops import ConvertTo3Channels\n",
    "from data_generator.data_augmentation_chain_original_ssd import SSDDataAugmentation\n",
    "from data_generator.object_detection_2d_misc_utils import apply_inverse_transforms\n",
    "\n",
    "from extra_files.f1_callback import F1_callback as f1_call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters (original SSD300 architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameteres needed for ssd_300() and SSDInputEncoder()\n",
    "\n",
    "img_height = 300 # Height of the model input images\n",
    "img_width = 300 # Width of the model input images\n",
    "img_channels = 3 # Number of color channels of the model input images\n",
    "mean_color = [1., 1., 1.] # The per-channel mean of the images in the dataset. Do not change this value if you're using any of the pre-trained weights.\n",
    "divide_by_stddev = [127.5, 127.5, 127.5]\n",
    "swap_channels = False # The color channel order in the original SSD is BGR, so we'll have the model reverse the color channel order of the input images.\n",
    "n_classes = 1 # Number of positive classes, e.g. 20 for Pascal VOC, 80 for MS COCO\n",
    "scales_pascal = [0.1, 0.2, 0.37, 0.54, 0.71, 0.88, 1.05] # The anchor box scaling factors used in the original SSD300 for the Pascal VOC datasets\n",
    "scales = scales_pascal\n",
    "#scales = [0.07, 0.15, 0.33, 0.51, 0.69, 0.87, 1.05]\n",
    "aspect_ratios = [[1.0, 2.0, 0.5],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5],\n",
    "                 [1.0, 2.0, 0.5]] # The anchor box aspect ratios used in the original SSD300; the order matters\n",
    "two_boxes_for_ar1 = True\n",
    "steps = [16, 30, 60, 100, 150, 300] # The space between two adjacent anchor box center points for each predictor layer.\n",
    "offsets = [0.5, 0.5, 0.5, 0.5, 0.5, 0.5] # The offsets of the first anchor box center points from the top and left borders of the image as a fraction of the step size for each predictor layer.\n",
    "clip_boxes = False # Whether or not to clip the anchor boxes to lie entirely within the image boundaries\n",
    "variances = [0.1, 0.1, 0.2, 0.2] # The variances by which the encoded target coordinates are divided as in the original implementation\n",
    "normalize_coords = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "596,843,577.5 --- 5,384,276\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "run_meta = tf.RunMetadata()\n",
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    K.set_session(sess)\n",
    "    model = ssd_300(image_size=(img_height, img_width, img_channels),\n",
    "                n_classes=n_classes,\n",
    "                input_tensor=tf.placeholder('float32', shape=(1,300,300,3)),\n",
    "                mode='inference',\n",
    "                scale_factor=1.5,\n",
    "                scales=scales,\n",
    "                aspect_ratios_per_layer=aspect_ratios,\n",
    "                two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                steps=steps,\n",
    "                offsets=offsets,\n",
    "                clip_boxes=clip_boxes,\n",
    "                variances=variances,\n",
    "                normalize_coords=normalize_coords,\n",
    "                subtract_mean=mean_color,\n",
    "                divide_by_stddev=divide_by_stddev,\n",
    "                swap_channels=swap_channels)\n",
    "    opts = tf.profiler.ProfileOptionBuilder.float_operation()    \n",
    "    flops = tf.profiler.profile(sess.graph, run_meta=run_meta, cmd='op', options=opts)\n",
    "\n",
    "    opts = tf.profiler.ProfileOptionBuilder.trainable_variables_parameter()    \n",
    "    params = tf.profiler.profile(sess.graph, run_meta=run_meta, cmd='op', options=opts)\n",
    "    \n",
    "# Factor 1.5\n",
    "print(\"{:,} --- {:,}\".format(flops.total_float_ops/2, params.total_parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new model with SSD weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Build the Keras model.\n",
    "\n",
    "K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "model = ssd_300(image_size=(img_height, img_width, img_channels),\n",
    "                n_classes=n_classes,\n",
    "                mode='training',\n",
    "                scale_factor=1.5,\n",
    "                scales=scales,\n",
    "                aspect_ratios_per_layer=aspect_ratios,\n",
    "                two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                steps=steps,\n",
    "                offsets=offsets,\n",
    "                clip_boxes=clip_boxes,\n",
    "                variances=variances,\n",
    "                normalize_coords=normalize_coords,\n",
    "                subtract_mean=mean_color,\n",
    "                divide_by_stddev=divide_by_stddev,\n",
    "                swap_channels=swap_channels)\n",
    "\n",
    "# 3: Instantiate an optimizer and the SSD loss function and compile the model.\n",
    "#    If you want to follow the original Caffe implementation, use the preset SGD\n",
    "#    optimizer, otherwise I'd recommend the commented-out Adam optimizer.\n",
    "\n",
    "adam = Adam(lr=0.001)\n",
    "#sgd = SGD(lr=0.001, momentum=0.9, decay=0.0, nesterov=False)\n",
    "\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "model.compile(optimizer=adam, loss=ssd_loss.compute_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generator for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images into memory: 100%|██████████| 255/255 [00:00<00:00, 370.10it/s]\n",
      "Loading images into memory: 100%|██████████| 45/45 [00:00<00:00, 378.52it/s]\n",
      "Number of images in the training dataset:\t   255\n",
      "Number of images in the validation dataset:\t    45\n"
     ]
    }
   ],
   "source": [
    "# 1: Instantiate two `DataGenerator` objects: One for training, one for validation.\n",
    "\n",
    "# Optional: If you have enough memory, consider loading the images into memory for the reasons explained above.\n",
    "\n",
    "train_dataset = DataGenerator(load_images_into_memory=True, hdf5_dataset_path=None)\n",
    "val_dataset = DataGenerator(load_images_into_memory=True, hdf5_dataset_path=None)\n",
    "\n",
    "# 2: Parse the image and label lists for the training and validation datasets.\n",
    "\n",
    "# TODO: Set the paths to your dataset here.\n",
    "\n",
    "# Images\n",
    "images_dir = data_path + 'images_reduced'\n",
    "\n",
    "# Ground truth\n",
    "# train_labels_filename = preprocess_path + '/cic_train_reduced.csv'\n",
    "train_labels_filename = preprocess_path + '/cic_train_val_reduced.csv'\n",
    "val_labels_filename   = preprocess_path + '/cic_val_reduced.csv'\n",
    "\n",
    "train_dataset.parse_csv(images_dir=images_dir,\n",
    "                        labels_filename=train_labels_filename,\n",
    "                        input_format=['image_name', 'xmin', 'xmax', 'ymin', 'ymax', 'class_id'], # This is the order of the first six columns in the CSV file that contains the labels for your dataset. If your labels are in XML format, maybe the XML parser will be helpful, check the documentation.\n",
    "                        include_classes='all')\n",
    "\n",
    "val_dataset.parse_csv(images_dir=images_dir,\n",
    "                      labels_filename=val_labels_filename,\n",
    "                      input_format=['image_name', 'xmin', 'xmax', 'ymin', 'ymax', 'class_id'],\n",
    "                      include_classes='all')\n",
    "\n",
    "# Get the number of samples in the training and validations datasets.\n",
    "train_dataset_size = train_dataset.get_dataset_size()\n",
    "val_dataset_size   = val_dataset.get_dataset_size()\n",
    "\n",
    "print(\"Number of images in the training dataset:\\t{:>6}\".format(train_dataset_size))\n",
    "print(\"Number of images in the validation dataset:\\t{:>6}\".format(val_dataset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the training dataset:\t   255\n",
      "Number of images in the validation dataset:\t    45\n"
     ]
    }
   ],
   "source": [
    "# 3: Set the batch size.\n",
    "batch_size = 32 # Change the batch size if you like, or if you run into GPU memory issues.\n",
    "\n",
    "# 4: Set the image transformations for pre-processing and data augmentation options.\n",
    "# For the training generator:\n",
    "ssd_data_augmentation = SSDDataAugmentation(img_height=img_height,\n",
    "                                            img_width=img_width,\n",
    "                                            background=mean_color)\n",
    "\n",
    "# For the validation generator:\n",
    "convert_to_3_channels = ConvertTo3Channels()\n",
    "resize = Resize(height=img_height, width=img_width)\n",
    "\n",
    "# 5: Instantiate an encoder that can encode ground truth labels into the format needed by the SSD loss function.\n",
    "# The encoder constructor needs the spatial dimensions of the model's predictor layers to create the anchor boxes.\n",
    "predictor_sizes = [model.get_layer('conv13_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv18_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv19_2_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv20_2_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv21_2_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv22_2_mbox_conf').output_shape[1:3]]\n",
    "\n",
    "ssd_input_encoder = SSDInputEncoder(img_height=img_height,\n",
    "                                    img_width=img_width,\n",
    "                                    n_classes=n_classes,\n",
    "                                    predictor_sizes=predictor_sizes,\n",
    "                                    scales=scales,\n",
    "                                    aspect_ratios_per_layer=aspect_ratios,\n",
    "                                    two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                                    steps=steps,\n",
    "                                    offsets=offsets,\n",
    "                                    clip_boxes=clip_boxes,\n",
    "                                    variances=variances,\n",
    "                                    matching_type='multi',\n",
    "                                    pos_iou_threshold=0.5,\n",
    "                                    neg_iou_limit=0.5,\n",
    "                                    normalize_coords=normalize_coords)\n",
    "\n",
    "# 6: Create the generator handles that will be passed to Keras' `fit_generator()` function.\n",
    "train_generator = train_dataset.generate(batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         transformations=[ssd_data_augmentation],\n",
    "                                         label_encoder=ssd_input_encoder,\n",
    "                                         returns={'processed_images',\n",
    "                                                  'encoded_labels'},\n",
    "                                         keep_images_without_gt=False)\n",
    "\n",
    "val_generator = val_dataset.generate(batch_size=batch_size,\n",
    "                                     shuffle=False,\n",
    "                                     transformations=[convert_to_3_channels,\n",
    "                                                      resize],\n",
    "                                     label_encoder=ssd_input_encoder,\n",
    "                                     returns={'processed_images',\n",
    "                                              'encoded_labels'},\n",
    "                                     keep_images_without_gt=False)\n",
    "\n",
    "# Get the number of samples in the training and validations datasets.\n",
    "train_dataset_size = train_dataset.get_dataset_size()\n",
    "val_dataset_size   = val_dataset.get_dataset_size()\n",
    "\n",
    "print(\"Number of images in the training dataset:\\t{:>6}\".format(train_dataset_size))\n",
    "print(\"Number of images in the validation dataset:\\t{:>6}\".format(val_dataset_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remaining training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a learning rate schedule.\n",
    "def lr_schedule(epoch):\n",
    "    if epoch < 450:\n",
    "        return 0.001\n",
    "    else:\n",
    "        return 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING MODEL WITH LEARNING RATE: 0.01\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 165s 826ms/step - loss: 4.0598 - val_loss: 6.2726\n",
      "Number of images: 1025\n",
      "Presicion: 0.1425\n",
      "Recall: 0.076\n",
      "F1 score: 0.0992\n",
      "F1 score: 0.09915137958112079\n",
      "Improve F1 score from -inf to 0.09915137958112079\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 151s 756ms/step - loss: 3.8709 - val_loss: 4.1463\n",
      "Number of images: 1025\n",
      "Presicion: 0.2077\n",
      "Recall: 0.3728\n",
      "F1 score: 0.2667\n",
      "F1 score: 0.2667306533068654\n",
      "Improve F1 score from 0.09915137958112079 to 0.2667306533068654\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 146s 728ms/step - loss: 3.4698 - val_loss: 3.6220\n",
      "Number of images: 1025\n",
      "Presicion: 0.2997\n",
      "Recall: 0.2776\n",
      "F1 score: 0.2882\n",
      "F1 score: 0.2881887472340263\n",
      "Improve F1 score from 0.2667306533068654 to 0.2881887472340263\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 156s 782ms/step - loss: 3.3254 - val_loss: 3.5332\n",
      "Number of images: 1025\n",
      "Presicion: 0.2613\n",
      "Recall: 0.2873\n",
      "F1 score: 0.2737\n",
      "F1 score: 0.27368490723920336\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 149s 745ms/step - loss: 3.2218 - val_loss: 3.7014\n",
      "Number of images: 1025\n",
      "Presicion: 0.116\n",
      "Recall: 0.1816\n",
      "F1 score: 0.1415\n",
      "F1 score: 0.14154926770291848\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 148s 740ms/step - loss: 3.0580 - val_loss: 3.5423\n",
      "Number of images: 1025\n",
      "Presicion: 0.2208\n",
      "Recall: 0.2227\n",
      "F1 score: 0.2217\n",
      "F1 score: 0.22174135302802633\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 146s 728ms/step - loss: 2.9806 - val_loss: 3.4418\n",
      "Number of images: 1025\n",
      "Presicion: 0.213\n",
      "Recall: 0.2808\n",
      "F1 score: 0.2423\n",
      "F1 score: 0.24226238213200688\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 148s 738ms/step - loss: 2.9235 - val_loss: 3.7469\n",
      "Number of images: 1025\n",
      "Presicion: 0.2063\n",
      "Recall: 0.3323\n",
      "F1 score: 0.2546\n",
      "F1 score: 0.25455717009084494\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 146s 730ms/step - loss: 2.8818 - val_loss: 3.2881\n",
      "Number of images: 1025\n",
      "Presicion: 0.2681\n",
      "Recall: 0.3576\n",
      "F1 score: 0.3065\n",
      "F1 score: 0.30647240951119364\n",
      "Improve F1 score from 0.2881887472340263 to 0.30647240951119364\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 148s 739ms/step - loss: 2.8280 - val_loss: 3.7436\n",
      "Number of images: 1025\n",
      "Presicion: 0.2895\n",
      "Recall: 0.1595\n",
      "F1 score: 0.2057\n",
      "F1 score: 0.2056728088387615\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 148s 738ms/step - loss: 2.7887 - val_loss: 4.0106\n",
      "Number of images: 1025\n",
      "Presicion: 0.2527\n",
      "Recall: 0.1981\n",
      "F1 score: 0.2221\n",
      "F1 score: 0.22211673388111625\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 145s 727ms/step - loss: 2.7041 - val_loss: 3.0718\n",
      "Number of images: 1025\n",
      "Presicion: 0.2838\n",
      "Recall: 0.226\n",
      "F1 score: 0.2516\n",
      "F1 score: 0.2516122135818291\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 144s 721ms/step - loss: 2.6209 - val_loss: 3.3801\n",
      "Number of images: 1025\n",
      "Presicion: 0.2324\n",
      "Recall: 0.2142\n",
      "F1 score: 0.2229\n",
      "F1 score: 0.22293970342448538\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 146s 732ms/step - loss: 3.7681 - val_loss: 6.2282\n",
      "Number of images: 1025\n",
      "Presicion: 0.0813\n",
      "Recall: 0.0581\n",
      "F1 score: 0.0678\n",
      "F1 score: 0.06780433145803724\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 145s 726ms/step - loss: 3.7695 - val_loss: 4.8161\n",
      "Number of images: 1025\n",
      "Presicion: 0.2528\n",
      "Recall: 0.08\n",
      "F1 score: 0.1216\n",
      "F1 score: 0.12158335108776434\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 149s 743ms/step - loss: 3.1752 - val_loss: 5.8053\n",
      "Number of images: 1025\n",
      "Presicion: 0.0657\n",
      "Recall: 0.0362\n",
      "F1 score: 0.0467\n",
      "F1 score: 0.04670658023014672\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 145s 723ms/step - loss: 2.9729 - val_loss: 3.0769\n",
      "Number of images: 1025\n",
      "Presicion: 0.3055\n",
      "Recall: 0.2859\n",
      "F1 score: 0.2954\n",
      "F1 score: 0.29537316654607026\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 147s 736ms/step - loss: 2.8487 - val_loss: 12.0881\n",
      "Number of images: 1025\n",
      "Presicion: 0.1803\n",
      "Recall: 0.0955\n",
      "F1 score: 0.1248\n",
      "F1 score: 0.12483201392250423\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 145s 724ms/step - loss: 2.7401 - val_loss: 3.3599\n",
      "Number of images: 1025\n",
      "Presicion: 0.2818\n",
      "Recall: 0.2473\n",
      "F1 score: 0.2634\n",
      "F1 score: 0.26343309445430674\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 142s 712ms/step - loss: 2.6107 - val_loss: 3.3920\n",
      "Number of images: 1025\n",
      "Presicion: 0.3011\n",
      "Recall: 0.106\n",
      "F1 score: 0.1568\n",
      "F1 score: 0.15677711369500383\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 144s 722ms/step - loss: 2.5251 - val_loss: 3.2294\n",
      "Number of images: 1025\n",
      "Presicion: 0.2973\n",
      "Recall: 0.1918\n",
      "F1 score: 0.2332\n",
      "F1 score: 0.23317343033095383\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 147s 736ms/step - loss: 2.5263 - val_loss: 3.4016\n",
      "Number of images: 1025\n",
      "Presicion: 0.3395\n",
      "Recall: 0.2402\n",
      "F1 score: 0.2814\n",
      "F1 score: 0.2813559288930679\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 147s 735ms/step - loss: 2.5249 - val_loss: 3.0600\n",
      "Number of images: 1025\n",
      "Presicion: 0.2844\n",
      "Recall: 0.2283\n",
      "F1 score: 0.2533\n",
      "F1 score: 0.2532776625407338\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 143s 714ms/step - loss: 2.6066 - val_loss: 3.2839\n",
      "Number of images: 1025\n",
      "Presicion: 0.2175\n",
      "Recall: 0.2526\n",
      "F1 score: 0.2337\n",
      "F1 score: 0.23371160909621722\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 147s 736ms/step - loss: 2.4652 - val_loss: 3.3180\n",
      "Number of images: 1025\n",
      "Presicion: 0.3135\n",
      "Recall: 0.1922\n",
      "F1 score: 0.2383\n",
      "F1 score: 0.2383368267545242\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 144s 720ms/step - loss: 2.6241 - val_loss: 2.9572\n",
      "Number of images: 1025\n",
      "Presicion: 0.4026\n",
      "Recall: 0.2422\n",
      "F1 score: 0.3025\n",
      "F1 score: 0.3024973529786667\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 144s 721ms/step - loss: 2.4285 - val_loss: 3.1906\n",
      "Number of images: 1025\n",
      "Presicion: 0.3052\n",
      "Recall: 0.2903\n",
      "F1 score: 0.2976\n",
      "F1 score: 0.297574054336618\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 148s 740ms/step - loss: 2.3580 - val_loss: 2.9769\n",
      "Number of images: 1025\n",
      "Presicion: 0.2759\n",
      "Recall: 0.3134\n",
      "F1 score: 0.2935\n",
      "F1 score: 0.29345626502208727\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 149s 743ms/step - loss: 2.3461 - val_loss: 3.0453\n",
      "Number of images: 1025\n",
      "Presicion: 0.2185\n",
      "Recall: 0.3421\n",
      "F1 score: 0.2667\n",
      "F1 score: 0.2666685741585048\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 146s 732ms/step - loss: 2.2855 - val_loss: 3.6288\n",
      "Number of images: 1025\n",
      "Presicion: 0.3915\n",
      "Recall: 0.1923\n",
      "F1 score: 0.2579\n",
      "F1 score: 0.2579157387438844\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 146s 730ms/step - loss: 2.2821 - val_loss: 3.0471\n",
      "Number of images: 1025\n",
      "Presicion: 0.2774\n",
      "Recall: 0.3352\n",
      "F1 score: 0.3036\n",
      "F1 score: 0.3035925233579066\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 146s 728ms/step - loss: 2.2338 - val_loss: 3.2060\n",
      "Number of images: 1025\n",
      "Presicion: 0.2809\n",
      "Recall: 0.3037\n",
      "F1 score: 0.2918\n",
      "F1 score: 0.29184596788360934\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 147s 737ms/step - loss: 2.3365 - val_loss: 3.1712\n",
      "Number of images: 1025\n",
      "Presicion: 0.3016\n",
      "Recall: 0.1636\n",
      "F1 score: 0.2121\n",
      "F1 score: 0.2120802540851818\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 146s 728ms/step - loss: 2.2718 - val_loss: 3.3613\n",
      "Number of images: 1025\n",
      "Presicion: 0.3269\n",
      "Recall: 0.2522\n",
      "F1 score: 0.2847\n",
      "F1 score: 0.28469047508819023\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 147s 734ms/step - loss: 2.2596 - val_loss: 3.3196\n",
      "Number of images: 1025\n",
      "Presicion: 0.3714\n",
      "Recall: 0.2673\n",
      "F1 score: 0.3109\n",
      "F1 score: 0.3108613821655196\n",
      "Improve F1 score from 0.30647240951119364 to 0.3108613821655196\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 144s 720ms/step - loss: 2.1500 - val_loss: 3.1656\n",
      "Number of images: 1025\n",
      "Presicion: 0.413\n",
      "Recall: 0.177\n",
      "F1 score: 0.2478\n",
      "F1 score: 0.24783630244668295\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 145s 725ms/step - loss: 2.1949 - val_loss: 3.0260\n",
      "Number of images: 1025\n",
      "Presicion: 0.3692\n",
      "Recall: 0.2852\n",
      "F1 score: 0.3218\n",
      "F1 score: 0.3217922569567033\n",
      "Improve F1 score from 0.3108613821655196 to 0.3217922569567033\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 145s 726ms/step - loss: 2.1666 - val_loss: 3.1055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 1025\n",
      "Presicion: 0.3328\n",
      "Recall: 0.2267\n",
      "F1 score: 0.2697\n",
      "F1 score: 0.2697197296236902\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 146s 729ms/step - loss: 2.1947 - val_loss: 3.2082\n",
      "Number of images: 1025\n",
      "Presicion: 0.3104\n",
      "Recall: 0.3054\n",
      "F1 score: 0.3079\n",
      "F1 score: 0.3078589779510703\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 143s 715ms/step - loss: 2.1443 - val_loss: 2.9373\n",
      "Number of images: 1025\n",
      "Presicion: 0.3213\n",
      "Recall: 0.2483\n",
      "F1 score: 0.2801\n",
      "F1 score: 0.28014212495552815\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 146s 730ms/step - loss: 2.1393 - val_loss: 2.9955\n",
      "Number of images: 1025\n",
      "Presicion: 0.3875\n",
      "Recall: 0.2782\n",
      "F1 score: 0.3239\n",
      "F1 score: 0.3238934167999601\n",
      "Improve F1 score from 0.3217922569567033 to 0.3238934167999601\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 143s 714ms/step - loss: 2.1242 - val_loss: 5.9124\n",
      "Number of images: 1025\n",
      "Presicion: 0.2587\n",
      "Recall: 0.2554\n",
      "F1 score: 0.257\n",
      "F1 score: 0.25704616010144676\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 143s 714ms/step - loss: 2.0762 - val_loss: 2.9622\n",
      "Number of images: 1025\n",
      "Presicion: 0.3574\n",
      "Recall: 0.2615\n",
      "F1 score: 0.302\n",
      "F1 score: 0.3020450404499547\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 146s 728ms/step - loss: 2.0624 - val_loss: 3.3990\n",
      "Number of images: 1025\n",
      "Presicion: 0.3222\n",
      "Recall: 0.1697\n",
      "F1 score: 0.2223\n",
      "F1 score: 0.22231059526288513\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 148s 739ms/step - loss: 2.0883 - val_loss: 4.0798\n",
      "Number of images: 1025\n",
      "Presicion: 0.2306\n",
      "Recall: 0.0282\n",
      "F1 score: 0.0503\n",
      "F1 score: 0.05026762738735866\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 145s 723ms/step - loss: 2.1182 - val_loss: 5.4892\n",
      "Number of images: 1025\n",
      "Presicion: 0.1808\n",
      "Recall: 0.0563\n",
      "F1 score: 0.0858\n",
      "F1 score: 0.08583959263204027\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 145s 725ms/step - loss: 2.0668 - val_loss: 4.1202\n",
      "Number of images: 1025\n",
      "Presicion: 0.3007\n",
      "Recall: 0.1154\n",
      "F1 score: 0.1668\n",
      "F1 score: 0.16675397554083246\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 145s 725ms/step - loss: 2.0448 - val_loss: 3.4181\n",
      "Number of images: 1025\n",
      "Presicion: 0.2897\n",
      "Recall: 0.3216\n",
      "F1 score: 0.3048\n",
      "F1 score: 0.3048262870478096\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 144s 720ms/step - loss: 2.0418 - val_loss: 3.4324\n",
      "Number of images: 1025\n",
      "Presicion: 0.3767\n",
      "Recall: 0.0877\n",
      "F1 score: 0.1423\n",
      "F1 score: 0.1423163068950401\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 144s 722ms/step - loss: 2.0438 - val_loss: 3.0620\n",
      "Number of images: 1025\n",
      "Presicion: 0.4174\n",
      "Recall: 0.178\n",
      "F1 score: 0.2496\n",
      "F1 score: 0.24957651204555356\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 144s 720ms/step - loss: 2.0608 - val_loss: 3.1329\n",
      "Number of images: 1025\n",
      "Presicion: 0.372\n",
      "Recall: 0.2972\n",
      "F1 score: 0.3305\n",
      "F1 score: 0.3304631565915689\n",
      "Improve F1 score from 0.3238934167999601 to 0.3304631565915689\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 146s 728ms/step - loss: 2.0507 - val_loss: 4.5248\n",
      "Number of images: 1025\n",
      "Presicion: 0.3189\n",
      "Recall: 0.1013\n",
      "F1 score: 0.1537\n",
      "F1 score: 0.15373021471173365\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 143s 714ms/step - loss: 2.1494 - val_loss: 3.0175\n",
      "Number of images: 1025\n",
      "Presicion: 0.2699\n",
      "Recall: 0.2774\n",
      "F1 score: 0.2736\n",
      "F1 score: 0.27359949182377324\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 145s 725ms/step - loss: 1.9735 - val_loss: 3.0987\n",
      "Number of images: 1025\n",
      "Presicion: 0.3148\n",
      "Recall: 0.3328\n",
      "F1 score: 0.3236\n",
      "F1 score: 0.32355523673483577\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 144s 718ms/step - loss: 2.2270 - val_loss: 4.6834\n",
      "Number of images: 1025\n",
      "Presicion: 0.3978\n",
      "Recall: 0.098\n",
      "F1 score: 0.1573\n",
      "F1 score: 0.15726313330067057\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 143s 714ms/step - loss: 2.0688 - val_loss: 3.2142\n",
      "Number of images: 1025\n",
      "Presicion: 0.3028\n",
      "Recall: 0.3364\n",
      "F1 score: 0.3187\n",
      "F1 score: 0.3187143357920939\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 143s 713ms/step - loss: 2.0555 - val_loss: 3.7280\n",
      "Number of images: 1025\n",
      "Presicion: 0.4859\n",
      "Recall: 0.1341\n",
      "F1 score: 0.2102\n",
      "F1 score: 0.21020295690518304\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 145s 725ms/step - loss: 1.9875 - val_loss: 2.8811\n",
      "Number of images: 1025\n",
      "Presicion: 0.3996\n",
      "Recall: 0.2307\n",
      "F1 score: 0.2925\n",
      "F1 score: 0.29249996405507817\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 145s 727ms/step - loss: 1.9799 - val_loss: 2.9743\n",
      "Number of images: 1025\n",
      "Presicion: 0.2537\n",
      "Recall: 0.3205\n",
      "F1 score: 0.2832\n",
      "F1 score: 0.2831799819419287\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 142s 712ms/step - loss: 1.9263 - val_loss: 3.5230\n",
      "Number of images: 1025\n",
      "Presicion: 0.4567\n",
      "Recall: 0.1954\n",
      "F1 score: 0.2737\n",
      "F1 score: 0.27370839022763416\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 143s 713ms/step - loss: 1.9204 - val_loss: 2.8908\n",
      "Number of images: 1025\n",
      "Presicion: 0.3889\n",
      "Recall: 0.1811\n",
      "F1 score: 0.2471\n",
      "F1 score: 0.24708045893994263\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 143s 715ms/step - loss: 1.9143 - val_loss: 2.8244\n",
      "Number of images: 1025\n",
      "Presicion: 0.4089\n",
      "Recall: 0.2621\n",
      "F1 score: 0.3194\n",
      "F1 score: 0.31944547563705294\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 145s 727ms/step - loss: 1.9346 - val_loss: 2.9030\n",
      "Number of images: 1025\n",
      "Presicion: 0.3851\n",
      "Recall: 0.1938\n",
      "F1 score: 0.2579\n",
      "F1 score: 0.25788579223729097\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 145s 725ms/step - loss: 1.9150 - val_loss: 2.8138\n",
      "Number of images: 1025\n",
      "Presicion: 0.2714\n",
      "Recall: 0.3256\n",
      "F1 score: 0.296\n",
      "F1 score: 0.29604460337469474\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 145s 724ms/step - loss: 1.8994 - val_loss: 4.4170\n",
      "Number of images: 1025\n",
      "Presicion: 0.2722\n",
      "Recall: 0.1005\n",
      "F1 score: 0.1468\n",
      "F1 score: 0.14679005311255675\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 144s 719ms/step - loss: 1.9000 - val_loss: 2.8043\n",
      "Number of images: 1025\n",
      "Presicion: 0.2666\n",
      "Recall: 0.3037\n",
      "F1 score: 0.2839\n",
      "F1 score: 0.2839303929413449\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 144s 722ms/step - loss: 1.8834 - val_loss: 4.0088\n",
      "Number of images: 1025\n",
      "Presicion: 0.3759\n",
      "Recall: 0.2359\n",
      "F1 score: 0.2899\n",
      "F1 score: 0.28990257462013785\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 143s 717ms/step - loss: 1.8739 - val_loss: 2.9144\n",
      "Number of images: 1025\n",
      "Presicion: 0.3583\n",
      "Recall: 0.3111\n",
      "F1 score: 0.333\n",
      "F1 score: 0.33304748169996107\n",
      "Improve F1 score from 0.3304631565915689 to 0.33304748169996107\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 144s 719ms/step - loss: 1.8746 - val_loss: 2.9838\n",
      "Number of images: 1025\n",
      "Presicion: 0.3639\n",
      "Recall: 0.2196\n",
      "F1 score: 0.2739\n",
      "F1 score: 0.2738857210608684\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 143s 716ms/step - loss: 1.8399 - val_loss: 3.1255\n",
      "Number of images: 1025\n",
      "Presicion: 0.3294\n",
      "Recall: 0.3097\n",
      "F1 score: 0.3192\n",
      "F1 score: 0.31923842214258114\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 143s 716ms/step - loss: 1.8799 - val_loss: 3.2279\n",
      "Number of images: 1025\n",
      "Presicion: 0.3062\n",
      "Recall: 0.3337\n",
      "F1 score: 0.3194\n",
      "F1 score: 0.319372724349934\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 145s 724ms/step - loss: 1.8737 - val_loss: 3.1008\n",
      "Number of images: 1025\n",
      "Presicion: 0.2797\n",
      "Recall: 0.308\n",
      "F1 score: 0.2931\n",
      "F1 score: 0.2931463846826011\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 146s 728ms/step - loss: 1.8796 - val_loss: 3.2645\n",
      "Number of images: 1025\n",
      "Presicion: 0.3267\n",
      "Recall: 0.1682\n",
      "F1 score: 0.222\n",
      "F1 score: 0.22202120743018583\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 147s 736ms/step - loss: 1.8772 - val_loss: 3.6932\n",
      "Number of images: 1025\n",
      "Presicion: 0.3623\n",
      "Recall: 0.2828\n",
      "F1 score: 0.3177\n",
      "F1 score: 0.3176591903399057\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 144s 719ms/step - loss: 1.8724 - val_loss: 2.9232\n",
      "Number of images: 1025\n",
      "Presicion: 0.2593\n",
      "Recall: 0.308\n",
      "F1 score: 0.2815\n",
      "F1 score: 0.2815375691582802\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 141s 706ms/step - loss: 1.8327 - val_loss: 3.1340\n",
      "Number of images: 1025\n",
      "Presicion: 0.3539\n",
      "Recall: 0.3028\n",
      "F1 score: 0.3264\n",
      "F1 score: 0.32637432781881237\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 146s 731ms/step - loss: 1.8041 - val_loss: 2.9809\n",
      "Number of images: 1025\n",
      "Presicion: 0.3321\n",
      "Recall: 0.1928\n",
      "F1 score: 0.2439\n",
      "F1 score: 0.24394121318830037\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 144s 719ms/step - loss: 1.8058 - val_loss: 3.1869\n",
      "Number of images: 1025\n",
      "Presicion: 0.355\n",
      "Recall: 0.2871\n",
      "F1 score: 0.3175\n",
      "F1 score: 0.3174770629953908\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 145s 723ms/step - loss: 1.8462 - val_loss: 2.7196\n",
      "Number of images: 1025\n",
      "Presicion: 0.3802\n",
      "Recall: 0.2343\n",
      "F1 score: 0.2899\n",
      "F1 score: 0.2899325861047995\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 146s 731ms/step - loss: 1.7886 - val_loss: 2.7593\n",
      "Number of images: 1025\n",
      "Presicion: 0.3512\n",
      "Recall: 0.3177\n",
      "F1 score: 0.3336\n",
      "F1 score: 0.3335959065173768\n",
      "Improve F1 score from 0.33304748169996107 to 0.3335959065173768\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 147s 734ms/step - loss: 1.8182 - val_loss: 3.1800\n",
      "Number of images: 1025\n",
      "Presicion: 0.3943\n",
      "Recall: 0.2439\n",
      "F1 score: 0.3014\n",
      "F1 score: 0.30135911885159195\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 144s 722ms/step - loss: 1.7933 - val_loss: 2.7034\n",
      "Number of images: 1025\n",
      "Presicion: 0.3377\n",
      "Recall: 0.2485\n",
      "F1 score: 0.2863\n",
      "F1 score: 0.28631965866233566\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 143s 717ms/step - loss: 1.8459 - val_loss: 2.7663\n",
      "Number of images: 1025\n",
      "Presicion: 0.3646\n",
      "Recall: 0.3028\n",
      "F1 score: 0.3308\n",
      "F1 score: 0.33082557651345007\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 142s 710ms/step - loss: 1.7888 - val_loss: 3.1325\n",
      "Number of images: 1025\n",
      "Presicion: 0.3685\n",
      "Recall: 0.2995\n",
      "F1 score: 0.3304\n",
      "F1 score: 0.33044931791189186\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 143s 717ms/step - loss: 1.7525 - val_loss: 2.8805\n",
      "Number of images: 1025\n",
      "Presicion: 0.4269\n",
      "Recall: 0.1871\n",
      "F1 score: 0.2602\n",
      "F1 score: 0.26021317792278925\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 145s 725ms/step - loss: 1.8039 - val_loss: 2.9251\n",
      "Number of images: 1025\n",
      "Presicion: 0.3724\n",
      "Recall: 0.1789\n",
      "F1 score: 0.2417\n",
      "F1 score: 0.24167758089399624\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 144s 718ms/step - loss: 1.7544 - val_loss: 3.1324\n",
      "Number of images: 1025\n",
      "Presicion: 0.4031\n",
      "Recall: 0.2168\n",
      "F1 score: 0.282\n",
      "F1 score: 0.28199338812752334\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 144s 720ms/step - loss: 1.7599 - val_loss: 2.9297\n",
      "Number of images: 1025\n",
      "Presicion: 0.4001\n",
      "Recall: 0.2311\n",
      "F1 score: 0.293\n",
      "F1 score: 0.29302127732630784\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 145s 726ms/step - loss: 1.7535 - val_loss: 2.9165\n",
      "Number of images: 1025\n",
      "Presicion: 0.3549\n",
      "Recall: 0.3141\n",
      "F1 score: 0.3333\n",
      "F1 score: 0.3332653902762191\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 146s 732ms/step - loss: 1.8184 - val_loss: 3.2799\n",
      "Number of images: 1025\n",
      "Presicion: 0.2879\n",
      "Recall: 0.3235\n",
      "F1 score: 0.3047\n",
      "F1 score: 0.304681044531156\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 145s 723ms/step - loss: 1.7629 - val_loss: 2.9853\n",
      "Number of images: 1025\n",
      "Presicion: 0.4022\n",
      "Recall: 0.2115\n",
      "F1 score: 0.2773\n",
      "F1 score: 0.2772554767387326\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 144s 718ms/step - loss: 1.7086 - val_loss: 3.2319\n",
      "Number of images: 1025\n",
      "Presicion: 0.3887\n",
      "Recall: 0.1157\n",
      "F1 score: 0.1783\n",
      "F1 score: 0.1783447093748926\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 145s 723ms/step - loss: 1.7287 - val_loss: 2.8857\n",
      "Number of images: 1025\n",
      "Presicion: 0.3799\n",
      "Recall: 0.2387\n",
      "F1 score: 0.2932\n",
      "F1 score: 0.29315598436692347\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 143s 714ms/step - loss: 1.7267 - val_loss: 2.8175\n",
      "Number of images: 1025\n",
      "Presicion: 0.3432\n",
      "Recall: 0.2972\n",
      "F1 score: 0.3186\n",
      "F1 score: 0.3185714238942921\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 143s 716ms/step - loss: 1.7089 - val_loss: 3.1996\n",
      "Number of images: 1025\n",
      "Presicion: 0.3233\n",
      "Recall: 0.2253\n",
      "F1 score: 0.2656\n",
      "F1 score: 0.2655547030321314\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 140s 702ms/step - loss: 1.6847 - val_loss: 2.8709\n",
      "Number of images: 1025\n",
      "Presicion: 0.3792\n",
      "Recall: 0.2858\n",
      "F1 score: 0.3259\n",
      "F1 score: 0.3259325544395249\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 145s 723ms/step - loss: 1.7052 - val_loss: 2.6167\n",
      "Number of images: 1025\n",
      "Presicion: 0.3591\n",
      "Recall: 0.2623\n",
      "F1 score: 0.3032\n",
      "F1 score: 0.3031581692298033\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 144s 719ms/step - loss: 1.7557 - val_loss: 3.1730\n",
      "Number of images: 1025\n",
      "Presicion: 0.3342\n",
      "Recall: 0.3366\n",
      "F1 score: 0.3354\n",
      "F1 score: 0.335412015657229\n",
      "Improve F1 score from 0.3335959065173768 to 0.335412015657229\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 143s 716ms/step - loss: 1.6982 - val_loss: 2.8788\n",
      "Number of images: 1025\n",
      "Presicion: 0.3623\n",
      "Recall: 0.2314\n",
      "F1 score: 0.2824\n",
      "F1 score: 0.28239440823387413\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 144s 722ms/step - loss: 1.7167 - val_loss: 2.7377\n",
      "Number of images: 1025\n",
      "Presicion: 0.3194\n",
      "Recall: 0.2484\n",
      "F1 score: 0.2795\n",
      "F1 score: 0.2794845816852134\n",
      "TRAINING MODEL WITH LEARNING RATE: 0.001\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 162s 808ms/step - loss: 3.1519 - val_loss: 2.9256\n",
      "Number of images: 1025\n",
      "Presicion: 0.5881\n",
      "Recall: 0.4578\n",
      "F1 score: 0.5149\n",
      "F1 score: 0.514857042642523\n",
      "Improve F1 score from -inf to 0.514857042642523\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 147s 735ms/step - loss: 2.8184 - val_loss: 2.6518\n",
      "Number of images: 1025\n",
      "Presicion: 0.5511\n",
      "Recall: 0.4644\n",
      "F1 score: 0.5041\n",
      "F1 score: 0.5040643053353485\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 146s 729ms/step - loss: 2.6294 - val_loss: 2.6570\n",
      "Number of images: 1025\n",
      "Presicion: 0.5689\n",
      "Recall: 0.4171\n",
      "F1 score: 0.4813\n",
      "F1 score: 0.4812843801947149\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 141s 707ms/step - loss: 2.4821 - val_loss: 2.6902\n",
      "Number of images: 1025\n",
      "Presicion: 0.5531\n",
      "Recall: 0.4184\n",
      "F1 score: 0.4764\n",
      "F1 score: 0.47639165728721944\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 144s 718ms/step - loss: 2.4106 - val_loss: 2.6009\n",
      "Number of images: 1025\n",
      "Presicion: 0.5596\n",
      "Recall: 0.3919\n",
      "F1 score: 0.461\n",
      "F1 score: 0.46095522733751054\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 146s 728ms/step - loss: 2.3310 - val_loss: 2.5493\n",
      "Number of images: 1025\n",
      "Presicion: 0.5404\n",
      "Recall: 0.4184\n",
      "F1 score: 0.4716\n",
      "F1 score: 0.4716323916087327\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 144s 719ms/step - loss: 2.2152 - val_loss: 2.4373\n",
      "Number of images: 1025\n",
      "Presicion: 0.5282\n",
      "Recall: 0.4147\n",
      "F1 score: 0.4647\n",
      "F1 score: 0.46466125481482806\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 146s 731ms/step - loss: 2.1923 - val_loss: 2.4598\n",
      "Number of images: 1025\n",
      "Presicion: 0.5167\n",
      "Recall: 0.4125\n",
      "F1 score: 0.4587\n",
      "F1 score: 0.4587470320496746\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 144s 719ms/step - loss: 2.1432 - val_loss: 2.3988\n",
      "Number of images: 1025\n",
      "Presicion: 0.5493\n",
      "Recall: 0.4095\n",
      "F1 score: 0.4692\n",
      "F1 score: 0.46917908393479185\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 144s 722ms/step - loss: 2.1016 - val_loss: 2.6075\n",
      "Number of images: 1025\n",
      "Presicion: 0.512\n",
      "Recall: 0.4025\n",
      "F1 score: 0.4507\n",
      "F1 score: 0.4506961057232784\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 143s 716ms/step - loss: 2.0563 - val_loss: 2.4823\n",
      "Number of images: 1025\n",
      "Presicion: 0.5102\n",
      "Recall: 0.3982\n",
      "F1 score: 0.4473\n",
      "F1 score: 0.4473376718855385\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 145s 726ms/step - loss: 2.0252 - val_loss: 2.4797\n",
      "Number of images: 1025\n",
      "Presicion: 0.5184\n",
      "Recall: 0.3511\n",
      "F1 score: 0.4186\n",
      "F1 score: 0.41864881528704473\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 145s 724ms/step - loss: 1.9743 - val_loss: 2.5724\n",
      "Number of images: 1025\n",
      "Presicion: 0.5129\n",
      "Recall: 0.397\n",
      "F1 score: 0.4475\n",
      "F1 score: 0.447546848145812\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 146s 730ms/step - loss: 1.9504 - val_loss: 2.6458\n",
      "Number of images: 1025\n",
      "Presicion: 0.5494\n",
      "Recall: 0.3684\n",
      "F1 score: 0.4411\n",
      "F1 score: 0.44107146833442956\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 144s 722ms/step - loss: 1.9381 - val_loss: 2.4909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 1025\n",
      "Presicion: 0.576\n",
      "Recall: 0.3352\n",
      "F1 score: 0.4238\n",
      "F1 score: 0.42381176160866507\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 145s 726ms/step - loss: 1.9311 - val_loss: 2.4133\n",
      "Number of images: 1025\n",
      "Presicion: 0.5616\n",
      "Recall: 0.3761\n",
      "F1 score: 0.4505\n",
      "F1 score: 0.45049835296901686\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 144s 721ms/step - loss: 1.8834 - val_loss: 2.5414\n",
      "Number of images: 1025\n",
      "Presicion: 0.5413\n",
      "Recall: 0.3493\n",
      "F1 score: 0.4246\n",
      "F1 score: 0.42464811877063746\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 146s 732ms/step - loss: 1.8780 - val_loss: 2.5584\n",
      "Number of images: 1025\n",
      "Presicion: 0.5185\n",
      "Recall: 0.3764\n",
      "F1 score: 0.4362\n",
      "F1 score: 0.4361917390664329\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 145s 726ms/step - loss: 1.8390 - val_loss: 2.4172\n",
      "Number of images: 1025\n",
      "Presicion: 0.5205\n",
      "Recall: 0.3866\n",
      "F1 score: 0.4437\n",
      "F1 score: 0.4436877875949395\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 146s 728ms/step - loss: 1.8524 - val_loss: 2.5929\n",
      "Number of images: 1025\n",
      "Presicion: 0.5315\n",
      "Recall: 0.3785\n",
      "F1 score: 0.4422\n",
      "F1 score: 0.44215892177851246\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 143s 714ms/step - loss: 1.8060 - val_loss: 2.8551\n",
      "Number of images: 1025\n",
      "Presicion: 0.5472\n",
      "Recall: 0.3573\n",
      "F1 score: 0.4323\n",
      "F1 score: 0.4323490218608315\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 146s 730ms/step - loss: 1.7781 - val_loss: 2.6600\n",
      "Number of images: 1025\n",
      "Presicion: 0.5255\n",
      "Recall: 0.3698\n",
      "F1 score: 0.4341\n",
      "F1 score: 0.4341215401623343\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 146s 731ms/step - loss: 1.7826 - val_loss: 2.4685\n",
      "Number of images: 1025\n",
      "Presicion: 0.5065\n",
      "Recall: 0.3587\n",
      "F1 score: 0.42\n",
      "F1 score: 0.4199834085874729\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 144s 719ms/step - loss: 1.7497 - val_loss: 2.6071\n",
      "Number of images: 1025\n",
      "Presicion: 0.508\n",
      "Recall: 0.3627\n",
      "F1 score: 0.4232\n",
      "F1 score: 0.4232043747658367\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 147s 735ms/step - loss: 1.7597 - val_loss: 2.6031\n",
      "Number of images: 1025\n",
      "Presicion: 0.5143\n",
      "Recall: 0.3645\n",
      "F1 score: 0.4266\n",
      "F1 score: 0.4266446851457878\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 147s 735ms/step - loss: 1.7374 - val_loss: 2.5818\n",
      "Number of images: 1025\n",
      "Presicion: 0.521\n",
      "Recall: 0.3683\n",
      "F1 score: 0.4316\n",
      "F1 score: 0.43156068857172164\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 148s 738ms/step - loss: 1.6991 - val_loss: 2.6592\n",
      "Number of images: 1025\n",
      "Presicion: 0.5026\n",
      "Recall: 0.3652\n",
      "F1 score: 0.423\n",
      "F1 score: 0.4230363323278598\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 144s 720ms/step - loss: 1.7181 - val_loss: 2.4897\n",
      "Number of images: 1025\n",
      "Presicion: 0.5396\n",
      "Recall: 0.3535\n",
      "F1 score: 0.4272\n",
      "F1 score: 0.4271581688170453\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 146s 731ms/step - loss: 1.6690 - val_loss: 2.5088\n",
      "Number of images: 1025\n",
      "Presicion: 0.527\n",
      "Recall: 0.3656\n",
      "F1 score: 0.4317\n",
      "F1 score: 0.43171342754340236\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 148s 740ms/step - loss: 1.6880 - val_loss: 2.5776\n",
      "Number of images: 1025\n",
      "Presicion: 0.5339\n",
      "Recall: 0.3412\n",
      "F1 score: 0.4163\n",
      "F1 score: 0.4163405505315322\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 146s 732ms/step - loss: 1.6633 - val_loss: 2.4833\n",
      "Number of images: 1025\n",
      "Presicion: 0.4882\n",
      "Recall: 0.353\n",
      "F1 score: 0.4098\n",
      "F1 score: 0.4097650590596562\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 147s 735ms/step - loss: 1.6589 - val_loss: 2.6526\n",
      "Number of images: 1025\n",
      "Presicion: 0.5195\n",
      "Recall: 0.3579\n",
      "F1 score: 0.4238\n",
      "F1 score: 0.4238042189731836\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 145s 726ms/step - loss: 1.6291 - val_loss: 2.6096\n",
      "Number of images: 1025\n",
      "Presicion: 0.4487\n",
      "Recall: 0.3443\n",
      "F1 score: 0.3896\n",
      "F1 score: 0.38958393951124903\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 146s 731ms/step - loss: 1.6233 - val_loss: 2.6993\n",
      "Number of images: 1025\n",
      "Presicion: 0.5031\n",
      "Recall: 0.3349\n",
      "F1 score: 0.4021\n",
      "F1 score: 0.40210751635394737\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 146s 731ms/step - loss: 1.6171 - val_loss: 2.6759\n",
      "Number of images: 1025\n",
      "Presicion: 0.5422\n",
      "Recall: 0.335\n",
      "F1 score: 0.4141\n",
      "F1 score: 0.41411190506157\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 144s 721ms/step - loss: 1.6232 - val_loss: 2.7868\n",
      "Number of images: 1025\n",
      "Presicion: 0.4921\n",
      "Recall: 0.3722\n",
      "F1 score: 0.4238\n",
      "F1 score: 0.42383447727194284\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 147s 735ms/step - loss: 1.6327 - val_loss: 2.7056\n",
      "Number of images: 1025\n",
      "Presicion: 0.5434\n",
      "Recall: 0.3506\n",
      "F1 score: 0.4262\n",
      "F1 score: 0.426220395066277\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 143s 717ms/step - loss: 1.5760 - val_loss: 2.6014\n",
      "Number of images: 1025\n",
      "Presicion: 0.5661\n",
      "Recall: 0.3242\n",
      "F1 score: 0.4123\n",
      "F1 score: 0.41233510163559367\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 146s 729ms/step - loss: 1.5896 - val_loss: 2.6601\n",
      "Number of images: 1025\n",
      "Presicion: 0.4605\n",
      "Recall: 0.343\n",
      "F1 score: 0.3932\n",
      "F1 score: 0.39317600033595373\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 148s 739ms/step - loss: 1.6137 - val_loss: 2.6092\n",
      "Number of images: 1025\n",
      "Presicion: 0.5109\n",
      "Recall: 0.3318\n",
      "F1 score: 0.4023\n",
      "F1 score: 0.40231905484968333\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 149s 744ms/step - loss: 1.5875 - val_loss: 2.6068\n",
      "Number of images: 1025\n",
      "Presicion: 0.5421\n",
      "Recall: 0.2826\n",
      "F1 score: 0.3715\n",
      "F1 score: 0.3714983734241818\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 145s 726ms/step - loss: 1.6106 - val_loss: 2.7702\n",
      "Number of images: 1025\n",
      "Presicion: 0.5412\n",
      "Recall: 0.2916\n",
      "F1 score: 0.379\n",
      "F1 score: 0.3790148154310807\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 152s 758ms/step - loss: 1.5847 - val_loss: 2.6335\n",
      "Number of images: 1025\n",
      "Presicion: 0.4974\n",
      "Recall: 0.3338\n",
      "F1 score: 0.3995\n",
      "F1 score: 0.39951673003380445\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 147s 736ms/step - loss: 1.5930 - val_loss: 2.6823\n",
      "Number of images: 1025\n",
      "Presicion: 0.5415\n",
      "Recall: 0.2757\n",
      "F1 score: 0.3654\n",
      "F1 score: 0.36538617329290063\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 146s 728ms/step - loss: 1.5481 - val_loss: 2.6274\n",
      "Number of images: 1025\n",
      "Presicion: 0.481\n",
      "Recall: 0.3373\n",
      "F1 score: 0.3965\n",
      "F1 score: 0.3965346312585314\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 145s 724ms/step - loss: 1.5120 - val_loss: 2.7375\n",
      "Number of images: 1025\n",
      "Presicion: 0.5213\n",
      "Recall: 0.3221\n",
      "F1 score: 0.3982\n",
      "F1 score: 0.3981863370525588\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 145s 726ms/step - loss: 1.5385 - val_loss: 2.6489\n",
      "Number of images: 1025\n",
      "Presicion: 0.5312\n",
      "Recall: 0.3284\n",
      "F1 score: 0.4059\n",
      "F1 score: 0.40585138595097503\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 144s 718ms/step - loss: 1.4929 - val_loss: 2.6608\n",
      "Number of images: 1025\n",
      "Presicion: 0.5162\n",
      "Recall: 0.3099\n",
      "F1 score: 0.3873\n",
      "F1 score: 0.387274418502507\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 148s 741ms/step - loss: 1.5061 - val_loss: 2.6844\n",
      "Number of images: 1025\n",
      "Presicion: 0.5283\n",
      "Recall: 0.323\n",
      "F1 score: 0.4009\n",
      "F1 score: 0.4008582125548273\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 146s 730ms/step - loss: 1.5018 - val_loss: 2.7078\n",
      "Number of images: 1025\n",
      "Presicion: 0.5189\n",
      "Recall: 0.3313\n",
      "F1 score: 0.4044\n",
      "F1 score: 0.40441478771083944\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 143s 715ms/step - loss: 1.4503 - val_loss: 2.7803\n",
      "Number of images: 1025\n",
      "Presicion: 0.4957\n",
      "Recall: 0.3243\n",
      "F1 score: 0.3921\n",
      "F1 score: 0.39206242745150227\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 147s 737ms/step - loss: 1.5066 - val_loss: 2.6146\n",
      "Number of images: 1025\n",
      "Presicion: 0.5141\n",
      "Recall: 0.3527\n",
      "F1 score: 0.4184\n",
      "F1 score: 0.4183576351810388\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 146s 728ms/step - loss: 1.4553 - val_loss: 2.5778\n",
      "Number of images: 1025\n",
      "Presicion: 0.5081\n",
      "Recall: 0.3568\n",
      "F1 score: 0.4192\n",
      "F1 score: 0.41919248255535424\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 145s 727ms/step - loss: 1.5243 - val_loss: 2.8008\n",
      "Number of images: 1025\n",
      "Presicion: 0.5358\n",
      "Recall: 0.3366\n",
      "F1 score: 0.4135\n",
      "F1 score: 0.4134549036746281\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 143s 717ms/step - loss: 1.4881 - val_loss: 2.7560\n",
      "Number of images: 1025\n",
      "Presicion: 0.5403\n",
      "Recall: 0.3079\n",
      "F1 score: 0.3923\n",
      "F1 score: 0.3922672904511012\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 147s 733ms/step - loss: 1.4867 - val_loss: 2.7321\n",
      "Number of images: 1025\n",
      "Presicion: 0.5598\n",
      "Recall: 0.3057\n",
      "F1 score: 0.3955\n",
      "F1 score: 0.3954604763982811\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 147s 736ms/step - loss: 1.4812 - val_loss: 2.7393\n",
      "Number of images: 1025\n",
      "Presicion: 0.5315\n",
      "Recall: 0.3221\n",
      "F1 score: 0.4011\n",
      "F1 score: 0.4011208008494121\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 144s 719ms/step - loss: 1.4537 - val_loss: 2.7583\n",
      "Number of images: 1025\n",
      "Presicion: 0.5318\n",
      "Recall: 0.3352\n",
      "F1 score: 0.4112\n",
      "F1 score: 0.4112095805783072\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 144s 719ms/step - loss: 1.4517 - val_loss: 2.6854\n",
      "Number of images: 1025\n",
      "Presicion: 0.5095\n",
      "Recall: 0.3199\n",
      "F1 score: 0.393\n",
      "F1 score: 0.393039638712918\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 146s 732ms/step - loss: 1.4359 - val_loss: 2.5808\n",
      "Number of images: 1025\n",
      "Presicion: 0.5155\n",
      "Recall: 0.3411\n",
      "F1 score: 0.4106\n",
      "F1 score: 0.4105887633426687\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 149s 745ms/step - loss: 1.4804 - val_loss: 2.8115\n",
      "Number of images: 1025\n",
      "Presicion: 0.4861\n",
      "Recall: 0.3566\n",
      "F1 score: 0.4114\n",
      "F1 score: 0.4113923803598143\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 146s 731ms/step - loss: 1.4561 - val_loss: 2.4833\n",
      "Number of images: 1025\n",
      "Presicion: 0.5358\n",
      "Recall: 0.3112\n",
      "F1 score: 0.3937\n",
      "F1 score: 0.39367845615293634\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 145s 727ms/step - loss: 1.4573 - val_loss: 2.7370\n",
      "Number of images: 1025\n",
      "Presicion: 0.5375\n",
      "Recall: 0.3069\n",
      "F1 score: 0.3907\n",
      "F1 score: 0.3907002368864479\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 146s 730ms/step - loss: 1.4196 - val_loss: 2.9268\n",
      "Number of images: 1025\n",
      "Presicion: 0.5519\n",
      "Recall: 0.3024\n",
      "F1 score: 0.3907\n",
      "F1 score: 0.39066973607857775\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 147s 737ms/step - loss: 1.4308 - val_loss: 2.5733\n",
      "Number of images: 1025\n",
      "Presicion: 0.4994\n",
      "Recall: 0.3233\n",
      "F1 score: 0.3925\n",
      "F1 score: 0.3924878942639705\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 145s 725ms/step - loss: 1.3977 - val_loss: 2.7376\n",
      "Number of images: 1025\n",
      "Presicion: 0.5224\n",
      "Recall: 0.321\n",
      "F1 score: 0.3976\n",
      "F1 score: 0.3976352613165061\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 146s 732ms/step - loss: 1.4321 - val_loss: 2.6339\n",
      "Number of images: 1025\n",
      "Presicion: 0.5513\n",
      "Recall: 0.3019\n",
      "F1 score: 0.3901\n",
      "F1 score: 0.3901052169992296\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 147s 735ms/step - loss: 1.4022 - val_loss: 2.6094\n",
      "Number of images: 1025\n",
      "Presicion: 0.547\n",
      "Recall: 0.3115\n",
      "F1 score: 0.397\n",
      "F1 score: 0.3969773156266506\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 145s 723ms/step - loss: 1.3951 - val_loss: 2.8069\n",
      "Number of images: 1025\n",
      "Presicion: 0.5068\n",
      "Recall: 0.3544\n",
      "F1 score: 0.4171\n",
      "F1 score: 0.41713305100913034\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 142s 711ms/step - loss: 1.4176 - val_loss: 2.8806\n",
      "Number of images: 1025\n",
      "Presicion: 0.5244\n",
      "Recall: 0.341\n",
      "F1 score: 0.4133\n",
      "F1 score: 0.4132946419263587\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 147s 733ms/step - loss: 1.4216 - val_loss: 2.7167\n",
      "Number of images: 1025\n",
      "Presicion: 0.527\n",
      "Recall: 0.342\n",
      "F1 score: 0.4148\n",
      "F1 score: 0.4148198523650876\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 144s 719ms/step - loss: 1.3968 - val_loss: 2.7724\n",
      "Number of images: 1025\n",
      "Presicion: 0.4915\n",
      "Recall: 0.3288\n",
      "F1 score: 0.394\n",
      "F1 score: 0.39404760274981404\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 146s 730ms/step - loss: 1.3900 - val_loss: 2.6329\n",
      "Number of images: 1025\n",
      "Presicion: 0.5323\n",
      "Recall: 0.3082\n",
      "F1 score: 0.3904\n",
      "F1 score: 0.3903777441880418\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 147s 736ms/step - loss: 1.4182 - val_loss: 2.7250\n",
      "Number of images: 1025\n",
      "Presicion: 0.5418\n",
      "Recall: 0.2951\n",
      "F1 score: 0.382\n",
      "F1 score: 0.3820443255522772\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 147s 734ms/step - loss: 1.3817 - val_loss: 2.7783\n",
      "Number of images: 1025\n",
      "Presicion: 0.5374\n",
      "Recall: 0.293\n",
      "F1 score: 0.3793\n",
      "F1 score: 0.37925340689590015\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 143s 716ms/step - loss: 1.3689 - val_loss: 2.8353\n",
      "Number of images: 1025\n",
      "Presicion: 0.5092\n",
      "Recall: 0.323\n",
      "F1 score: 0.3953\n",
      "F1 score: 0.3952803075893192\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 144s 719ms/step - loss: 1.3768 - val_loss: 2.6429\n",
      "Number of images: 1025\n",
      "Presicion: 0.5447\n",
      "Recall: 0.3056\n",
      "F1 score: 0.3916\n",
      "F1 score: 0.3915718617589098\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 145s 724ms/step - loss: 1.3900 - val_loss: 2.6409\n",
      "Number of images: 1025\n",
      "Presicion: 0.5034\n",
      "Recall: 0.3033\n",
      "F1 score: 0.3785\n",
      "F1 score: 0.378506505164821\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 145s 727ms/step - loss: 1.4074 - val_loss: 2.6625\n",
      "Number of images: 1025\n",
      "Presicion: 0.5034\n",
      "Recall: 0.3179\n",
      "F1 score: 0.3897\n",
      "F1 score: 0.3896911244366746\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 148s 739ms/step - loss: 1.3580 - val_loss: 2.7354\n",
      "Number of images: 1025\n",
      "Presicion: 0.5405\n",
      "Recall: 0.3127\n",
      "F1 score: 0.3962\n",
      "F1 score: 0.3961661956538991\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 143s 717ms/step - loss: 1.4049 - val_loss: 2.6034\n",
      "Number of images: 1025\n",
      "Presicion: 0.5013\n",
      "Recall: 0.3354\n",
      "F1 score: 0.4019\n",
      "F1 score: 0.4019350830187655\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 145s 725ms/step - loss: 1.3612 - val_loss: 2.7618\n",
      "Number of images: 1025\n",
      "Presicion: 0.5689\n",
      "Recall: 0.2802\n",
      "F1 score: 0.3754\n",
      "F1 score: 0.3754162653352611\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 145s 727ms/step - loss: 1.3476 - val_loss: 2.6874\n",
      "Number of images: 1025\n",
      "Presicion: 0.5514\n",
      "Recall: 0.2923\n",
      "F1 score: 0.3821\n",
      "F1 score: 0.3820788489192347\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 143s 713ms/step - loss: 1.3442 - val_loss: 2.7214\n",
      "Number of images: 1025\n",
      "Presicion: 0.4976\n",
      "Recall: 0.3338\n",
      "F1 score: 0.3996\n",
      "F1 score: 0.3995680665213924\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 143s 716ms/step - loss: 1.3367 - val_loss: 2.7961\n",
      "Number of images: 1025\n",
      "Presicion: 0.5532\n",
      "Recall: 0.2932\n",
      "F1 score: 0.3833\n",
      "F1 score: 0.3833080858873802\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 145s 727ms/step - loss: 1.3434 - val_loss: 2.7229\n",
      "Number of images: 1025\n",
      "Presicion: 0.4838\n",
      "Recall: 0.3213\n",
      "F1 score: 0.3861\n",
      "F1 score: 0.3861064116328127\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 146s 731ms/step - loss: 1.3574 - val_loss: 2.5706\n",
      "Number of images: 1025\n",
      "Presicion: 0.5529\n",
      "Recall: 0.2947\n",
      "F1 score: 0.3844\n",
      "F1 score: 0.38442252687112116\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 147s 735ms/step - loss: 1.3653 - val_loss: 2.7915\n",
      "Number of images: 1025\n",
      "Presicion: 0.5287\n",
      "Recall: 0.3063\n",
      "F1 score: 0.3879\n",
      "F1 score: 0.38786435523549473\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 147s 733ms/step - loss: 1.3149 - val_loss: 2.6629\n",
      "Number of images: 1025\n",
      "Presicion: 0.5487\n",
      "Recall: 0.2598\n",
      "F1 score: 0.3527\n",
      "F1 score: 0.3526607857813114\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 146s 728ms/step - loss: 1.3411 - val_loss: 2.9038\n",
      "Number of images: 1025\n",
      "Presicion: 0.5227\n",
      "Recall: 0.3174\n",
      "F1 score: 0.395\n",
      "F1 score: 0.39496783628698595\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 144s 719ms/step - loss: 1.3235 - val_loss: 2.8197\n",
      "Number of images: 1025\n",
      "Presicion: 0.5383\n",
      "Recall: 0.2513\n",
      "F1 score: 0.3427\n",
      "F1 score: 0.3426515524546296\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 147s 734ms/step - loss: 1.3547 - val_loss: 2.7908\n",
      "Number of images: 1025\n",
      "Presicion: 0.5323\n",
      "Recall: 0.2868\n",
      "F1 score: 0.3727\n",
      "F1 score: 0.37273691524051455\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 146s 729ms/step - loss: 1.3160 - val_loss: 2.6141\n",
      "Number of images: 1025\n",
      "Presicion: 0.487\n",
      "Recall: 0.316\n",
      "F1 score: 0.3833\n",
      "F1 score: 0.38325351576945865\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 143s 713ms/step - loss: 1.3258 - val_loss: 2.9109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 1025\n",
      "Presicion: 0.5608\n",
      "Recall: 0.3021\n",
      "F1 score: 0.3926\n",
      "F1 score: 0.392648353071744\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 147s 737ms/step - loss: 1.3228 - val_loss: 2.7599\n",
      "Number of images: 1025\n",
      "Presicion: 0.562\n",
      "Recall: 0.2785\n",
      "F1 score: 0.3725\n",
      "F1 score: 0.3724630079685695\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 145s 726ms/step - loss: 1.3159 - val_loss: 2.6971\n",
      "Number of images: 1025\n",
      "Presicion: 0.5683\n",
      "Recall: 0.2858\n",
      "F1 score: 0.3803\n",
      "F1 score: 0.3802946627245749\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 143s 716ms/step - loss: 1.3413 - val_loss: 2.9031\n",
      "Number of images: 1025\n",
      "Presicion: 0.5149\n",
      "Recall: 0.3264\n",
      "F1 score: 0.3996\n",
      "F1 score: 0.3995637903860957\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 141s 707ms/step - loss: 1.2832 - val_loss: 2.9560\n",
      "Number of images: 1025\n",
      "Presicion: 0.535\n",
      "Recall: 0.3094\n",
      "F1 score: 0.3921\n",
      "F1 score: 0.3920874822321196\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 144s 720ms/step - loss: 1.2892 - val_loss: 2.8086\n",
      "Number of images: 1025\n",
      "Presicion: 0.5263\n",
      "Recall: 0.2752\n",
      "F1 score: 0.3614\n",
      "F1 score: 0.36138595143139274\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 146s 729ms/step - loss: 1.2774 - val_loss: 2.7345\n",
      "Number of images: 1025\n",
      "Presicion: 0.5364\n",
      "Recall: 0.3037\n",
      "F1 score: 0.3878\n",
      "F1 score: 0.387844012711524\n",
      "TRAINING MODEL WITH LEARNING RATE: 0.0001\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 163s 814ms/step - loss: 3.6329 - val_loss: 3.3463\n",
      "Number of images: 1025\n",
      "Presicion: 0.5887\n",
      "Recall: 0.5625\n",
      "F1 score: 0.5753\n",
      "F1 score: 0.5753247003703107\n",
      "Improve F1 score from -inf to 0.5753247003703107\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 146s 728ms/step - loss: 3.3326 - val_loss: 3.1490\n",
      "Number of images: 1025\n",
      "Presicion: 0.581\n",
      "Recall: 0.5483\n",
      "F1 score: 0.5642\n",
      "F1 score: 0.5641753625330852\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 147s 737ms/step - loss: 3.1817 - val_loss: 2.9796\n",
      "Number of images: 1025\n",
      "Presicion: 0.5843\n",
      "Recall: 0.5443\n",
      "F1 score: 0.5636\n",
      "F1 score: 0.5635725952190753\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 149s 744ms/step - loss: 3.1328 - val_loss: 2.8892\n",
      "Number of images: 1025\n",
      "Presicion: 0.5981\n",
      "Recall: 0.5348\n",
      "F1 score: 0.5647\n",
      "F1 score: 0.5646629488489207\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 147s 734ms/step - loss: 3.0210 - val_loss: 2.8613\n",
      "Number of images: 1025\n",
      "Presicion: 0.5745\n",
      "Recall: 0.5346\n",
      "F1 score: 0.5538\n",
      "F1 score: 0.5538265496551447\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 145s 727ms/step - loss: 2.9485 - val_loss: 2.7704\n",
      "Number of images: 1025\n",
      "Presicion: 0.5878\n",
      "Recall: 0.5248\n",
      "F1 score: 0.5545\n",
      "F1 score: 0.5545127273296919\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 148s 740ms/step - loss: 2.9114 - val_loss: 2.7464\n",
      "Number of images: 1025\n",
      "Presicion: 0.5665\n",
      "Recall: 0.5211\n",
      "F1 score: 0.5428\n",
      "F1 score: 0.5428367519940391\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 145s 726ms/step - loss: 2.8284 - val_loss: 2.7319\n",
      "Number of images: 1025\n",
      "Presicion: 0.5788\n",
      "Recall: 0.5127\n",
      "F1 score: 0.5437\n",
      "F1 score: 0.5437172137528237\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 145s 727ms/step - loss: 2.7999 - val_loss: 2.7031\n",
      "Number of images: 1025\n",
      "Presicion: 0.5688\n",
      "Recall: 0.5166\n",
      "F1 score: 0.5414\n",
      "F1 score: 0.5414157800207977\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 145s 726ms/step - loss: 2.7337 - val_loss: 2.6765\n",
      "Number of images: 1025\n",
      "Presicion: 0.5649\n",
      "Recall: 0.5092\n",
      "F1 score: 0.5356\n",
      "F1 score: 0.5356447568229837\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 146s 728ms/step - loss: 2.7182 - val_loss: 2.6456\n",
      "Number of images: 1025\n",
      "Presicion: 0.5711\n",
      "Recall: 0.5046\n",
      "F1 score: 0.5358\n",
      "F1 score: 0.5358012204116905\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 147s 735ms/step - loss: 2.6930 - val_loss: 2.6097\n",
      "Number of images: 1025\n",
      "Presicion: 0.5627\n",
      "Recall: 0.5036\n",
      "F1 score: 0.5315\n",
      "F1 score: 0.5315140639706423\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 146s 731ms/step - loss: 2.6620 - val_loss: 2.5986\n",
      "Number of images: 1025\n",
      "Presicion: 0.5706\n",
      "Recall: 0.4975\n",
      "F1 score: 0.5316\n",
      "F1 score: 0.5315749941052941\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 144s 719ms/step - loss: 2.6151 - val_loss: 2.5565\n",
      "Number of images: 1025\n",
      "Presicion: 0.5648\n",
      "Recall: 0.4964\n",
      "F1 score: 0.5284\n",
      "F1 score: 0.528389293991169\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 149s 745ms/step - loss: 2.6177 - val_loss: 2.5708\n",
      "Number of images: 1025\n",
      "Presicion: 0.555\n",
      "Recall: 0.4948\n",
      "F1 score: 0.5232\n",
      "F1 score: 0.5231615848593164\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 147s 734ms/step - loss: 2.5794 - val_loss: 2.5339\n",
      "Number of images: 1025\n",
      "Presicion: 0.5698\n",
      "Recall: 0.4872\n",
      "F1 score: 0.5253\n",
      "F1 score: 0.5252792918565693\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 144s 722ms/step - loss: 2.5488 - val_loss: 2.5346\n",
      "Number of images: 1025\n",
      "Presicion: 0.5646\n",
      "Recall: 0.4889\n",
      "F1 score: 0.524\n",
      "F1 score: 0.5240083829133038\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 145s 723ms/step - loss: 2.5214 - val_loss: 2.5297\n",
      "Number of images: 1025\n",
      "Presicion: 0.569\n",
      "Recall: 0.483\n",
      "F1 score: 0.5225\n",
      "F1 score: 0.5224626896773115\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 147s 733ms/step - loss: 2.5554 - val_loss: 2.5345\n",
      "Number of images: 1025\n",
      "Presicion: 0.5633\n",
      "Recall: 0.486\n",
      "F1 score: 0.5218\n",
      "F1 score: 0.5218213469624914\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 146s 731ms/step - loss: 2.5299 - val_loss: 2.5232\n",
      "Number of images: 1025\n",
      "Presicion: 0.5651\n",
      "Recall: 0.4874\n",
      "F1 score: 0.5234\n",
      "F1 score: 0.5233543454303643\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 144s 719ms/step - loss: 2.4508 - val_loss: 2.5127\n",
      "Number of images: 1025\n",
      "Presicion: 0.569\n",
      "Recall: 0.4827\n",
      "F1 score: 0.5223\n",
      "F1 score: 0.522291545970346\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 148s 741ms/step - loss: 2.5013 - val_loss: 2.4650\n",
      "Number of images: 1025\n",
      "Presicion: 0.5706\n",
      "Recall: 0.4783\n",
      "F1 score: 0.5204\n",
      "F1 score: 0.5203881746472923\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 145s 727ms/step - loss: 2.4448 - val_loss: 2.4604\n",
      "Number of images: 1025\n",
      "Presicion: 0.5732\n",
      "Recall: 0.4772\n",
      "F1 score: 0.5208\n",
      "F1 score: 0.5208108506226341\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 146s 730ms/step - loss: 2.4106 - val_loss: 2.4483\n",
      "Number of images: 1025\n",
      "Presicion: 0.5746\n",
      "Recall: 0.476\n",
      "F1 score: 0.5207\n",
      "F1 score: 0.5206946806734063\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 146s 729ms/step - loss: 2.4512 - val_loss: 2.4529\n",
      "Number of images: 1025\n",
      "Presicion: 0.5718\n",
      "Recall: 0.4792\n",
      "F1 score: 0.5214\n",
      "F1 score: 0.5214212129286543\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 144s 719ms/step - loss: 2.4024 - val_loss: 2.4223\n",
      "Number of images: 1025\n",
      "Presicion: 0.5686\n",
      "Recall: 0.4717\n",
      "F1 score: 0.5156\n",
      "F1 score: 0.5156489178168409\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 147s 733ms/step - loss: 2.4093 - val_loss: 2.4393\n",
      "Number of images: 1025\n",
      "Presicion: 0.5711\n",
      "Recall: 0.4715\n",
      "F1 score: 0.5165\n",
      "F1 score: 0.5165404549750007\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 147s 736ms/step - loss: 2.3518 - val_loss: 2.4420\n",
      "Number of images: 1025\n",
      "Presicion: 0.57\n",
      "Recall: 0.4672\n",
      "F1 score: 0.5135\n",
      "F1 score: 0.513525337484753\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 148s 740ms/step - loss: 2.3251 - val_loss: 2.4046\n",
      "Number of images: 1025\n",
      "Presicion: 0.5749\n",
      "Recall: 0.468\n",
      "F1 score: 0.516\n",
      "F1 score: 0.5159773894344348\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 146s 728ms/step - loss: 2.3279 - val_loss: 2.3919\n",
      "Number of images: 1025\n",
      "Presicion: 0.5669\n",
      "Recall: 0.4667\n",
      "F1 score: 0.512\n",
      "F1 score: 0.5119685636751602\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 144s 722ms/step - loss: 2.3214 - val_loss: 2.4059\n",
      "Number of images: 1025\n",
      "Presicion: 0.5709\n",
      "Recall: 0.4661\n",
      "F1 score: 0.5132\n",
      "F1 score: 0.5132034654855414\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 148s 742ms/step - loss: 2.3232 - val_loss: 2.4030\n",
      "Number of images: 1025\n",
      "Presicion: 0.558\n",
      "Recall: 0.4659\n",
      "F1 score: 0.5078\n",
      "F1 score: 0.5078193967675197\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 143s 717ms/step - loss: 2.2948 - val_loss: 2.4164\n",
      "Number of images: 1025\n",
      "Presicion: 0.5686\n",
      "Recall: 0.4648\n",
      "F1 score: 0.5115\n",
      "F1 score: 0.5115054623219076\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 143s 716ms/step - loss: 2.2789 - val_loss: 2.4119\n",
      "Number of images: 1025\n",
      "Presicion: 0.5667\n",
      "Recall: 0.457\n",
      "F1 score: 0.506\n",
      "F1 score: 0.5059756723423117\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 143s 716ms/step - loss: 2.2635 - val_loss: 2.4027\n",
      "Number of images: 1025\n",
      "Presicion: 0.5683\n",
      "Recall: 0.454\n",
      "F1 score: 0.5048\n",
      "F1 score: 0.5047641231352666\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 145s 726ms/step - loss: 2.2761 - val_loss: 2.3948\n",
      "Number of images: 1025\n",
      "Presicion: 0.5612\n",
      "Recall: 0.4655\n",
      "F1 score: 0.5088\n",
      "F1 score: 0.5088468677466262\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 149s 743ms/step - loss: 2.2452 - val_loss: 2.3982\n",
      "Number of images: 1025\n",
      "Presicion: 0.5638\n",
      "Recall: 0.4558\n",
      "F1 score: 0.5041\n",
      "F1 score: 0.504074334293504\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 146s 732ms/step - loss: 2.2489 - val_loss: 2.3996\n",
      "Number of images: 1025\n",
      "Presicion: 0.5561\n",
      "Recall: 0.4599\n",
      "F1 score: 0.5035\n",
      "F1 score: 0.5034623727162402\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 143s 714ms/step - loss: 2.2151 - val_loss: 2.4356\n",
      "Number of images: 1025\n",
      "Presicion: 0.5587\n",
      "Recall: 0.4623\n",
      "F1 score: 0.506\n",
      "F1 score: 0.5059617686769857\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 146s 729ms/step - loss: 2.2112 - val_loss: 2.4266\n",
      "Number of images: 1025\n",
      "Presicion: 0.5652\n",
      "Recall: 0.4606\n",
      "F1 score: 0.5076\n",
      "F1 score: 0.5075798671238855\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 143s 716ms/step - loss: 2.1762 - val_loss: 2.4328\n",
      "Number of images: 1025\n",
      "Presicion: 0.566\n",
      "Recall: 0.4552\n",
      "F1 score: 0.5046\n",
      "F1 score: 0.5045695766483125\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 147s 733ms/step - loss: 2.1997 - val_loss: 2.3920\n",
      "Number of images: 1025\n",
      "Presicion: 0.5601\n",
      "Recall: 0.4524\n",
      "F1 score: 0.5005\n",
      "F1 score: 0.5005093540793665\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 144s 719ms/step - loss: 2.2006 - val_loss: 2.3752\n",
      "Number of images: 1025\n",
      "Presicion: 0.5729\n",
      "Recall: 0.4472\n",
      "F1 score: 0.5023\n",
      "F1 score: 0.5023201155986209\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 144s 722ms/step - loss: 2.1497 - val_loss: 2.3953\n",
      "Number of images: 1025\n",
      "Presicion: 0.57\n",
      "Recall: 0.4524\n",
      "F1 score: 0.5044\n",
      "F1 score: 0.5044469892633089\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 146s 728ms/step - loss: 2.1746 - val_loss: 2.3889\n",
      "Number of images: 1025\n",
      "Presicion: 0.5617\n",
      "Recall: 0.4522\n",
      "F1 score: 0.501\n",
      "F1 score: 0.5010183233814951\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 147s 734ms/step - loss: 2.1565 - val_loss: 2.4004\n",
      "Number of images: 1025\n",
      "Presicion: 0.5691\n",
      "Recall: 0.4463\n",
      "F1 score: 0.5003\n",
      "F1 score: 0.500254017738467\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 146s 730ms/step - loss: 2.1759 - val_loss: 2.3948\n",
      "Number of images: 1025\n",
      "Presicion: 0.5628\n",
      "Recall: 0.4526\n",
      "F1 score: 0.5017\n",
      "F1 score: 0.5016876922930518\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 146s 731ms/step - loss: 2.1516 - val_loss: 2.4042\n",
      "Number of images: 1025\n",
      "Presicion: 0.5571\n",
      "Recall: 0.4461\n",
      "F1 score: 0.4954\n",
      "F1 score: 0.4954452805033747\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 146s 729ms/step - loss: 2.1412 - val_loss: 2.3972\n",
      "Number of images: 1025\n",
      "Presicion: 0.5706\n",
      "Recall: 0.4454\n",
      "F1 score: 0.5003\n",
      "F1 score: 0.5003066324221503\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 147s 735ms/step - loss: 2.1463 - val_loss: 2.3892\n",
      "Number of images: 1025\n",
      "Presicion: 0.553\n",
      "Recall: 0.4522\n",
      "F1 score: 0.4976\n",
      "F1 score: 0.49758061032828554\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 146s 729ms/step - loss: 2.1114 - val_loss: 2.4003\n",
      "Number of images: 1025\n",
      "Presicion: 0.5526\n",
      "Recall: 0.4525\n",
      "F1 score: 0.4976\n",
      "F1 score: 0.497576542768105\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 145s 727ms/step - loss: 2.1225 - val_loss: 2.4241\n",
      "Number of images: 1025\n",
      "Presicion: 0.5648\n",
      "Recall: 0.4446\n",
      "F1 score: 0.4975\n",
      "F1 score: 0.49753279909659065\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 147s 735ms/step - loss: 2.1015 - val_loss: 2.3863\n",
      "Number of images: 1025\n",
      "Presicion: 0.5592\n",
      "Recall: 0.4439\n",
      "F1 score: 0.4949\n",
      "F1 score: 0.49487863485079314\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 147s 734ms/step - loss: 2.0821 - val_loss: 2.3866\n",
      "Number of images: 1025\n",
      "Presicion: 0.5654\n",
      "Recall: 0.4456\n",
      "F1 score: 0.4984\n",
      "F1 score: 0.4984422800061157\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 144s 721ms/step - loss: 2.0636 - val_loss: 2.3960\n",
      "Number of images: 1025\n",
      "Presicion: 0.5682\n",
      "Recall: 0.4408\n",
      "F1 score: 0.4965\n",
      "F1 score: 0.49646830652593893\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 147s 733ms/step - loss: 2.0610 - val_loss: 2.3872\n",
      "Number of images: 1025\n",
      "Presicion: 0.5699\n",
      "Recall: 0.4296\n",
      "F1 score: 0.4899\n",
      "F1 score: 0.4898955940619134\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 146s 729ms/step - loss: 2.0302 - val_loss: 2.3963\n",
      "Number of images: 1025\n",
      "Presicion: 0.5677\n",
      "Recall: 0.4382\n",
      "F1 score: 0.4946\n",
      "F1 score: 0.4946064308181104\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 146s 730ms/step - loss: 2.0720 - val_loss: 2.3715\n",
      "Number of images: 1025\n",
      "Presicion: 0.5566\n",
      "Recall: 0.4411\n",
      "F1 score: 0.4922\n",
      "F1 score: 0.49220060440666613\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 148s 740ms/step - loss: 2.0733 - val_loss: 2.3878\n",
      "Number of images: 1025\n",
      "Presicion: 0.5653\n",
      "Recall: 0.439\n",
      "F1 score: 0.4942\n",
      "F1 score: 0.4942041633296237\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 146s 732ms/step - loss: 2.0535 - val_loss: 2.4085\n",
      "Number of images: 1025\n",
      "Presicion: 0.5668\n",
      "Recall: 0.4419\n",
      "F1 score: 0.4966\n",
      "F1 score: 0.49660635085996024\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 144s 722ms/step - loss: 2.0307 - val_loss: 2.3617\n",
      "Number of images: 1025\n",
      "Presicion: 0.5737\n",
      "Recall: 0.4327\n",
      "F1 score: 0.4934\n",
      "F1 score: 0.4933513950010825\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 146s 732ms/step - loss: 2.0139 - val_loss: 2.3885\n",
      "Number of images: 1025\n",
      "Presicion: 0.5648\n",
      "Recall: 0.4375\n",
      "F1 score: 0.4931\n",
      "F1 score: 0.4930917045476391\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 144s 718ms/step - loss: 2.0257 - val_loss: 2.3863\n",
      "Number of images: 1025\n",
      "Presicion: 0.5684\n",
      "Recall: 0.4357\n",
      "F1 score: 0.4933\n",
      "F1 score: 0.493298031366529\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 146s 730ms/step - loss: 2.0186 - val_loss: 2.3280\n",
      "Number of images: 1025\n",
      "Presicion: 0.5643\n",
      "Recall: 0.4373\n",
      "F1 score: 0.4928\n",
      "F1 score: 0.4927724031612827\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 145s 723ms/step - loss: 1.9976 - val_loss: 2.3500\n",
      "Number of images: 1025\n",
      "Presicion: 0.5717\n",
      "Recall: 0.4356\n",
      "F1 score: 0.4945\n",
      "F1 score: 0.494473968304338\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 143s 717ms/step - loss: 2.0039 - val_loss: 2.3261\n",
      "Number of images: 1025\n",
      "Presicion: 0.5656\n",
      "Recall: 0.4358\n",
      "F1 score: 0.4923\n",
      "F1 score: 0.49229955991155666\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 147s 733ms/step - loss: 1.9868 - val_loss: 2.3466\n",
      "Number of images: 1025\n",
      "Presicion: 0.5712\n",
      "Recall: 0.4381\n",
      "F1 score: 0.4958\n",
      "F1 score: 0.49584020414040625\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 146s 732ms/step - loss: 2.0045 - val_loss: 2.3532\n",
      "Number of images: 1025\n",
      "Presicion: 0.5639\n",
      "Recall: 0.4414\n",
      "F1 score: 0.4952\n",
      "F1 score: 0.49521996312676453\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 145s 726ms/step - loss: 1.9870 - val_loss: 2.3374\n",
      "Number of images: 1025\n",
      "Presicion: 0.5644\n",
      "Recall: 0.4381\n",
      "F1 score: 0.4933\n",
      "F1 score: 0.49329364455190516\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 144s 718ms/step - loss: 2.0009 - val_loss: 2.3199\n",
      "Number of images: 1025\n",
      "Presicion: 0.5561\n",
      "Recall: 0.4362\n",
      "F1 score: 0.4889\n",
      "F1 score: 0.4889127817428439\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 148s 738ms/step - loss: 2.0219 - val_loss: 2.3231\n",
      "Number of images: 1025\n",
      "Presicion: 0.5618\n",
      "Recall: 0.4335\n",
      "F1 score: 0.4894\n",
      "F1 score: 0.4893891772744101\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 144s 721ms/step - loss: 1.9678 - val_loss: 2.3236\n",
      "Number of images: 1025\n",
      "Presicion: 0.5654\n",
      "Recall: 0.4293\n",
      "F1 score: 0.488\n",
      "F1 score: 0.4880309698998355\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 145s 726ms/step - loss: 1.9392 - val_loss: 2.3505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 1025\n",
      "Presicion: 0.563\n",
      "Recall: 0.4364\n",
      "F1 score: 0.4917\n",
      "F1 score: 0.4916757481575481\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 145s 726ms/step - loss: 1.9666 - val_loss: 2.3582\n",
      "Number of images: 1025\n",
      "Presicion: 0.5591\n",
      "Recall: 0.4364\n",
      "F1 score: 0.4902\n",
      "F1 score: 0.49021074714005597\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 146s 731ms/step - loss: 1.9655 - val_loss: 2.3831\n",
      "Number of images: 1025\n",
      "Presicion: 0.557\n",
      "Recall: 0.4365\n",
      "F1 score: 0.4895\n",
      "F1 score: 0.4894751080343841\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 144s 722ms/step - loss: 1.9463 - val_loss: 2.3747\n",
      "Number of images: 1025\n",
      "Presicion: 0.5699\n",
      "Recall: 0.4322\n",
      "F1 score: 0.4916\n",
      "F1 score: 0.49159650634228635\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 147s 734ms/step - loss: 1.9163 - val_loss: 2.3687\n",
      "Number of images: 1025\n",
      "Presicion: 0.5658\n",
      "Recall: 0.4325\n",
      "F1 score: 0.4902\n",
      "F1 score: 0.49020391795117474\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 148s 738ms/step - loss: 1.9759 - val_loss: 2.3638\n",
      "Number of images: 1025\n",
      "Presicion: 0.5718\n",
      "Recall: 0.4276\n",
      "F1 score: 0.4893\n",
      "F1 score: 0.4893158301442877\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 148s 739ms/step - loss: 1.9265 - val_loss: 2.3720\n",
      "Number of images: 1025\n",
      "Presicion: 0.5524\n",
      "Recall: 0.424\n",
      "F1 score: 0.4798\n",
      "F1 score: 0.47976862149770755\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 146s 731ms/step - loss: 1.9590 - val_loss: 2.3570\n",
      "Number of images: 1025\n",
      "Presicion: 0.5587\n",
      "Recall: 0.425\n",
      "F1 score: 0.4827\n",
      "F1 score: 0.48274192931377474\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 148s 738ms/step - loss: 1.9469 - val_loss: 2.3644\n",
      "Number of images: 1025\n",
      "Presicion: 0.5745\n",
      "Recall: 0.4186\n",
      "F1 score: 0.4843\n",
      "F1 score: 0.4843032045335825\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 146s 729ms/step - loss: 1.9244 - val_loss: 2.3816\n",
      "Number of images: 1025\n",
      "Presicion: 0.5643\n",
      "Recall: 0.4279\n",
      "F1 score: 0.4868\n",
      "F1 score: 0.48675153998417214\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 147s 737ms/step - loss: 1.9285 - val_loss: 2.3557\n",
      "Number of images: 1025\n",
      "Presicion: 0.5697\n",
      "Recall: 0.4268\n",
      "F1 score: 0.488\n",
      "F1 score: 0.48800499891168736\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 146s 730ms/step - loss: 1.9217 - val_loss: 2.3436\n",
      "Number of images: 1025\n",
      "Presicion: 0.5616\n",
      "Recall: 0.4275\n",
      "F1 score: 0.4854\n",
      "F1 score: 0.485432459631917\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 145s 727ms/step - loss: 1.9431 - val_loss: 2.3588\n",
      "Number of images: 1025\n",
      "Presicion: 0.5498\n",
      "Recall: 0.4305\n",
      "F1 score: 0.4829\n",
      "F1 score: 0.4828718060221816\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 147s 733ms/step - loss: 1.8861 - val_loss: 2.3493\n",
      "Number of images: 1025\n",
      "Presicion: 0.5754\n",
      "Recall: 0.4179\n",
      "F1 score: 0.4841\n",
      "F1 score: 0.48412615120694785\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 144s 721ms/step - loss: 1.9148 - val_loss: 2.3576\n",
      "Number of images: 1025\n",
      "Presicion: 0.5609\n",
      "Recall: 0.4231\n",
      "F1 score: 0.4823\n",
      "F1 score: 0.4823379057195837\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 145s 725ms/step - loss: 1.8878 - val_loss: 2.3299\n",
      "Number of images: 1025\n",
      "Presicion: 0.5718\n",
      "Recall: 0.4131\n",
      "F1 score: 0.4797\n",
      "F1 score: 0.4796588292286711\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 147s 735ms/step - loss: 1.8732 - val_loss: 2.3907\n",
      "Number of images: 1025\n",
      "Presicion: 0.5663\n",
      "Recall: 0.4275\n",
      "F1 score: 0.4872\n",
      "F1 score: 0.48719569023227605\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 147s 735ms/step - loss: 1.8970 - val_loss: 2.3635\n",
      "Number of images: 1025\n",
      "Presicion: 0.5728\n",
      "Recall: 0.4155\n",
      "F1 score: 0.4816\n",
      "F1 score: 0.48160487966034776\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 148s 742ms/step - loss: 1.8685 - val_loss: 2.3747\n",
      "Number of images: 1025\n",
      "Presicion: 0.5624\n",
      "Recall: 0.428\n",
      "F1 score: 0.4861\n",
      "F1 score: 0.4860799882984091\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 146s 731ms/step - loss: 1.8444 - val_loss: 2.3702\n",
      "Number of images: 1025\n",
      "Presicion: 0.5678\n",
      "Recall: 0.4242\n",
      "F1 score: 0.4856\n",
      "F1 score: 0.48564128402386353\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 145s 725ms/step - loss: 1.8756 - val_loss: 2.3835\n",
      "Number of images: 1025\n",
      "Presicion: 0.5625\n",
      "Recall: 0.4147\n",
      "F1 score: 0.4774\n",
      "F1 score: 0.47743784103441517\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 149s 743ms/step - loss: 1.8800 - val_loss: 2.3693\n",
      "Number of images: 1025\n",
      "Presicion: 0.5581\n",
      "Recall: 0.4201\n",
      "F1 score: 0.4794\n",
      "F1 score: 0.479357046546285\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 148s 740ms/step - loss: 1.8375 - val_loss: 2.3990\n",
      "Number of images: 1025\n",
      "Presicion: 0.558\n",
      "Recall: 0.4135\n",
      "F1 score: 0.475\n",
      "F1 score: 0.4750186792896271\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 148s 741ms/step - loss: 1.8519 - val_loss: 2.3372\n",
      "Number of images: 1025\n",
      "Presicion: 0.5617\n",
      "Recall: 0.4134\n",
      "F1 score: 0.4763\n",
      "F1 score: 0.47627907432929406\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 146s 728ms/step - loss: 1.8538 - val_loss: 2.3356\n",
      "Number of images: 1025\n",
      "Presicion: 0.5647\n",
      "Recall: 0.4117\n",
      "F1 score: 0.4762\n",
      "F1 score: 0.4761802908197547\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 148s 740ms/step - loss: 1.8424 - val_loss: 2.3375\n",
      "Number of images: 1025\n",
      "Presicion: 0.5668\n",
      "Recall: 0.4105\n",
      "F1 score: 0.4761\n",
      "F1 score: 0.4761134706104724\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 145s 724ms/step - loss: 1.8257 - val_loss: 2.3513\n",
      "Number of images: 1025\n",
      "Presicion: 0.5714\n",
      "Recall: 0.4028\n",
      "F1 score: 0.4725\n",
      "F1 score: 0.4725188869819497\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 146s 731ms/step - loss: 1.8606 - val_loss: 2.3633\n",
      "Number of images: 1025\n",
      "Presicion: 0.5708\n",
      "Recall: 0.4016\n",
      "F1 score: 0.4715\n",
      "F1 score: 0.47147135203564683\n",
      "TRAINING MODEL WITH LEARNING RATE: 1e-05\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 167s 836ms/step - loss: 3.9718 - val_loss: 3.8951\n",
      "Number of images: 1025\n",
      "Presicion: 0.6135\n",
      "Recall: 0.5451\n",
      "F1 score: 0.5773\n",
      "F1 score: 0.5773058904151054\n",
      "Improve F1 score from -inf to 0.5773058904151054\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 145s 726ms/step - loss: 3.8513 - val_loss: 3.7474\n",
      "Number of images: 1025\n",
      "Presicion: 0.6076\n",
      "Recall: 0.5539\n",
      "F1 score: 0.5795\n",
      "F1 score: 0.5794779378802319\n",
      "Improve F1 score from 0.5773058904151054 to 0.5794779378802319\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 150s 749ms/step - loss: 3.7711 - val_loss: 3.6552\n",
      "Number of images: 1025\n",
      "Presicion: 0.605\n",
      "Recall: 0.5576\n",
      "F1 score: 0.5803\n",
      "F1 score: 0.5803372769279634\n",
      "Improve F1 score from 0.5794779378802319 to 0.5803372769279634\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 148s 740ms/step - loss: 3.7085 - val_loss: 3.5777\n",
      "Number of images: 1025\n",
      "Presicion: 0.6021\n",
      "Recall: 0.5565\n",
      "F1 score: 0.5784\n",
      "F1 score: 0.5783981348610879\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 147s 737ms/step - loss: 3.6353 - val_loss: 3.5179\n",
      "Number of images: 1025\n",
      "Presicion: 0.6034\n",
      "Recall: 0.5563\n",
      "F1 score: 0.5789\n",
      "F1 score: 0.5789044489491247\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 147s 733ms/step - loss: 3.6286 - val_loss: 3.4658\n",
      "Number of images: 1025\n",
      "Presicion: 0.6008\n",
      "Recall: 0.5568\n",
      "F1 score: 0.5779\n",
      "F1 score: 0.5779354596487982\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 150s 752ms/step - loss: 3.5467 - val_loss: 3.4190\n",
      "Number of images: 1025\n",
      "Presicion: 0.6\n",
      "Recall: 0.5576\n",
      "F1 score: 0.578\n",
      "F1 score: 0.5780272407748375\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 145s 726ms/step - loss: 3.4765 - val_loss: 3.3936\n",
      "Number of images: 1025\n",
      "Presicion: 0.5973\n",
      "Recall: 0.5586\n",
      "F1 score: 0.5773\n",
      "F1 score: 0.5773255321125095\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 148s 741ms/step - loss: 3.4801 - val_loss: 3.3613\n",
      "Number of images: 1025\n",
      "Presicion: 0.5998\n",
      "Recall: 0.5571\n",
      "F1 score: 0.5777\n",
      "F1 score: 0.5776617581243638\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 145s 725ms/step - loss: 3.4197 - val_loss: 3.3328\n",
      "Number of images: 1025\n",
      "Presicion: 0.6017\n",
      "Recall: 0.5589\n",
      "F1 score: 0.5795\n",
      "F1 score: 0.5794818032347605\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 146s 728ms/step - loss: 3.4414 - val_loss: 3.3072\n",
      "Number of images: 1025\n",
      "Presicion: 0.601\n",
      "Recall: 0.5565\n",
      "F1 score: 0.5779\n",
      "F1 score: 0.5778901762744958\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 148s 741ms/step - loss: 3.4021 - val_loss: 3.2839\n",
      "Number of images: 1025\n",
      "Presicion: 0.6003\n",
      "Recall: 0.5575\n",
      "F1 score: 0.5781\n",
      "F1 score: 0.5781257926243207\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 146s 731ms/step - loss: 3.3756 - val_loss: 3.2611\n",
      "Number of images: 1025\n",
      "Presicion: 0.6001\n",
      "Recall: 0.5567\n",
      "F1 score: 0.5776\n",
      "F1 score: 0.5775505400069894\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 147s 735ms/step - loss: 3.3405 - val_loss: 3.2424\n",
      "Number of images: 1025\n",
      "Presicion: 0.6008\n",
      "Recall: 0.5546\n",
      "F1 score: 0.5768\n",
      "F1 score: 0.5767919329056489\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 149s 744ms/step - loss: 3.3464 - val_loss: 3.2194\n",
      "Number of images: 1025\n",
      "Presicion: 0.5989\n",
      "Recall: 0.5543\n",
      "F1 score: 0.5758\n",
      "F1 score: 0.5757523268522321\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 147s 734ms/step - loss: 3.3103 - val_loss: 3.1959\n",
      "Number of images: 1025\n",
      "Presicion: 0.5962\n",
      "Recall: 0.5535\n",
      "F1 score: 0.5741\n",
      "F1 score: 0.5740520424637142\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 148s 742ms/step - loss: 3.3225 - val_loss: 3.1719\n",
      "Number of images: 1025\n",
      "Presicion: 0.5949\n",
      "Recall: 0.5525\n",
      "F1 score: 0.5729\n",
      "F1 score: 0.5729363428621858\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 147s 733ms/step - loss: 3.2991 - val_loss: 3.1503\n",
      "Number of images: 1025\n",
      "Presicion: 0.5938\n",
      "Recall: 0.551\n",
      "F1 score: 0.5716\n",
      "F1 score: 0.5716023727499076\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 147s 735ms/step - loss: 3.2674 - val_loss: 3.1316\n",
      "Number of images: 1025\n",
      "Presicion: 0.5928\n",
      "Recall: 0.5508\n",
      "F1 score: 0.571\n",
      "F1 score: 0.5710393800960496\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 147s 733ms/step - loss: 3.2433 - val_loss: 3.1136\n",
      "Number of images: 1025\n",
      "Presicion: 0.592\n",
      "Recall: 0.5508\n",
      "F1 score: 0.5707\n",
      "F1 score: 0.5706556394509398\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 148s 742ms/step - loss: 3.2166 - val_loss: 3.0973\n",
      "Number of images: 1025\n",
      "Presicion: 0.5921\n",
      "Recall: 0.5501\n",
      "F1 score: 0.5703\n",
      "F1 score: 0.5703177802084639\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 148s 739ms/step - loss: 3.2218 - val_loss: 3.0755\n",
      "Number of images: 1025\n",
      "Presicion: 0.5909\n",
      "Recall: 0.5484\n",
      "F1 score: 0.5688\n",
      "F1 score: 0.5688324543215315\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 150s 749ms/step - loss: 3.2387 - val_loss: 3.0599\n",
      "Number of images: 1025\n",
      "Presicion: 0.5926\n",
      "Recall: 0.5475\n",
      "F1 score: 0.5691\n",
      "F1 score: 0.5691436714184414\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 149s 745ms/step - loss: 3.1809 - val_loss: 3.0464\n",
      "Number of images: 1025\n",
      "Presicion: 0.5953\n",
      "Recall: 0.5472\n",
      "F1 score: 0.5703\n",
      "F1 score: 0.5702656024785927\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 146s 729ms/step - loss: 3.1682 - val_loss: 3.0303\n",
      "Number of images: 1025\n",
      "Presicion: 0.5937\n",
      "Recall: 0.5453\n",
      "F1 score: 0.5684\n",
      "F1 score: 0.56843872011065\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 147s 737ms/step - loss: 3.1589 - val_loss: 3.0198\n",
      "Number of images: 1025\n",
      "Presicion: 0.5894\n",
      "Recall: 0.5461\n",
      "F1 score: 0.5669\n",
      "F1 score: 0.5668951027025563\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 147s 733ms/step - loss: 3.1456 - val_loss: 3.0071\n",
      "Number of images: 1025\n",
      "Presicion: 0.5919\n",
      "Recall: 0.5451\n",
      "F1 score: 0.5676\n",
      "F1 score: 0.5675668383644595\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 145s 727ms/step - loss: 3.1185 - val_loss: 2.9964\n",
      "Number of images: 1025\n",
      "Presicion: 0.5833\n",
      "Recall: 0.5453\n",
      "F1 score: 0.5636\n",
      "F1 score: 0.5636254793130904\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 145s 723ms/step - loss: 3.1346 - val_loss: 2.9804\n",
      "Number of images: 1025\n",
      "Presicion: 0.5879\n",
      "Recall: 0.5435\n",
      "F1 score: 0.5648\n",
      "F1 score: 0.5648411525378462\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 144s 718ms/step - loss: 3.1137 - val_loss: 2.9692\n",
      "Number of images: 1025\n",
      "Presicion: 0.5899\n",
      "Recall: 0.5428\n",
      "F1 score: 0.5654\n",
      "F1 score: 0.565364681856693\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 149s 747ms/step - loss: 3.1184 - val_loss: 2.9650\n",
      "Number of images: 1025\n",
      "Presicion: 0.5855\n",
      "Recall: 0.5433\n",
      "F1 score: 0.5636\n",
      "F1 score: 0.5636083656101134\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 146s 729ms/step - loss: 3.1087 - val_loss: 2.9494\n",
      "Number of images: 1025\n",
      "Presicion: 0.5885\n",
      "Recall: 0.5404\n",
      "F1 score: 0.5634\n",
      "F1 score: 0.5634009040227057\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 148s 738ms/step - loss: 3.1302 - val_loss: 2.9326\n",
      "Number of images: 1025\n",
      "Presicion: 0.5901\n",
      "Recall: 0.5415\n",
      "F1 score: 0.5647\n",
      "F1 score: 0.5647462792391759\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 145s 727ms/step - loss: 3.0766 - val_loss: 2.9265\n",
      "Number of images: 1025\n",
      "Presicion: 0.5866\n",
      "Recall: 0.54\n",
      "F1 score: 0.5623\n",
      "F1 score: 0.5623479428393884\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 143s 715ms/step - loss: 3.0701 - val_loss: 2.9181\n",
      "Number of images: 1025\n",
      "Presicion: 0.588\n",
      "Recall: 0.5397\n",
      "F1 score: 0.5628\n",
      "F1 score: 0.5628243436480755\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 145s 725ms/step - loss: 3.0725 - val_loss: 2.9076\n",
      "Number of images: 1025\n",
      "Presicion: 0.5851\n",
      "Recall: 0.5392\n",
      "F1 score: 0.5612\n",
      "F1 score: 0.5612271808941958\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 144s 722ms/step - loss: 3.0479 - val_loss: 2.8970\n",
      "Number of images: 1025\n",
      "Presicion: 0.5846\n",
      "Recall: 0.5387\n",
      "F1 score: 0.5607\n",
      "F1 score: 0.560719094772363\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 145s 724ms/step - loss: 3.0283 - val_loss: 2.8950\n",
      "Number of images: 1025\n",
      "Presicion: 0.5838\n",
      "Recall: 0.5388\n",
      "F1 score: 0.5604\n",
      "F1 score: 0.560384431004803\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 143s 715ms/step - loss: 3.0500 - val_loss: 2.8846\n",
      "Number of images: 1025\n",
      "Presicion: 0.5831\n",
      "Recall: 0.538\n",
      "F1 score: 0.5596\n",
      "F1 score: 0.5596429082853324\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 147s 733ms/step - loss: 3.0673 - val_loss: 2.8789\n",
      "Number of images: 1025\n",
      "Presicion: 0.5807\n",
      "Recall: 0.539\n",
      "F1 score: 0.5591\n",
      "F1 score: 0.5590860510331671\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 144s 719ms/step - loss: 2.9979 - val_loss: 2.8702\n",
      "Number of images: 1025\n",
      "Presicion: 0.5837\n",
      "Recall: 0.5368\n",
      "F1 score: 0.5592\n",
      "F1 score: 0.5592285802922144\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 144s 718ms/step - loss: 3.0105 - val_loss: 2.8563\n",
      "Number of images: 1025\n",
      "Presicion: 0.5839\n",
      "Recall: 0.5373\n",
      "F1 score: 0.5597\n",
      "F1 score: 0.5596662394703522\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 146s 732ms/step - loss: 2.9911 - val_loss: 2.8572\n",
      "Number of images: 1025\n",
      "Presicion: 0.5788\n",
      "Recall: 0.5361\n",
      "F1 score: 0.5566\n",
      "F1 score: 0.5566205380650784\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 146s 728ms/step - loss: 3.0097 - val_loss: 2.8446\n",
      "Number of images: 1025\n",
      "Presicion: 0.582\n",
      "Recall: 0.5335\n",
      "F1 score: 0.5567\n",
      "F1 score: 0.5567135744453796\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 143s 717ms/step - loss: 2.9668 - val_loss: 2.8445\n",
      "Number of images: 1025\n",
      "Presicion: 0.5816\n",
      "Recall: 0.5354\n",
      "F1 score: 0.5575\n",
      "F1 score: 0.5575287817352051\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 148s 741ms/step - loss: 2.9868 - val_loss: 2.8363\n",
      "Number of images: 1025\n",
      "Presicion: 0.5794\n",
      "Recall: 0.5335\n",
      "F1 score: 0.5555\n",
      "F1 score: 0.5555311467156203\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 148s 739ms/step - loss: 2.9881 - val_loss: 2.8371\n",
      "Number of images: 1025\n",
      "Presicion: 0.578\n",
      "Recall: 0.5334\n",
      "F1 score: 0.5548\n",
      "F1 score: 0.5547888662886029\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 145s 727ms/step - loss: 2.9459 - val_loss: 2.8300\n",
      "Number of images: 1025\n",
      "Presicion: 0.5773\n",
      "Recall: 0.5341\n",
      "F1 score: 0.5548\n",
      "F1 score: 0.5548450668846655\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 144s 721ms/step - loss: 2.9693 - val_loss: 2.8184\n",
      "Number of images: 1025\n",
      "Presicion: 0.5774\n",
      "Recall: 0.5322\n",
      "F1 score: 0.5539\n",
      "F1 score: 0.5538871857052785\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 144s 718ms/step - loss: 2.9537 - val_loss: 2.8245\n",
      "Number of images: 1025\n",
      "Presicion: 0.5757\n",
      "Recall: 0.5339\n",
      "F1 score: 0.554\n",
      "F1 score: 0.5540124948440305\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 149s 747ms/step - loss: 2.9737 - val_loss: 2.8096\n",
      "Number of images: 1025\n",
      "Presicion: 0.5761\n",
      "Recall: 0.5328\n",
      "F1 score: 0.5536\n",
      "F1 score: 0.5536406900374968\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 145s 724ms/step - loss: 2.9463 - val_loss: 2.8037\n",
      "Number of images: 1025\n",
      "Presicion: 0.5737\n",
      "Recall: 0.5323\n",
      "F1 score: 0.5522\n",
      "F1 score: 0.5522136438532773\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 146s 730ms/step - loss: 2.9845 - val_loss: 2.8028\n",
      "Number of images: 1025\n",
      "Presicion: 0.5763\n",
      "Recall: 0.5323\n",
      "F1 score: 0.5534\n",
      "F1 score: 0.5534464359285097\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 146s 729ms/step - loss: 2.9222 - val_loss: 2.7991\n",
      "Number of images: 1025\n",
      "Presicion: 0.575\n",
      "Recall: 0.5317\n",
      "F1 score: 0.5525\n",
      "F1 score: 0.5525190986003062\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 146s 730ms/step - loss: 2.9343 - val_loss: 2.7965\n",
      "Number of images: 1025\n",
      "Presicion: 0.575\n",
      "Recall: 0.5317\n",
      "F1 score: 0.5525\n",
      "F1 score: 0.5525059994557318\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 149s 745ms/step - loss: 2.9251 - val_loss: 2.7942\n",
      "Number of images: 1025\n",
      "Presicion: 0.5729\n",
      "Recall: 0.5304\n",
      "F1 score: 0.5508\n",
      "F1 score: 0.5508096119387339\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 148s 739ms/step - loss: 2.9230 - val_loss: 2.7822\n",
      "Number of images: 1025\n",
      "Presicion: 0.5722\n",
      "Recall: 0.5292\n",
      "F1 score: 0.5499\n",
      "F1 score: 0.549878756159107\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 146s 731ms/step - loss: 2.8709 - val_loss: 2.7748\n",
      "Number of images: 1025\n",
      "Presicion: 0.5774\n",
      "Recall: 0.5282\n",
      "F1 score: 0.5517\n",
      "F1 score: 0.5516858056891225\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 146s 729ms/step - loss: 2.9093 - val_loss: 2.7711\n",
      "Number of images: 1025\n",
      "Presicion: 0.5778\n",
      "Recall: 0.5268\n",
      "F1 score: 0.5511\n",
      "F1 score: 0.5511346355109037\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 144s 718ms/step - loss: 2.8715 - val_loss: 2.7655\n",
      "Number of images: 1025\n",
      "Presicion: 0.5737\n",
      "Recall: 0.5284\n",
      "F1 score: 0.5501\n",
      "F1 score: 0.5501104299439626\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 148s 738ms/step - loss: 2.9209 - val_loss: 2.7651\n",
      "Number of images: 1025\n",
      "Presicion: 0.5755\n",
      "Recall: 0.5282\n",
      "F1 score: 0.5508\n",
      "F1 score: 0.5508189358733596\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 146s 728ms/step - loss: 2.9073 - val_loss: 2.7621\n",
      "Number of images: 1025\n",
      "Presicion: 0.5703\n",
      "Recall: 0.5288\n",
      "F1 score: 0.5488\n",
      "F1 score: 0.5487936250305046\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 146s 728ms/step - loss: 2.8312 - val_loss: 2.7555\n",
      "Number of images: 1025\n",
      "Presicion: 0.5726\n",
      "Recall: 0.5282\n",
      "F1 score: 0.5495\n",
      "F1 score: 0.5494894448188065\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 147s 737ms/step - loss: 2.8582 - val_loss: 2.7512\n",
      "Number of images: 1025\n",
      "Presicion: 0.575\n",
      "Recall: 0.5273\n",
      "F1 score: 0.5501\n",
      "F1 score: 0.5501107464773289\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 147s 733ms/step - loss: 2.8587 - val_loss: 2.7514\n",
      "Number of images: 1025\n",
      "Presicion: 0.5756\n",
      "Recall: 0.5272\n",
      "F1 score: 0.5503\n",
      "F1 score: 0.5503239045867238\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 146s 731ms/step - loss: 2.8531 - val_loss: 2.7468\n",
      "Number of images: 1025\n",
      "Presicion: 0.5744\n",
      "Recall: 0.5281\n",
      "F1 score: 0.5502\n",
      "F1 score: 0.5502497300621644\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 146s 729ms/step - loss: 2.8791 - val_loss: 2.7451\n",
      "Number of images: 1025\n",
      "Presicion: 0.5709\n",
      "Recall: 0.5281\n",
      "F1 score: 0.5487\n",
      "F1 score: 0.5486589670474044\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 146s 731ms/step - loss: 2.8650 - val_loss: 2.7361\n",
      "Number of images: 1025\n",
      "Presicion: 0.5752\n",
      "Recall: 0.5261\n",
      "F1 score: 0.5495\n",
      "F1 score: 0.5495196220898009\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 146s 732ms/step - loss: 2.8840 - val_loss: 2.7361\n",
      "Number of images: 1025\n",
      "Presicion: 0.5746\n",
      "Recall: 0.5267\n",
      "F1 score: 0.5496\n",
      "F1 score: 0.5495744621846644\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 146s 731ms/step - loss: 2.9147 - val_loss: 2.7320\n",
      "Number of images: 1025\n",
      "Presicion: 0.5707\n",
      "Recall: 0.5249\n",
      "F1 score: 0.5469\n",
      "F1 score: 0.5468542033295635\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 145s 725ms/step - loss: 2.8582 - val_loss: 2.7202\n",
      "Number of images: 1025\n",
      "Presicion: 0.5734\n",
      "Recall: 0.526\n",
      "F1 score: 0.5487\n",
      "F1 score: 0.5486617978091334\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 147s 735ms/step - loss: 2.8198 - val_loss: 2.7194\n",
      "Number of images: 1025\n",
      "Presicion: 0.5746\n",
      "Recall: 0.524\n",
      "F1 score: 0.5481\n",
      "F1 score: 0.5481246288712945\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 145s 725ms/step - loss: 2.8414 - val_loss: 2.7204\n",
      "Number of images: 1025\n",
      "Presicion: 0.5738\n",
      "Recall: 0.5246\n",
      "F1 score: 0.5481\n",
      "F1 score: 0.5480803653816929\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 148s 740ms/step - loss: 2.8408 - val_loss: 2.7205\n",
      "Number of images: 1025\n",
      "Presicion: 0.5732\n",
      "Recall: 0.525\n",
      "F1 score: 0.548\n",
      "F1 score: 0.5480384195844205\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 147s 733ms/step - loss: 2.8030 - val_loss: 2.7141\n",
      "Number of images: 1025\n",
      "Presicion: 0.5757\n",
      "Recall: 0.5226\n",
      "F1 score: 0.5479\n",
      "F1 score: 0.5478813580311938\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 143s 713ms/step - loss: 2.8095 - val_loss: 2.7161\n",
      "Number of images: 1025\n",
      "Presicion: 0.5715\n",
      "Recall: 0.5241\n",
      "F1 score: 0.5468\n",
      "F1 score: 0.5467949692355868\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 143s 717ms/step - loss: 2.7671 - val_loss: 2.7135\n",
      "Number of images: 1025\n",
      "Presicion: 0.5747\n",
      "Recall: 0.5216\n",
      "F1 score: 0.5469\n",
      "F1 score: 0.5468692946330788\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 145s 723ms/step - loss: 2.7992 - val_loss: 2.7065\n",
      "Number of images: 1025\n",
      "Presicion: 0.5761\n",
      "Recall: 0.5209\n",
      "F1 score: 0.5471\n",
      "F1 score: 0.5470875751491323\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 145s 725ms/step - loss: 2.8106 - val_loss: 2.7068\n",
      "Number of images: 1025\n",
      "Presicion: 0.5723\n",
      "Recall: 0.5218\n",
      "F1 score: 0.5459\n",
      "F1 score: 0.5459024646320826\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 146s 732ms/step - loss: 2.7828 - val_loss: 2.7072\n",
      "Number of images: 1025\n",
      "Presicion: 0.5711\n",
      "Recall: 0.5202\n",
      "F1 score: 0.5444\n",
      "F1 score: 0.5444324537890262\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 141s 706ms/step - loss: 2.7675 - val_loss: 2.7056\n",
      "Number of images: 1025\n",
      "Presicion: 0.5704\n",
      "Recall: 0.521\n",
      "F1 score: 0.5446\n",
      "F1 score: 0.5445763828802395\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 146s 729ms/step - loss: 2.7845 - val_loss: 2.7058\n",
      "Number of images: 1025\n",
      "Presicion: 0.568\n",
      "Recall: 0.5206\n",
      "F1 score: 0.5433\n",
      "F1 score: 0.5433036275183503\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 143s 717ms/step - loss: 2.7731 - val_loss: 2.7024\n",
      "Number of images: 1025\n",
      "Presicion: 0.5662\n",
      "Recall: 0.5212\n",
      "F1 score: 0.5428\n",
      "F1 score: 0.5428087720866523\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 144s 722ms/step - loss: 2.7643 - val_loss: 2.6985\n",
      "Number of images: 1025\n",
      "Presicion: 0.5718\n",
      "Recall: 0.5189\n",
      "F1 score: 0.544\n",
      "F1 score: 0.5440383153321036\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 148s 741ms/step - loss: 2.7319 - val_loss: 2.6902\n",
      "Number of images: 1025\n",
      "Presicion: 0.5716\n",
      "Recall: 0.5192\n",
      "F1 score: 0.5441\n",
      "F1 score: 0.5441324916179641\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 146s 728ms/step - loss: 2.7643 - val_loss: 2.6865\n",
      "Number of images: 1025\n",
      "Presicion: 0.5691\n",
      "Recall: 0.5165\n",
      "F1 score: 0.5415\n",
      "F1 score: 0.5415483827266053\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 147s 737ms/step - loss: 2.8053 - val_loss: 2.6824\n",
      "Number of images: 1025\n",
      "Presicion: 0.5678\n",
      "Recall: 0.5174\n",
      "F1 score: 0.5414\n",
      "F1 score: 0.5414286885513511\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 144s 721ms/step - loss: 2.7719 - val_loss: 2.6800\n",
      "Number of images: 1025\n",
      "Presicion: 0.5674\n",
      "Recall: 0.5175\n",
      "F1 score: 0.5413\n",
      "F1 score: 0.5413283538033724\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 146s 730ms/step - loss: 2.7632 - val_loss: 2.6748\n",
      "Number of images: 1025\n",
      "Presicion: 0.5679\n",
      "Recall: 0.5166\n",
      "F1 score: 0.5411\n",
      "F1 score: 0.5410622446241924\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 144s 721ms/step - loss: 2.7483 - val_loss: 2.6807\n",
      "Number of images: 1025\n",
      "Presicion: 0.5619\n",
      "Recall: 0.5183\n",
      "F1 score: 0.5392\n",
      "F1 score: 0.5392216845494181\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 147s 735ms/step - loss: 2.7472 - val_loss: 2.6752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 1025\n",
      "Presicion: 0.5655\n",
      "Recall: 0.5164\n",
      "F1 score: 0.5398\n",
      "F1 score: 0.5398167592752513\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 147s 737ms/step - loss: 2.7431 - val_loss: 2.6711\n",
      "Number of images: 1025\n",
      "Presicion: 0.5675\n",
      "Recall: 0.5167\n",
      "F1 score: 0.5409\n",
      "F1 score: 0.5409336809575662\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 145s 723ms/step - loss: 2.7354 - val_loss: 2.6711\n",
      "Number of images: 1025\n",
      "Presicion: 0.567\n",
      "Recall: 0.5153\n",
      "F1 score: 0.5399\n",
      "F1 score: 0.5399310806818743\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 144s 720ms/step - loss: 2.7520 - val_loss: 2.6689\n",
      "Number of images: 1025\n",
      "Presicion: 0.5625\n",
      "Recall: 0.5153\n",
      "F1 score: 0.5378\n",
      "F1 score: 0.5378252915618636\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 146s 729ms/step - loss: 2.7404 - val_loss: 2.6659\n",
      "Number of images: 1025\n",
      "Presicion: 0.5658\n",
      "Recall: 0.5147\n",
      "F1 score: 0.539\n",
      "F1 score: 0.5390438647921483\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 143s 714ms/step - loss: 2.7312 - val_loss: 2.6618\n",
      "Number of images: 1025\n",
      "Presicion: 0.5661\n",
      "Recall: 0.5143\n",
      "F1 score: 0.539\n",
      "F1 score: 0.5389701262811669\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 145s 723ms/step - loss: 2.7610 - val_loss: 2.6672\n",
      "Number of images: 1025\n",
      "Presicion: 0.5689\n",
      "Recall: 0.5144\n",
      "F1 score: 0.5403\n",
      "F1 score: 0.540292123403606\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 144s 719ms/step - loss: 2.7158 - val_loss: 2.6649\n",
      "Number of images: 1025\n",
      "Presicion: 0.5674\n",
      "Recall: 0.5135\n",
      "F1 score: 0.5391\n",
      "F1 score: 0.5391172484119711\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 146s 730ms/step - loss: 2.7389 - val_loss: 2.6597\n",
      "Number of images: 1025\n",
      "Presicion: 0.5641\n",
      "Recall: 0.5134\n",
      "F1 score: 0.5375\n",
      "F1 score: 0.5375429698999876\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 143s 716ms/step - loss: 2.7259 - val_loss: 2.6527\n",
      "Number of images: 1025\n",
      "Presicion: 0.5661\n",
      "Recall: 0.5131\n",
      "F1 score: 0.5383\n",
      "F1 score: 0.5382792584950906\n"
     ]
    }
   ],
   "source": [
    "lr_list = [0.01, 0.001, 0.0001, 0.00001]\n",
    "\n",
    "for lr in lr_list:\n",
    "    # 1: Build the Keras model.\n",
    "    K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "    print('TRAINING MODEL WITH LEARNING RATE:', lr)\n",
    "    \n",
    "    model = ssd_300(image_size=(img_height, img_width, img_channels),\n",
    "                n_classes=n_classes,\n",
    "                mode='training',\n",
    "                scale_factor=1.5,\n",
    "                scales=scales,\n",
    "                aspect_ratios_per_layer=aspect_ratios,\n",
    "                two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                steps=steps,\n",
    "                offsets=offsets,\n",
    "                clip_boxes=clip_boxes,\n",
    "                variances=variances,\n",
    "                normalize_coords=normalize_coords,\n",
    "                subtract_mean=mean_color,\n",
    "                divide_by_stddev=divide_by_stddev,\n",
    "                swap_channels=swap_channels)\n",
    "\n",
    "    adam = Adam(lr=lr)\n",
    "    ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "    model.load_weights('/home/aldo/Documents/weights/light_models/PASCAL/shufflenet_v2_ssdlayers_light_relu6_se_no_shuffle_factor_1.5.h5', by_name=True)\n",
    "    model.compile(optimizer=adam, loss=ssd_loss.compute_loss)\n",
    "    \n",
    "    # Define model callbacks.\n",
    "    main_path = '/home/aldo/Downloads/noshufflese/'\n",
    "    # TODO: Set the filepath under which you want to save the model.\n",
    "\n",
    "    csv_logger = CSVLogger(filename=main_path + 'model_' + str(lr) + '.csv',\n",
    "                           separator=',',\n",
    "                           append=True)\n",
    "\n",
    "\n",
    "    f1_callback = f1_call(0.20, \n",
    "                           0.45, \n",
    "                           200, \n",
    "                           normalize_coords, \n",
    "                           img_height, \n",
    "                           img_width, \n",
    "                           (1, 2268, 14),\n",
    "                           main_path + 'f1_' + str(lr) + '.csv',\n",
    "                           main_path + 'model.h5',\n",
    "                           label_csv='/home/aldo/Documents/data-cic/preprocess_data/PASCAL_val.csv',\n",
    "                           path_img='/home/aldo/Documents/data-cic/PASCAL',\n",
    "                           verborse=True)\n",
    "\n",
    "\n",
    "    callbacks = [csv_logger,\n",
    "                 f1_callback]\n",
    "    \n",
    "    initial_epoch   = 0\n",
    "    final_epoch     = 100\n",
    "    steps_per_epoch = 200\n",
    "\n",
    "    history = model.fit_generator(generator=train_generator,\n",
    "                                  steps_per_epoch=steps_per_epoch,\n",
    "                                  epochs=final_epoch,\n",
    "                                  callbacks=callbacks,\n",
    "                                  validation_data=val_generator,\n",
    "                                  validation_steps=ceil(val_dataset_size/batch_size),\n",
    "                                  initial_epoch=initial_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fca4b0a0fd0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "main_path = '/home/aldo/Downloads/noshufflese/'\n",
    "mob_01 = pd.read_csv(main_path + 'model_0.01.csv')\n",
    "mob_001 = pd.read_csv(main_path + 'model_0.001.csv')\n",
    "mob_0001 = pd.read_csv(main_path + 'model_0.0001.csv')\n",
    "mob_00001 = pd.read_csv(main_path + 'model_1e-05.csv')\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "# ax.plot(mob_01['epoch'][10:], mob_01['val_loss'][10:], color='r')\n",
    "ax.plot(mob_001['epoch'][10:], mob_001['val_loss'][10:], color='b')\n",
    "ax.plot(mob_0001['epoch'][10:], mob_0001['val_loss'][10:], color='g')\n",
    "ax.plot(mob_00001['epoch'][10:], mob_00001['val_loss'][10:], color='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fca4b07cd68>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mob_01_f1 = pd.read_csv(main_path + 'f1_0.01.csv')\n",
    "mob_001_f1 = pd.read_csv(main_path + 'f1_0.001.csv')\n",
    "mob_0001_f1 = pd.read_csv(main_path + 'f1_0.0001.csv')\n",
    "mob_00001_f1 = pd.read_csv(main_path + 'f1_1e-05.csv')\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(mob_01_f1['epoch'], mob_01_f1['f1 score'], color='r')\n",
    "ax.plot(mob_001_f1['epoch'], mob_001_f1['f1 score'], color='b')\n",
    "ax.plot(mob_0001_f1['epoch'], mob_0001_f1['f1 score'], color='g')\n",
    "ax.plot(mob_00001_f1['epoch'], mob_00001_f1['f1 score'], color='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING MODEL WITH FACTOR: 1.5\n",
      "Epoch 1/600\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 26s 2s/step - loss: 3.7195\n",
      "Epoch 2/600\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 15s 1s/step - loss: 3.6074\n",
      "Epoch 3/600\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 935ms/step - loss: 3.4132\n",
      "Epoch 4/600\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 854ms/step - loss: 3.2123\n",
      "Epoch 5/600\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 923ms/step - loss: 3.4476\n",
      "Epoch 6/600\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 824ms/step - loss: 3.1075\n",
      "Epoch 7/600\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 883ms/step - loss: 3.2229\n",
      "Epoch 8/600\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 883ms/step - loss: 3.1118\n",
      "Epoch 9/600\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 855ms/step - loss: 3.0840\n",
      "Epoch 10/600\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 838ms/step - loss: 2.9994\n",
      "Epoch 11/600\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 879ms/step - loss: 2.9057\n",
      "Epoch 12/600\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 838ms/step - loss: 2.9133\n",
      "Epoch 13/600\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 853ms/step - loss: 2.9617\n",
      "Epoch 14/600\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 851ms/step - loss: 2.7797\n",
      "Epoch 15/600\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 883ms/step - loss: 2.9571\n",
      "Epoch 16/600\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 15s 991ms/step - loss: 2.9085\n",
      "Epoch 17/600\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 15s 1s/step - loss: 2.7807\n",
      "Epoch 18/600\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 868ms/step - loss: 2.8089\n",
      "Epoch 19/600\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 819ms/step - loss: 2.7223\n",
      "Epoch 20/600\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 810ms/step - loss: 2.6781\n",
      "Epoch 21/600\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 883ms/step - loss: 2.8751\n",
      "Epoch 22/600\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 860ms/step - loss: 2.7602\n",
      "Epoch 23/600\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 829ms/step - loss: 2.7183\n",
      "Epoch 24/600\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 830ms/step - loss: 2.6414\n",
      "Epoch 25/600\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 882ms/step - loss: 2.6722\n",
      "Epoch 26/600\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 894ms/step - loss: 2.6787\n",
      "Epoch 27/600\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 862ms/step - loss: 2.6289\n",
      "Epoch 28/600\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 917ms/step - loss: 2.5990\n",
      "Epoch 29/600\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 873ms/step - loss: 2.5895\n",
      "Epoch 30/600\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 864ms/step - loss: 2.6191\n",
      "Epoch 31/600\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 860ms/step - loss: 2.6941\n",
      "Epoch 32/600\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 887ms/step - loss: 2.6555\n",
      "Epoch 33/600\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 935ms/step - loss: 2.6127\n",
      "Epoch 34/600\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 897ms/step - loss: 2.6546\n",
      "Epoch 35/600\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 843ms/step - loss: 2.6719\n",
      "Epoch 36/600\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 895ms/step - loss: 2.7558\n",
      "Epoch 37/600\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 827ms/step - loss: 2.6474\n",
      "Epoch 38/600\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 844ms/step - loss: 2.4682\n",
      "Epoch 39/600\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 861ms/step - loss: 2.5454\n",
      "Epoch 40/600\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 909ms/step - loss: 2.6215\n",
      "Epoch 41/600\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 928ms/step - loss: 2.7022\n",
      "Epoch 42/600\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 890ms/step - loss: 2.6071\n",
      "Epoch 43/600\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 860ms/step - loss: 2.4929\n",
      "Epoch 44/600\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 812ms/step - loss: 2.5744\n",
      "Epoch 45/600\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 827ms/step - loss: 2.4758\n",
      "Epoch 46/600\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 866ms/step - loss: 2.5382\n",
      "Epoch 47/600\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 899ms/step - loss: 2.4896\n",
      "Epoch 48/600\n",
      "\n",
      "Epoch 00048: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 881ms/step - loss: 2.4304\n",
      "Epoch 49/600\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 801ms/step - loss: 2.4807\n",
      "Epoch 50/600\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 840ms/step - loss: 2.4957\n",
      "Epoch 51/600\n",
      "\n",
      "Epoch 00051: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 866ms/step - loss: 2.4052\n",
      "Epoch 52/600\n",
      "\n",
      "Epoch 00052: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 787ms/step - loss: 2.4601\n",
      "Epoch 53/600\n",
      "\n",
      "Epoch 00053: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 853ms/step - loss: 2.4388\n",
      "Epoch 54/600\n",
      "\n",
      "Epoch 00054: LearningRateScheduler setting learning rate to 0.001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 13s 854ms/step - loss: 2.4030\n",
      "Epoch 55/600\n",
      "\n",
      "Epoch 00055: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 923ms/step - loss: 2.4692\n",
      "Epoch 56/600\n",
      "\n",
      "Epoch 00056: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 877ms/step - loss: 2.4854\n",
      "Epoch 57/600\n",
      "\n",
      "Epoch 00057: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 864ms/step - loss: 2.5028\n",
      "Epoch 58/600\n",
      "\n",
      "Epoch 00058: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 894ms/step - loss: 2.4291\n",
      "Epoch 59/600\n",
      "\n",
      "Epoch 00059: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 927ms/step - loss: 2.4813\n",
      "Epoch 60/600\n",
      "\n",
      "Epoch 00060: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 894ms/step - loss: 2.4113\n",
      "Epoch 61/600\n",
      "\n",
      "Epoch 00061: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 872ms/step - loss: 2.3809\n",
      "Epoch 62/600\n",
      "\n",
      "Epoch 00062: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 817ms/step - loss: 2.3319\n",
      "Epoch 63/600\n",
      "\n",
      "Epoch 00063: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 849ms/step - loss: 2.4363\n",
      "Epoch 64/600\n",
      "\n",
      "Epoch 00064: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 863ms/step - loss: 2.3452\n",
      "Epoch 65/600\n",
      "\n",
      "Epoch 00065: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 905ms/step - loss: 2.3277\n",
      "Epoch 66/600\n",
      "\n",
      "Epoch 00066: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 921ms/step - loss: 2.3894\n",
      "Epoch 67/600\n",
      "\n",
      "Epoch 00067: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 873ms/step - loss: 2.3972\n",
      "Epoch 68/600\n",
      "\n",
      "Epoch 00068: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 916ms/step - loss: 2.4955\n",
      "Epoch 69/600\n",
      "\n",
      "Epoch 00069: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 863ms/step - loss: 2.3936\n",
      "Epoch 70/600\n",
      "\n",
      "Epoch 00070: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 889ms/step - loss: 2.3603\n",
      "Epoch 71/600\n",
      "\n",
      "Epoch 00071: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 943ms/step - loss: 2.4710\n",
      "Epoch 72/600\n",
      "\n",
      "Epoch 00072: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 834ms/step - loss: 2.2634\n",
      "Epoch 73/600\n",
      "\n",
      "Epoch 00073: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 887ms/step - loss: 2.3957\n",
      "Epoch 74/600\n",
      "\n",
      "Epoch 00074: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 865ms/step - loss: 2.3851\n",
      "Epoch 75/600\n",
      "\n",
      "Epoch 00075: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 866ms/step - loss: 2.3655\n",
      "Epoch 76/600\n",
      "\n",
      "Epoch 00076: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 914ms/step - loss: 2.2922\n",
      "Epoch 77/600\n",
      "\n",
      "Epoch 00077: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 875ms/step - loss: 2.2588\n",
      "Epoch 78/600\n",
      "\n",
      "Epoch 00078: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 842ms/step - loss: 2.2584\n",
      "Epoch 79/600\n",
      "\n",
      "Epoch 00079: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 891ms/step - loss: 2.4536\n",
      "Epoch 80/600\n",
      "\n",
      "Epoch 00080: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 922ms/step - loss: 2.2915\n",
      "Epoch 81/600\n",
      "\n",
      "Epoch 00081: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 881ms/step - loss: 2.1913\n",
      "Epoch 82/600\n",
      "\n",
      "Epoch 00082: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 856ms/step - loss: 2.2142\n",
      "Epoch 83/600\n",
      "\n",
      "Epoch 00083: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 922ms/step - loss: 2.3258\n",
      "Epoch 84/600\n",
      "\n",
      "Epoch 00084: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 864ms/step - loss: 2.3037\n",
      "Epoch 85/600\n",
      "\n",
      "Epoch 00085: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 834ms/step - loss: 2.2139\n",
      "Epoch 86/600\n",
      "\n",
      "Epoch 00086: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 862ms/step - loss: 2.3276\n",
      "Epoch 87/600\n",
      "\n",
      "Epoch 00087: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 905ms/step - loss: 2.4018\n",
      "Epoch 88/600\n",
      "\n",
      "Epoch 00088: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 855ms/step - loss: 2.2919\n",
      "Epoch 89/600\n",
      "\n",
      "Epoch 00089: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 856ms/step - loss: 2.3277\n",
      "Epoch 90/600\n",
      "\n",
      "Epoch 00090: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 875ms/step - loss: 2.2335\n",
      "Epoch 91/600\n",
      "\n",
      "Epoch 00091: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 856ms/step - loss: 2.3775\n",
      "Epoch 92/600\n",
      "\n",
      "Epoch 00092: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 887ms/step - loss: 2.2363\n",
      "Epoch 93/600\n",
      "\n",
      "Epoch 00093: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 933ms/step - loss: 2.2447\n",
      "Epoch 94/600\n",
      "\n",
      "Epoch 00094: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 885ms/step - loss: 2.1337\n",
      "Epoch 95/600\n",
      "\n",
      "Epoch 00095: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 923ms/step - loss: 2.2734\n",
      "Epoch 96/600\n",
      "\n",
      "Epoch 00096: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 876ms/step - loss: 2.3199\n",
      "Epoch 97/600\n",
      "\n",
      "Epoch 00097: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 883ms/step - loss: 2.3388\n",
      "Epoch 98/600\n",
      "\n",
      "Epoch 00098: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 927ms/step - loss: 2.3334\n",
      "Epoch 99/600\n",
      "\n",
      "Epoch 00099: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 891ms/step - loss: 2.1982\n",
      "Epoch 100/600\n",
      "\n",
      "Epoch 00100: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 827ms/step - loss: 2.1608\n",
      "Epoch 101/600\n",
      "\n",
      "Epoch 00101: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 886ms/step - loss: 2.2418\n",
      "Epoch 102/600\n",
      "\n",
      "Epoch 00102: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 806ms/step - loss: 2.2161\n",
      "Epoch 103/600\n",
      "\n",
      "Epoch 00103: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 849ms/step - loss: 2.2349\n",
      "Epoch 104/600\n",
      "\n",
      "Epoch 00104: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 832ms/step - loss: 2.1216\n",
      "Epoch 105/600\n",
      "\n",
      "Epoch 00105: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 806ms/step - loss: 2.1902\n",
      "Epoch 106/600\n",
      "\n",
      "Epoch 00106: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 902ms/step - loss: 2.2430\n",
      "Epoch 107/600\n",
      "\n",
      "Epoch 00107: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 853ms/step - loss: 2.2720\n",
      "Epoch 108/600\n",
      "\n",
      "Epoch 00108: LearningRateScheduler setting learning rate to 0.001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 13s 893ms/step - loss: 2.2279\n",
      "Epoch 109/600\n",
      "\n",
      "Epoch 00109: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 803ms/step - loss: 2.2238\n",
      "Epoch 110/600\n",
      "\n",
      "Epoch 00110: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 862ms/step - loss: 2.3137\n",
      "Epoch 111/600\n",
      "\n",
      "Epoch 00111: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 833ms/step - loss: 2.1525\n",
      "Epoch 112/600\n",
      "\n",
      "Epoch 00112: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 878ms/step - loss: 2.2117\n",
      "Epoch 113/600\n",
      "\n",
      "Epoch 00113: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 925ms/step - loss: 2.1546\n",
      "Epoch 114/600\n",
      "\n",
      "Epoch 00114: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 881ms/step - loss: 2.1932\n",
      "Epoch 115/600\n",
      "\n",
      "Epoch 00115: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 886ms/step - loss: 2.1126\n",
      "Epoch 116/600\n",
      "\n",
      "Epoch 00116: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 821ms/step - loss: 2.1479\n",
      "Epoch 117/600\n",
      "\n",
      "Epoch 00117: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 843ms/step - loss: 2.1924\n",
      "Epoch 118/600\n",
      "\n",
      "Epoch 00118: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 834ms/step - loss: 2.0848\n",
      "Epoch 119/600\n",
      "\n",
      "Epoch 00119: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 845ms/step - loss: 2.1285\n",
      "Epoch 120/600\n",
      "\n",
      "Epoch 00120: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 955ms/step - loss: 2.2574\n",
      "Epoch 121/600\n",
      "\n",
      "Epoch 00121: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 893ms/step - loss: 2.1813\n",
      "Epoch 122/600\n",
      "\n",
      "Epoch 00122: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 864ms/step - loss: 2.1404\n",
      "Epoch 123/600\n",
      "\n",
      "Epoch 00123: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 838ms/step - loss: 2.1355\n",
      "Epoch 124/600\n",
      "\n",
      "Epoch 00124: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 906ms/step - loss: 2.0459\n",
      "Epoch 125/600\n",
      "\n",
      "Epoch 00125: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 861ms/step - loss: 2.2337\n",
      "Epoch 126/600\n",
      "\n",
      "Epoch 00126: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 807ms/step - loss: 2.0775\n",
      "Epoch 127/600\n",
      "\n",
      "Epoch 00127: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 886ms/step - loss: 2.1726\n",
      "Epoch 128/600\n",
      "\n",
      "Epoch 00128: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 893ms/step - loss: 2.2007\n",
      "Epoch 129/600\n",
      "\n",
      "Epoch 00129: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 846ms/step - loss: 2.0833\n",
      "Epoch 130/600\n",
      "\n",
      "Epoch 00130: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 889ms/step - loss: 2.1302\n",
      "Epoch 131/600\n",
      "\n",
      "Epoch 00131: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 883ms/step - loss: 2.1392\n",
      "Epoch 132/600\n",
      "\n",
      "Epoch 00132: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 827ms/step - loss: 2.0990\n",
      "Epoch 133/600\n",
      "\n",
      "Epoch 00133: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 881ms/step - loss: 2.0813\n",
      "Epoch 134/600\n",
      "\n",
      "Epoch 00134: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 900ms/step - loss: 2.1652\n",
      "Epoch 135/600\n",
      "\n",
      "Epoch 00135: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 862ms/step - loss: 2.0872\n",
      "Epoch 136/600\n",
      "\n",
      "Epoch 00136: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 903ms/step - loss: 2.0685\n",
      "Epoch 137/600\n",
      "\n",
      "Epoch 00137: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 930ms/step - loss: 2.0807\n",
      "Epoch 138/600\n",
      "\n",
      "Epoch 00138: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 889ms/step - loss: 2.1584\n",
      "Epoch 139/600\n",
      "\n",
      "Epoch 00139: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 887ms/step - loss: 2.1286\n",
      "Epoch 140/600\n",
      "\n",
      "Epoch 00140: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 894ms/step - loss: 2.1494\n",
      "Epoch 141/600\n",
      "\n",
      "Epoch 00141: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 921ms/step - loss: 2.1756\n",
      "Epoch 142/600\n",
      "\n",
      "Epoch 00142: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 960ms/step - loss: 2.1895\n",
      "Epoch 143/600\n",
      "\n",
      "Epoch 00143: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 907ms/step - loss: 2.0220\n",
      "Epoch 144/600\n",
      "\n",
      "Epoch 00144: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 921ms/step - loss: 2.0926\n",
      "Epoch 145/600\n",
      "\n",
      "Epoch 00145: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 880ms/step - loss: 2.0433\n",
      "Epoch 146/600\n",
      "\n",
      "Epoch 00146: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 881ms/step - loss: 2.0946\n",
      "Epoch 147/600\n",
      "\n",
      "Epoch 00147: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 879ms/step - loss: 2.1145\n",
      "Epoch 148/600\n",
      "\n",
      "Epoch 00148: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 898ms/step - loss: 2.0181\n",
      "Epoch 149/600\n",
      "\n",
      "Epoch 00149: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 917ms/step - loss: 2.1393\n",
      "Epoch 150/600\n",
      "\n",
      "Epoch 00150: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 934ms/step - loss: 2.0070\n",
      "Epoch 151/600\n",
      "\n",
      "Epoch 00151: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 868ms/step - loss: 2.0628\n",
      "Epoch 152/600\n",
      "\n",
      "Epoch 00152: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 849ms/step - loss: 2.0354\n",
      "Epoch 153/600\n",
      "\n",
      "Epoch 00153: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 927ms/step - loss: 2.1865\n",
      "Epoch 154/600\n",
      "\n",
      "Epoch 00154: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 881ms/step - loss: 2.0468\n",
      "Epoch 155/600\n",
      "\n",
      "Epoch 00155: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 896ms/step - loss: 2.1098\n",
      "Epoch 156/600\n",
      "\n",
      "Epoch 00156: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 832ms/step - loss: 2.0690\n",
      "Epoch 157/600\n",
      "\n",
      "Epoch 00157: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 870ms/step - loss: 2.0473\n",
      "Epoch 158/600\n",
      "\n",
      "Epoch 00158: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 15s 982ms/step - loss: 2.1815\n",
      "Epoch 159/600\n",
      "\n",
      "Epoch 00159: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 841ms/step - loss: 2.0156\n",
      "Epoch 160/600\n",
      "\n",
      "Epoch 00160: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 910ms/step - loss: 2.0570\n",
      "Epoch 161/600\n",
      "\n",
      "Epoch 00161: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 826ms/step - loss: 1.9842\n",
      "Epoch 162/600\n",
      "\n",
      "Epoch 00162: LearningRateScheduler setting learning rate to 0.001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 13s 852ms/step - loss: 2.0109\n",
      "Epoch 163/600\n",
      "\n",
      "Epoch 00163: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 817ms/step - loss: 1.9224\n",
      "Epoch 164/600\n",
      "\n",
      "Epoch 00164: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 824ms/step - loss: 1.9545\n",
      "Epoch 165/600\n",
      "\n",
      "Epoch 00165: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 874ms/step - loss: 1.9929\n",
      "Epoch 166/600\n",
      "\n",
      "Epoch 00166: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 877ms/step - loss: 2.0980\n",
      "Epoch 167/600\n",
      "\n",
      "Epoch 00167: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 889ms/step - loss: 1.9924\n",
      "Epoch 168/600\n",
      "\n",
      "Epoch 00168: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 866ms/step - loss: 1.9605\n",
      "Epoch 169/600\n",
      "\n",
      "Epoch 00169: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 829ms/step - loss: 1.9103\n",
      "Epoch 170/600\n",
      "\n",
      "Epoch 00170: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 893ms/step - loss: 1.9533\n",
      "Epoch 171/600\n",
      "\n",
      "Epoch 00171: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 865ms/step - loss: 1.9870\n",
      "Epoch 172/600\n",
      "\n",
      "Epoch 00172: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 899ms/step - loss: 2.1295\n",
      "Epoch 173/600\n",
      "\n",
      "Epoch 00173: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 835ms/step - loss: 1.9344\n",
      "Epoch 174/600\n",
      "\n",
      "Epoch 00174: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 864ms/step - loss: 1.9760\n",
      "Epoch 175/600\n",
      "\n",
      "Epoch 00175: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 877ms/step - loss: 2.0309\n",
      "Epoch 176/600\n",
      "\n",
      "Epoch 00176: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 871ms/step - loss: 1.9333\n",
      "Epoch 177/600\n",
      "\n",
      "Epoch 00177: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 810ms/step - loss: 1.8892\n",
      "Epoch 178/600\n",
      "\n",
      "Epoch 00178: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 928ms/step - loss: 2.0667\n",
      "Epoch 179/600\n",
      "\n",
      "Epoch 00179: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 866ms/step - loss: 2.0355\n",
      "Epoch 180/600\n",
      "\n",
      "Epoch 00180: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 892ms/step - loss: 1.9894\n",
      "Epoch 181/600\n",
      "\n",
      "Epoch 00181: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 836ms/step - loss: 1.9645\n",
      "Epoch 182/600\n",
      "\n",
      "Epoch 00182: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 858ms/step - loss: 2.0386\n",
      "Epoch 183/600\n",
      "\n",
      "Epoch 00183: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 838ms/step - loss: 1.9280\n",
      "Epoch 184/600\n",
      "\n",
      "Epoch 00184: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 888ms/step - loss: 2.1263\n",
      "Epoch 185/600\n",
      "\n",
      "Epoch 00185: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 851ms/step - loss: 1.9879\n",
      "Epoch 186/600\n",
      "\n",
      "Epoch 00186: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 857ms/step - loss: 1.9920\n",
      "Epoch 187/600\n",
      "\n",
      "Epoch 00187: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 889ms/step - loss: 1.9262\n",
      "Epoch 188/600\n",
      "\n",
      "Epoch 00188: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 918ms/step - loss: 2.0074\n",
      "Epoch 189/600\n",
      "\n",
      "Epoch 00189: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 914ms/step - loss: 2.0621\n",
      "Epoch 190/600\n",
      "\n",
      "Epoch 00190: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 804ms/step - loss: 1.8121\n",
      "Epoch 191/600\n",
      "\n",
      "Epoch 00191: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 841ms/step - loss: 1.8441\n",
      "Epoch 192/600\n",
      "\n",
      "Epoch 00192: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 899ms/step - loss: 2.1134\n",
      "Epoch 193/600\n",
      "\n",
      "Epoch 00193: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 884ms/step - loss: 2.1495\n",
      "Epoch 194/600\n",
      "\n",
      "Epoch 00194: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 866ms/step - loss: 1.9945\n",
      "Epoch 195/600\n",
      "\n",
      "Epoch 00195: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 846ms/step - loss: 2.0336\n",
      "Epoch 196/600\n",
      "\n",
      "Epoch 00196: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 820ms/step - loss: 1.9415\n",
      "Epoch 197/600\n",
      "\n",
      "Epoch 00197: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 862ms/step - loss: 1.8216\n",
      "Epoch 198/600\n",
      "\n",
      "Epoch 00198: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 870ms/step - loss: 1.9241\n",
      "Epoch 199/600\n",
      "\n",
      "Epoch 00199: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 913ms/step - loss: 2.0166\n",
      "Epoch 200/600\n",
      "\n",
      "Epoch 00200: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 860ms/step - loss: 2.0270\n",
      "Epoch 201/600\n",
      "\n",
      "Epoch 00201: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 850ms/step - loss: 1.8937\n",
      "Epoch 202/600\n",
      "\n",
      "Epoch 00202: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 829ms/step - loss: 1.9153\n",
      "Epoch 203/600\n",
      "\n",
      "Epoch 00203: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 831ms/step - loss: 1.9179\n",
      "Epoch 204/600\n",
      "\n",
      "Epoch 00204: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 871ms/step - loss: 1.8405\n",
      "Epoch 205/600\n",
      "\n",
      "Epoch 00205: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 885ms/step - loss: 2.0474\n",
      "Epoch 206/600\n",
      "\n",
      "Epoch 00206: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 864ms/step - loss: 1.9091\n",
      "Epoch 207/600\n",
      "\n",
      "Epoch 00207: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 903ms/step - loss: 2.0717\n",
      "Epoch 208/600\n",
      "\n",
      "Epoch 00208: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 916ms/step - loss: 2.0719\n",
      "Epoch 209/600\n",
      "\n",
      "Epoch 00209: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 838ms/step - loss: 1.9499\n",
      "Epoch 210/600\n",
      "\n",
      "Epoch 00210: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 878ms/step - loss: 1.9490\n",
      "Epoch 211/600\n",
      "\n",
      "Epoch 00211: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 842ms/step - loss: 2.0469\n",
      "Epoch 212/600\n",
      "\n",
      "Epoch 00212: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 833ms/step - loss: 1.9004\n",
      "Epoch 213/600\n",
      "\n",
      "Epoch 00213: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 815ms/step - loss: 1.8106\n",
      "Epoch 214/600\n",
      "\n",
      "Epoch 00214: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 863ms/step - loss: 1.8984\n",
      "Epoch 215/600\n",
      "\n",
      "Epoch 00215: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 878ms/step - loss: 1.9005\n",
      "Epoch 216/600\n",
      "\n",
      "Epoch 00216: LearningRateScheduler setting learning rate to 0.001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 13s 842ms/step - loss: 1.8324\n",
      "Epoch 217/600\n",
      "\n",
      "Epoch 00217: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 867ms/step - loss: 1.9157\n",
      "Epoch 218/600\n",
      "\n",
      "Epoch 00218: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 871ms/step - loss: 1.9464\n",
      "Epoch 219/600\n",
      "\n",
      "Epoch 00219: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 809ms/step - loss: 1.9788\n",
      "Epoch 220/600\n",
      "\n",
      "Epoch 00220: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 799ms/step - loss: 1.7974\n",
      "Epoch 221/600\n",
      "\n",
      "Epoch 00221: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 771ms/step - loss: 1.8191\n",
      "Epoch 222/600\n",
      "\n",
      "Epoch 00222: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 830ms/step - loss: 1.8810\n",
      "Epoch 223/600\n",
      "\n",
      "Epoch 00223: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 910ms/step - loss: 1.9020\n",
      "Epoch 224/600\n",
      "\n",
      "Epoch 00224: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 849ms/step - loss: 1.8689\n",
      "Epoch 225/600\n",
      "\n",
      "Epoch 00225: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 887ms/step - loss: 1.8248\n",
      "Epoch 226/600\n",
      "\n",
      "Epoch 00226: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 864ms/step - loss: 1.7421\n",
      "Epoch 227/600\n",
      "\n",
      "Epoch 00227: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 877ms/step - loss: 1.8663\n",
      "Epoch 228/600\n",
      "\n",
      "Epoch 00228: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 890ms/step - loss: 1.8734\n",
      "Epoch 229/600\n",
      "\n",
      "Epoch 00229: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 892ms/step - loss: 1.9334\n",
      "Epoch 230/600\n",
      "\n",
      "Epoch 00230: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 908ms/step - loss: 1.8236\n",
      "Epoch 231/600\n",
      "\n",
      "Epoch 00231: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 872ms/step - loss: 1.9087\n",
      "Epoch 232/600\n",
      "\n",
      "Epoch 00232: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 887ms/step - loss: 1.8957\n",
      "Epoch 233/600\n",
      "\n",
      "Epoch 00233: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 902ms/step - loss: 1.8490\n",
      "Epoch 234/600\n",
      "\n",
      "Epoch 00234: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 864ms/step - loss: 1.9984\n",
      "Epoch 235/600\n",
      "\n",
      "Epoch 00235: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 870ms/step - loss: 1.8349\n",
      "Epoch 236/600\n",
      "\n",
      "Epoch 00236: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 916ms/step - loss: 1.9275\n",
      "Epoch 237/600\n",
      "\n",
      "Epoch 00237: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 901ms/step - loss: 1.9159\n",
      "Epoch 238/600\n",
      "\n",
      "Epoch 00238: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 826ms/step - loss: 1.9186\n",
      "Epoch 239/600\n",
      "\n",
      "Epoch 00239: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 914ms/step - loss: 1.8701\n",
      "Epoch 240/600\n",
      "\n",
      "Epoch 00240: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 917ms/step - loss: 1.9983\n",
      "Epoch 241/600\n",
      "\n",
      "Epoch 00241: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 827ms/step - loss: 1.8548\n",
      "Epoch 242/600\n",
      "\n",
      "Epoch 00242: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 874ms/step - loss: 1.8815\n",
      "Epoch 243/600\n",
      "\n",
      "Epoch 00243: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 877ms/step - loss: 1.9472\n",
      "Epoch 244/600\n",
      "\n",
      "Epoch 00244: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 873ms/step - loss: 1.9636\n",
      "Epoch 245/600\n",
      "\n",
      "Epoch 00245: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 854ms/step - loss: 1.7824\n",
      "Epoch 246/600\n",
      "\n",
      "Epoch 00246: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 865ms/step - loss: 1.9703\n",
      "Epoch 247/600\n",
      "\n",
      "Epoch 00247: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 935ms/step - loss: 1.9317\n",
      "Epoch 248/600\n",
      "\n",
      "Epoch 00248: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 831ms/step - loss: 1.7565\n",
      "Epoch 249/600\n",
      "\n",
      "Epoch 00249: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 804ms/step - loss: 1.8244\n",
      "Epoch 250/600\n",
      "\n",
      "Epoch 00250: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 868ms/step - loss: 1.8297\n",
      "Epoch 251/600\n",
      "\n",
      "Epoch 00251: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 836ms/step - loss: 1.8944\n",
      "Epoch 252/600\n",
      "\n",
      "Epoch 00252: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 888ms/step - loss: 1.8219\n",
      "Epoch 253/600\n",
      "\n",
      "Epoch 00253: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 883ms/step - loss: 1.9672\n",
      "Epoch 254/600\n",
      "\n",
      "Epoch 00254: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 891ms/step - loss: 1.9383\n",
      "Epoch 255/600\n",
      "\n",
      "Epoch 00255: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 877ms/step - loss: 1.7886\n",
      "Epoch 256/600\n",
      "\n",
      "Epoch 00256: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 869ms/step - loss: 1.8713\n",
      "Epoch 257/600\n",
      "\n",
      "Epoch 00257: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 879ms/step - loss: 1.9470\n",
      "Epoch 258/600\n",
      "\n",
      "Epoch 00258: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 807ms/step - loss: 1.8705\n",
      "Epoch 259/600\n",
      "\n",
      "Epoch 00259: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 854ms/step - loss: 1.8844\n",
      "Epoch 260/600\n",
      "\n",
      "Epoch 00260: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 884ms/step - loss: 1.9189\n",
      "Epoch 261/600\n",
      "\n",
      "Epoch 00261: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 848ms/step - loss: 1.8991\n",
      "Epoch 262/600\n",
      "\n",
      "Epoch 00262: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 841ms/step - loss: 1.8242\n",
      "Epoch 263/600\n",
      "\n",
      "Epoch 00263: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 870ms/step - loss: 1.8608\n",
      "Epoch 264/600\n",
      "\n",
      "Epoch 00264: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 835ms/step - loss: 1.8460\n",
      "Epoch 265/600\n",
      "\n",
      "Epoch 00265: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 856ms/step - loss: 1.7660\n",
      "Epoch 266/600\n",
      "\n",
      "Epoch 00266: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 886ms/step - loss: 1.9234\n",
      "Epoch 267/600\n",
      "\n",
      "Epoch 00267: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 858ms/step - loss: 1.8588\n",
      "Epoch 268/600\n",
      "\n",
      "Epoch 00268: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 857ms/step - loss: 1.8968\n",
      "Epoch 269/600\n",
      "\n",
      "Epoch 00269: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 832ms/step - loss: 1.8691\n",
      "Epoch 270/600\n",
      "\n",
      "Epoch 00270: LearningRateScheduler setting learning rate to 0.001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 12s 827ms/step - loss: 1.9012\n",
      "Epoch 271/600\n",
      "\n",
      "Epoch 00271: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 869ms/step - loss: 1.7805\n",
      "Epoch 272/600\n",
      "\n",
      "Epoch 00272: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 858ms/step - loss: 1.8631\n",
      "Epoch 273/600\n",
      "\n",
      "Epoch 00273: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 867ms/step - loss: 1.8681\n",
      "Epoch 274/600\n",
      "\n",
      "Epoch 00274: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 859ms/step - loss: 1.8523\n",
      "Epoch 275/600\n",
      "\n",
      "Epoch 00275: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 861ms/step - loss: 1.7833\n",
      "Epoch 276/600\n",
      "\n",
      "Epoch 00276: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 872ms/step - loss: 1.8405\n",
      "Epoch 277/600\n",
      "\n",
      "Epoch 00277: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 872ms/step - loss: 1.8165\n",
      "Epoch 278/600\n",
      "\n",
      "Epoch 00278: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 933ms/step - loss: 1.8713\n",
      "Epoch 279/600\n",
      "\n",
      "Epoch 00279: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 860ms/step - loss: 1.8648\n",
      "Epoch 280/600\n",
      "\n",
      "Epoch 00280: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 911ms/step - loss: 1.8123\n",
      "Epoch 281/600\n",
      "\n",
      "Epoch 00281: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 821ms/step - loss: 1.8259\n",
      "Epoch 282/600\n",
      "\n",
      "Epoch 00282: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 856ms/step - loss: 1.7511\n",
      "Epoch 283/600\n",
      "\n",
      "Epoch 00283: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 947ms/step - loss: 1.8534\n",
      "Epoch 284/600\n",
      "\n",
      "Epoch 00284: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 857ms/step - loss: 1.8601\n",
      "Epoch 285/600\n",
      "\n",
      "Epoch 00285: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 824ms/step - loss: 1.7246\n",
      "Epoch 286/600\n",
      "\n",
      "Epoch 00286: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 856ms/step - loss: 1.8564\n",
      "Epoch 287/600\n",
      "\n",
      "Epoch 00287: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 854ms/step - loss: 1.7794\n",
      "Epoch 288/600\n",
      "\n",
      "Epoch 00288: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 881ms/step - loss: 1.9363\n",
      "Epoch 289/600\n",
      "\n",
      "Epoch 00289: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 885ms/step - loss: 1.8257\n",
      "Epoch 290/600\n",
      "\n",
      "Epoch 00290: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 881ms/step - loss: 1.8435\n",
      "Epoch 291/600\n",
      "\n",
      "Epoch 00291: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 849ms/step - loss: 1.8670\n",
      "Epoch 292/600\n",
      "\n",
      "Epoch 00292: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 876ms/step - loss: 1.7777\n",
      "Epoch 293/600\n",
      "\n",
      "Epoch 00293: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 856ms/step - loss: 1.8280\n",
      "Epoch 294/600\n",
      "\n",
      "Epoch 00294: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 841ms/step - loss: 1.8202\n",
      "Epoch 295/600\n",
      "\n",
      "Epoch 00295: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 863ms/step - loss: 1.8124\n",
      "Epoch 296/600\n",
      "\n",
      "Epoch 00296: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 840ms/step - loss: 1.7889\n",
      "Epoch 297/600\n",
      "\n",
      "Epoch 00297: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 887ms/step - loss: 1.7564\n",
      "Epoch 298/600\n",
      "\n",
      "Epoch 00298: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 894ms/step - loss: 1.9414\n",
      "Epoch 299/600\n",
      "\n",
      "Epoch 00299: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 891ms/step - loss: 1.8276\n",
      "Epoch 300/600\n",
      "\n",
      "Epoch 00300: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 899ms/step - loss: 1.9264\n",
      "Epoch 301/600\n",
      "\n",
      "Epoch 00301: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 845ms/step - loss: 1.8478\n",
      "Epoch 302/600\n",
      "\n",
      "Epoch 00302: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 910ms/step - loss: 1.8021\n",
      "Epoch 303/600\n",
      "\n",
      "Epoch 00303: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 827ms/step - loss: 1.7457\n",
      "Epoch 304/600\n",
      "\n",
      "Epoch 00304: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 905ms/step - loss: 1.7439\n",
      "Epoch 305/600\n",
      "\n",
      "Epoch 00305: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 859ms/step - loss: 1.8196\n",
      "Epoch 306/600\n",
      "\n",
      "Epoch 00306: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 903ms/step - loss: 1.7527\n",
      "Epoch 307/600\n",
      "\n",
      "Epoch 00307: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 895ms/step - loss: 1.8229\n",
      "Epoch 308/600\n",
      "\n",
      "Epoch 00308: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 868ms/step - loss: 1.8030\n",
      "Epoch 309/600\n",
      "\n",
      "Epoch 00309: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 909ms/step - loss: 1.7762\n",
      "Epoch 310/600\n",
      "\n",
      "Epoch 00310: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 895ms/step - loss: 1.7710\n",
      "Epoch 311/600\n",
      "\n",
      "Epoch 00311: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 839ms/step - loss: 1.8529\n",
      "Epoch 312/600\n",
      "\n",
      "Epoch 00312: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 856ms/step - loss: 1.8292\n",
      "Epoch 313/600\n",
      "\n",
      "Epoch 00313: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 844ms/step - loss: 1.7492\n",
      "Epoch 314/600\n",
      "\n",
      "Epoch 00314: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 865ms/step - loss: 1.7104\n",
      "Epoch 315/600\n",
      "\n",
      "Epoch 00315: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 839ms/step - loss: 1.8274\n",
      "Epoch 316/600\n",
      "\n",
      "Epoch 00316: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 805ms/step - loss: 1.7785\n",
      "Epoch 317/600\n",
      "\n",
      "Epoch 00317: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 885ms/step - loss: 1.8521\n",
      "Epoch 318/600\n",
      "\n",
      "Epoch 00318: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 856ms/step - loss: 1.7722\n",
      "Epoch 319/600\n",
      "\n",
      "Epoch 00319: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 893ms/step - loss: 1.8599\n",
      "Epoch 320/600\n",
      "\n",
      "Epoch 00320: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 884ms/step - loss: 1.7678\n",
      "Epoch 321/600\n",
      "\n",
      "Epoch 00321: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 932ms/step - loss: 1.9012\n",
      "Epoch 322/600\n",
      "\n",
      "Epoch 00322: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 878ms/step - loss: 1.8576\n",
      "Epoch 323/600\n",
      "\n",
      "Epoch 00323: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 900ms/step - loss: 1.7909\n",
      "Epoch 324/600\n",
      "\n",
      "Epoch 00324: LearningRateScheduler setting learning rate to 0.001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 13s 845ms/step - loss: 1.6502\n",
      "Epoch 325/600\n",
      "\n",
      "Epoch 00325: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 826ms/step - loss: 1.7541\n",
      "Epoch 326/600\n",
      "\n",
      "Epoch 00326: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 878ms/step - loss: 1.7221\n",
      "Epoch 327/600\n",
      "\n",
      "Epoch 00327: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 867ms/step - loss: 1.8383\n",
      "Epoch 328/600\n",
      "\n",
      "Epoch 00328: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 867ms/step - loss: 1.7222\n",
      "Epoch 329/600\n",
      "\n",
      "Epoch 00329: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 864ms/step - loss: 1.8664\n",
      "Epoch 330/600\n",
      "\n",
      "Epoch 00330: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 868ms/step - loss: 1.8250\n",
      "Epoch 331/600\n",
      "\n",
      "Epoch 00331: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 881ms/step - loss: 1.7903\n",
      "Epoch 332/600\n",
      "\n",
      "Epoch 00332: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 841ms/step - loss: 1.7341\n",
      "Epoch 333/600\n",
      "\n",
      "Epoch 00333: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 821ms/step - loss: 1.6749\n",
      "Epoch 334/600\n",
      "\n",
      "Epoch 00334: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 874ms/step - loss: 1.8188\n",
      "Epoch 335/600\n",
      "\n",
      "Epoch 00335: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 870ms/step - loss: 1.7919\n",
      "Epoch 336/600\n",
      "\n",
      "Epoch 00336: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 901ms/step - loss: 1.7502\n",
      "Epoch 337/600\n",
      "\n",
      "Epoch 00337: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 802ms/step - loss: 1.7740\n",
      "Epoch 338/600\n",
      "\n",
      "Epoch 00338: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 782ms/step - loss: 1.6947\n",
      "Epoch 339/600\n",
      "\n",
      "Epoch 00339: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 892ms/step - loss: 1.7842\n",
      "Epoch 340/600\n",
      "\n",
      "Epoch 00340: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 868ms/step - loss: 1.8395\n",
      "Epoch 341/600\n",
      "\n",
      "Epoch 00341: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 905ms/step - loss: 1.8819\n",
      "Epoch 342/600\n",
      "\n",
      "Epoch 00342: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 870ms/step - loss: 1.7768\n",
      "Epoch 343/600\n",
      "\n",
      "Epoch 00343: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 840ms/step - loss: 1.7049\n",
      "Epoch 344/600\n",
      "\n",
      "Epoch 00344: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 830ms/step - loss: 1.8015\n",
      "Epoch 345/600\n",
      "\n",
      "Epoch 00345: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 894ms/step - loss: 1.7560\n",
      "Epoch 346/600\n",
      "\n",
      "Epoch 00346: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 844ms/step - loss: 1.7652\n",
      "Epoch 347/600\n",
      "\n",
      "Epoch 00347: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 898ms/step - loss: 1.6810\n",
      "Epoch 348/600\n",
      "\n",
      "Epoch 00348: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 920ms/step - loss: 1.8008\n",
      "Epoch 349/600\n",
      "\n",
      "Epoch 00349: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 816ms/step - loss: 1.8094\n",
      "Epoch 350/600\n",
      "\n",
      "Epoch 00350: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 833ms/step - loss: 1.7359\n",
      "Epoch 351/600\n",
      "\n",
      "Epoch 00351: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 835ms/step - loss: 1.8038\n",
      "Epoch 352/600\n",
      "\n",
      "Epoch 00352: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 849ms/step - loss: 1.7302\n",
      "Epoch 353/600\n",
      "\n",
      "Epoch 00353: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 913ms/step - loss: 1.7211\n",
      "Epoch 354/600\n",
      "\n",
      "Epoch 00354: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 838ms/step - loss: 1.7505\n",
      "Epoch 355/600\n",
      "\n",
      "Epoch 00355: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 850ms/step - loss: 1.5868\n",
      "Epoch 356/600\n",
      "\n",
      "Epoch 00356: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 889ms/step - loss: 1.7759\n",
      "Epoch 357/600\n",
      "\n",
      "Epoch 00357: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 876ms/step - loss: 1.7588\n",
      "Epoch 358/600\n",
      "\n",
      "Epoch 00358: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 853ms/step - loss: 1.8308\n",
      "Epoch 359/600\n",
      "\n",
      "Epoch 00359: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 842ms/step - loss: 1.8404\n",
      "Epoch 360/600\n",
      "\n",
      "Epoch 00360: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 845ms/step - loss: 1.7903\n",
      "Epoch 361/600\n",
      "\n",
      "Epoch 00361: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 902ms/step - loss: 1.8306\n",
      "Epoch 362/600\n",
      "\n",
      "Epoch 00362: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 897ms/step - loss: 1.6340\n",
      "Epoch 363/600\n",
      "\n",
      "Epoch 00363: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 813ms/step - loss: 1.8104\n",
      "Epoch 364/600\n",
      "\n",
      "Epoch 00364: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 855ms/step - loss: 1.6856\n",
      "Epoch 365/600\n",
      "\n",
      "Epoch 00365: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 883ms/step - loss: 1.7319\n",
      "Epoch 366/600\n",
      "\n",
      "Epoch 00366: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 912ms/step - loss: 1.6601\n",
      "Epoch 367/600\n",
      "\n",
      "Epoch 00367: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 888ms/step - loss: 1.7591\n",
      "Epoch 368/600\n",
      "\n",
      "Epoch 00368: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 887ms/step - loss: 1.7106\n",
      "Epoch 369/600\n",
      "\n",
      "Epoch 00369: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 935ms/step - loss: 1.8484\n",
      "Epoch 370/600\n",
      "\n",
      "Epoch 00370: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 901ms/step - loss: 1.7411\n",
      "Epoch 371/600\n",
      "\n",
      "Epoch 00371: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 887ms/step - loss: 1.6740\n",
      "Epoch 372/600\n",
      "\n",
      "Epoch 00372: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 874ms/step - loss: 1.6749\n",
      "Epoch 373/600\n",
      "\n",
      "Epoch 00373: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 842ms/step - loss: 1.5092\n",
      "Epoch 374/600\n",
      "\n",
      "Epoch 00374: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 818ms/step - loss: 1.7813\n",
      "Epoch 375/600\n",
      "\n",
      "Epoch 00375: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 822ms/step - loss: 1.6068\n",
      "Epoch 376/600\n",
      "\n",
      "Epoch 00376: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 904ms/step - loss: 1.7669\n",
      "Epoch 377/600\n",
      "\n",
      "Epoch 00377: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 877ms/step - loss: 1.6406\n",
      "Epoch 378/600\n",
      "\n",
      "Epoch 00378: LearningRateScheduler setting learning rate to 0.001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 13s 869ms/step - loss: 1.8081\n",
      "Epoch 379/600\n",
      "\n",
      "Epoch 00379: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 857ms/step - loss: 1.7765\n",
      "Epoch 380/600\n",
      "\n",
      "Epoch 00380: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 904ms/step - loss: 1.7353\n",
      "Epoch 381/600\n",
      "\n",
      "Epoch 00381: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 895ms/step - loss: 1.7476\n",
      "Epoch 382/600\n",
      "\n",
      "Epoch 00382: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 887ms/step - loss: 1.7487\n",
      "Epoch 383/600\n",
      "\n",
      "Epoch 00383: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 875ms/step - loss: 1.6249\n",
      "Epoch 384/600\n",
      "\n",
      "Epoch 00384: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 856ms/step - loss: 1.6418\n",
      "Epoch 385/600\n",
      "\n",
      "Epoch 00385: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 870ms/step - loss: 1.6420\n",
      "Epoch 386/600\n",
      "\n",
      "Epoch 00386: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 889ms/step - loss: 1.7238\n",
      "Epoch 387/600\n",
      "\n",
      "Epoch 00387: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 864ms/step - loss: 1.7378\n",
      "Epoch 388/600\n",
      "\n",
      "Epoch 00388: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 15s 970ms/step - loss: 1.7621\n",
      "Epoch 389/600\n",
      "\n",
      "Epoch 00389: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 16s 1s/step - loss: 1.7134\n",
      "Epoch 390/600\n",
      "\n",
      "Epoch 00390: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 893ms/step - loss: 1.7790\n",
      "Epoch 391/600\n",
      "\n",
      "Epoch 00391: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 861ms/step - loss: 1.6433\n",
      "Epoch 392/600\n",
      "\n",
      "Epoch 00392: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 899ms/step - loss: 1.6190\n",
      "Epoch 393/600\n",
      "\n",
      "Epoch 00393: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 897ms/step - loss: 1.8110\n",
      "Epoch 394/600\n",
      "\n",
      "Epoch 00394: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 883ms/step - loss: 1.7185\n",
      "Epoch 395/600\n",
      "\n",
      "Epoch 00395: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 955ms/step - loss: 1.7541\n",
      "Epoch 396/600\n",
      "\n",
      "Epoch 00396: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 797ms/step - loss: 1.7660\n",
      "Epoch 397/600\n",
      "\n",
      "Epoch 00397: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 851ms/step - loss: 1.7075\n",
      "Epoch 398/600\n",
      "\n",
      "Epoch 00398: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 854ms/step - loss: 1.7602\n",
      "Epoch 399/600\n",
      "\n",
      "Epoch 00399: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 884ms/step - loss: 1.7690\n",
      "Epoch 400/600\n",
      "\n",
      "Epoch 00400: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 819ms/step - loss: 1.6752\n",
      "Epoch 401/600\n",
      "\n",
      "Epoch 00401: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 879ms/step - loss: 1.6831\n",
      "Epoch 402/600\n",
      "\n",
      "Epoch 00402: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 862ms/step - loss: 1.6795\n",
      "Epoch 403/600\n",
      "\n",
      "Epoch 00403: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 870ms/step - loss: 1.7019\n",
      "Epoch 404/600\n",
      "\n",
      "Epoch 00404: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 859ms/step - loss: 1.7476\n",
      "Epoch 405/600\n",
      "\n",
      "Epoch 00405: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 831ms/step - loss: 1.6511\n",
      "Epoch 406/600\n",
      "\n",
      "Epoch 00406: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 895ms/step - loss: 1.7300\n",
      "Epoch 407/600\n",
      "\n",
      "Epoch 00407: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 867ms/step - loss: 1.7701\n",
      "Epoch 408/600\n",
      "\n",
      "Epoch 00408: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 822ms/step - loss: 1.6120\n",
      "Epoch 409/600\n",
      "\n",
      "Epoch 00409: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 899ms/step - loss: 1.6518\n",
      "Epoch 410/600\n",
      "\n",
      "Epoch 00410: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 868ms/step - loss: 1.7457\n",
      "Epoch 411/600\n",
      "\n",
      "Epoch 00411: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 929ms/step - loss: 1.6903\n",
      "Epoch 412/600\n",
      "\n",
      "Epoch 00412: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 846ms/step - loss: 1.6149\n",
      "Epoch 413/600\n",
      "\n",
      "Epoch 00413: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 877ms/step - loss: 1.6620\n",
      "Epoch 414/600\n",
      "\n",
      "Epoch 00414: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 860ms/step - loss: 1.6284\n",
      "Epoch 415/600\n",
      "\n",
      "Epoch 00415: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 843ms/step - loss: 1.6643\n",
      "Epoch 416/600\n",
      "\n",
      "Epoch 00416: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 840ms/step - loss: 1.5029\n",
      "Epoch 417/600\n",
      "\n",
      "Epoch 00417: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 900ms/step - loss: 1.6988\n",
      "Epoch 418/600\n",
      "\n",
      "Epoch 00418: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 877ms/step - loss: 1.6574\n",
      "Epoch 419/600\n",
      "\n",
      "Epoch 00419: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 870ms/step - loss: 1.5788\n",
      "Epoch 420/600\n",
      "\n",
      "Epoch 00420: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 908ms/step - loss: 1.7842\n",
      "Epoch 421/600\n",
      "\n",
      "Epoch 00421: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 879ms/step - loss: 1.7150\n",
      "Epoch 422/600\n",
      "\n",
      "Epoch 00422: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 893ms/step - loss: 1.7000\n",
      "Epoch 423/600\n",
      "\n",
      "Epoch 00423: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 886ms/step - loss: 1.7470\n",
      "Epoch 424/600\n",
      "\n",
      "Epoch 00424: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 864ms/step - loss: 1.6027\n",
      "Epoch 425/600\n",
      "\n",
      "Epoch 00425: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 817ms/step - loss: 1.6225\n",
      "Epoch 426/600\n",
      "\n",
      "Epoch 00426: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 885ms/step - loss: 1.6558\n",
      "Epoch 427/600\n",
      "\n",
      "Epoch 00427: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 857ms/step - loss: 1.7342\n",
      "Epoch 428/600\n",
      "\n",
      "Epoch 00428: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 841ms/step - loss: 1.7367\n",
      "Epoch 429/600\n",
      "\n",
      "Epoch 00429: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 866ms/step - loss: 1.6343\n",
      "Epoch 430/600\n",
      "\n",
      "Epoch 00430: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 878ms/step - loss: 1.6951\n",
      "Epoch 431/600\n",
      "\n",
      "Epoch 00431: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 890ms/step - loss: 1.7270\n",
      "Epoch 432/600\n",
      "\n",
      "Epoch 00432: LearningRateScheduler setting learning rate to 0.001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 14s 954ms/step - loss: 1.6987\n",
      "Epoch 433/600\n",
      "\n",
      "Epoch 00433: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 920ms/step - loss: 1.7634\n",
      "Epoch 434/600\n",
      "\n",
      "Epoch 00434: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 886ms/step - loss: 1.6654\n",
      "Epoch 435/600\n",
      "\n",
      "Epoch 00435: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 888ms/step - loss: 1.6854\n",
      "Epoch 436/600\n",
      "\n",
      "Epoch 00436: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 869ms/step - loss: 1.6876\n",
      "Epoch 437/600\n",
      "\n",
      "Epoch 00437: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 920ms/step - loss: 1.7524\n",
      "Epoch 438/600\n",
      "\n",
      "Epoch 00438: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 888ms/step - loss: 1.7013\n",
      "Epoch 439/600\n",
      "\n",
      "Epoch 00439: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 889ms/step - loss: 1.6912\n",
      "Epoch 440/600\n",
      "\n",
      "Epoch 00440: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 880ms/step - loss: 1.7290\n",
      "Epoch 441/600\n",
      "\n",
      "Epoch 00441: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 858ms/step - loss: 1.6414\n",
      "Epoch 442/600\n",
      "\n",
      "Epoch 00442: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 836ms/step - loss: 1.6455\n",
      "Epoch 443/600\n",
      "\n",
      "Epoch 00443: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 861ms/step - loss: 1.6699\n",
      "Epoch 444/600\n",
      "\n",
      "Epoch 00444: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 861ms/step - loss: 1.6218\n",
      "Epoch 445/600\n",
      "\n",
      "Epoch 00445: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 865ms/step - loss: 1.6989\n",
      "Epoch 446/600\n",
      "\n",
      "Epoch 00446: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 12s 833ms/step - loss: 1.6236\n",
      "Epoch 447/600\n",
      "\n",
      "Epoch 00447: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 931ms/step - loss: 1.7497\n",
      "Epoch 448/600\n",
      "\n",
      "Epoch 00448: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 836ms/step - loss: 1.6246\n",
      "Epoch 449/600\n",
      "\n",
      "Epoch 00449: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 14s 927ms/step - loss: 1.7332\n",
      "Epoch 450/600\n",
      "\n",
      "Epoch 00450: LearningRateScheduler setting learning rate to 0.001.\n",
      "15/15 [==============================] - 13s 871ms/step - loss: 1.6814\n",
      "Epoch 451/600\n",
      "\n",
      "Epoch 00451: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 12s 827ms/step - loss: 1.6753\n",
      "Epoch 452/600\n",
      "\n",
      "Epoch 00452: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 12s 804ms/step - loss: 1.5527\n",
      "Epoch 453/600\n",
      "\n",
      "Epoch 00453: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 859ms/step - loss: 1.5596\n",
      "Epoch 454/600\n",
      "\n",
      "Epoch 00454: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 12s 825ms/step - loss: 1.6275\n",
      "Epoch 455/600\n",
      "\n",
      "Epoch 00455: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 12s 826ms/step - loss: 1.6459\n",
      "Epoch 456/600\n",
      "\n",
      "Epoch 00456: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 879ms/step - loss: 1.5588\n",
      "Epoch 457/600\n",
      "\n",
      "Epoch 00457: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 14s 900ms/step - loss: 1.6219\n",
      "Epoch 458/600\n",
      "\n",
      "Epoch 00458: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 893ms/step - loss: 1.5041\n",
      "Epoch 459/600\n",
      "\n",
      "Epoch 00459: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 880ms/step - loss: 1.6727\n",
      "Epoch 460/600\n",
      "\n",
      "Epoch 00460: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 872ms/step - loss: 1.5061\n",
      "Epoch 461/600\n",
      "\n",
      "Epoch 00461: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 866ms/step - loss: 1.5505\n",
      "Epoch 462/600\n",
      "\n",
      "Epoch 00462: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 14s 911ms/step - loss: 1.6236\n",
      "Epoch 463/600\n",
      "\n",
      "Epoch 00463: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 14s 901ms/step - loss: 1.5420\n",
      "Epoch 464/600\n",
      "\n",
      "Epoch 00464: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 12s 830ms/step - loss: 1.6020\n",
      "Epoch 465/600\n",
      "\n",
      "Epoch 00465: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 872ms/step - loss: 1.6302\n",
      "Epoch 466/600\n",
      "\n",
      "Epoch 00466: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 844ms/step - loss: 1.6219\n",
      "Epoch 467/600\n",
      "\n",
      "Epoch 00467: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 12s 831ms/step - loss: 1.5592\n",
      "Epoch 468/600\n",
      "\n",
      "Epoch 00468: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 12s 827ms/step - loss: 1.4959\n",
      "Epoch 469/600\n",
      "\n",
      "Epoch 00469: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 12s 817ms/step - loss: 1.5405\n",
      "Epoch 470/600\n",
      "\n",
      "Epoch 00470: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 846ms/step - loss: 1.5063\n",
      "Epoch 471/600\n",
      "\n",
      "Epoch 00471: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 883ms/step - loss: 1.6568\n",
      "Epoch 472/600\n",
      "\n",
      "Epoch 00472: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 858ms/step - loss: 1.5543\n",
      "Epoch 473/600\n",
      "\n",
      "Epoch 00473: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 870ms/step - loss: 1.4827\n",
      "Epoch 474/600\n",
      "\n",
      "Epoch 00474: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 892ms/step - loss: 1.5931\n",
      "Epoch 475/600\n",
      "\n",
      "Epoch 00475: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 12s 829ms/step - loss: 1.5225\n",
      "Epoch 476/600\n",
      "\n",
      "Epoch 00476: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 14s 911ms/step - loss: 1.7140\n",
      "Epoch 477/600\n",
      "\n",
      "Epoch 00477: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 862ms/step - loss: 1.5020\n",
      "Epoch 478/600\n",
      "\n",
      "Epoch 00478: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 12s 821ms/step - loss: 1.5370\n",
      "Epoch 479/600\n",
      "\n",
      "Epoch 00479: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 852ms/step - loss: 1.6785\n",
      "Epoch 480/600\n",
      "\n",
      "Epoch 00480: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 856ms/step - loss: 1.6048\n",
      "Epoch 481/600\n",
      "\n",
      "Epoch 00481: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 865ms/step - loss: 1.5339\n",
      "Epoch 482/600\n",
      "\n",
      "Epoch 00482: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 835ms/step - loss: 1.5087\n",
      "Epoch 483/600\n",
      "\n",
      "Epoch 00483: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 840ms/step - loss: 1.4871\n",
      "Epoch 484/600\n",
      "\n",
      "Epoch 00484: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 879ms/step - loss: 1.4798\n",
      "Epoch 485/600\n",
      "\n",
      "Epoch 00485: LearningRateScheduler setting learning rate to 0.0001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 13s 875ms/step - loss: 1.5104\n",
      "Epoch 486/600\n",
      "\n",
      "Epoch 00486: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 879ms/step - loss: 1.6399\n",
      "Epoch 487/600\n",
      "\n",
      "Epoch 00487: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 864ms/step - loss: 1.5769\n",
      "Epoch 488/600\n",
      "\n",
      "Epoch 00488: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 876ms/step - loss: 1.5154\n",
      "Epoch 489/600\n",
      "\n",
      "Epoch 00489: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 878ms/step - loss: 1.4800\n",
      "Epoch 490/600\n",
      "\n",
      "Epoch 00490: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 872ms/step - loss: 1.4925\n",
      "Epoch 491/600\n",
      "\n",
      "Epoch 00491: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 846ms/step - loss: 1.4755\n",
      "Epoch 492/600\n",
      "\n",
      "Epoch 00492: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 838ms/step - loss: 1.4844\n",
      "Epoch 493/600\n",
      "\n",
      "Epoch 00493: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 834ms/step - loss: 1.5918\n",
      "Epoch 494/600\n",
      "\n",
      "Epoch 00494: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 864ms/step - loss: 1.6363\n",
      "Epoch 495/600\n",
      "\n",
      "Epoch 00495: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 878ms/step - loss: 1.5156\n",
      "Epoch 496/600\n",
      "\n",
      "Epoch 00496: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 889ms/step - loss: 1.6500\n",
      "Epoch 497/600\n",
      "\n",
      "Epoch 00497: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 881ms/step - loss: 1.5166\n",
      "Epoch 498/600\n",
      "\n",
      "Epoch 00498: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 14s 923ms/step - loss: 1.6440\n",
      "Epoch 499/600\n",
      "\n",
      "Epoch 00499: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 854ms/step - loss: 1.5752\n",
      "Epoch 500/600\n",
      "\n",
      "Epoch 00500: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 852ms/step - loss: 1.5431\n",
      "Epoch 501/600\n",
      "\n",
      "Epoch 00501: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 14s 903ms/step - loss: 1.5171\n",
      "Epoch 502/600\n",
      "\n",
      "Epoch 00502: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 871ms/step - loss: 1.5271\n",
      "Epoch 503/600\n",
      "\n",
      "Epoch 00503: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 883ms/step - loss: 1.5568\n",
      "Epoch 504/600\n",
      "\n",
      "Epoch 00504: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 845ms/step - loss: 1.5159\n",
      "Epoch 505/600\n",
      "\n",
      "Epoch 00505: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 889ms/step - loss: 1.3877\n",
      "Epoch 506/600\n",
      "\n",
      "Epoch 00506: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 12s 821ms/step - loss: 1.4896\n",
      "Epoch 507/600\n",
      "\n",
      "Epoch 00507: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 867ms/step - loss: 1.4283\n",
      "Epoch 508/600\n",
      "\n",
      "Epoch 00508: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 882ms/step - loss: 1.5516\n",
      "Epoch 509/600\n",
      "\n",
      "Epoch 00509: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 839ms/step - loss: 1.4839\n",
      "Epoch 510/600\n",
      "\n",
      "Epoch 00510: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 858ms/step - loss: 1.4746\n",
      "Epoch 511/600\n",
      "\n",
      "Epoch 00511: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 877ms/step - loss: 1.5160\n",
      "Epoch 512/600\n",
      "\n",
      "Epoch 00512: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 878ms/step - loss: 1.6128\n",
      "Epoch 513/600\n",
      "\n",
      "Epoch 00513: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 12s 822ms/step - loss: 1.5913\n",
      "Epoch 514/600\n",
      "\n",
      "Epoch 00514: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 859ms/step - loss: 1.6041\n",
      "Epoch 515/600\n",
      "\n",
      "Epoch 00515: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 880ms/step - loss: 1.5689\n",
      "Epoch 516/600\n",
      "\n",
      "Epoch 00516: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 866ms/step - loss: 1.6169\n",
      "Epoch 517/600\n",
      "\n",
      "Epoch 00517: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 867ms/step - loss: 1.5231\n",
      "Epoch 518/600\n",
      "\n",
      "Epoch 00518: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 14s 904ms/step - loss: 1.5786\n",
      "Epoch 519/600\n",
      "\n",
      "Epoch 00519: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 846ms/step - loss: 1.4617\n",
      "Epoch 520/600\n",
      "\n",
      "Epoch 00520: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 855ms/step - loss: 1.4697\n",
      "Epoch 521/600\n",
      "\n",
      "Epoch 00521: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 858ms/step - loss: 1.5544\n",
      "Epoch 522/600\n",
      "\n",
      "Epoch 00522: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 897ms/step - loss: 1.5452\n",
      "Epoch 523/600\n",
      "\n",
      "Epoch 00523: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 850ms/step - loss: 1.5393\n",
      "Epoch 524/600\n",
      "\n",
      "Epoch 00524: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 865ms/step - loss: 1.5414\n",
      "Epoch 525/600\n",
      "\n",
      "Epoch 00525: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 872ms/step - loss: 1.4711\n",
      "Epoch 526/600\n",
      "\n",
      "Epoch 00526: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 860ms/step - loss: 1.5836\n",
      "Epoch 527/600\n",
      "\n",
      "Epoch 00527: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 888ms/step - loss: 1.4900\n",
      "Epoch 528/600\n",
      "\n",
      "Epoch 00528: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 858ms/step - loss: 1.6458\n",
      "Epoch 529/600\n",
      "\n",
      "Epoch 00529: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 850ms/step - loss: 1.5019\n",
      "Epoch 530/600\n",
      "\n",
      "Epoch 00530: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 876ms/step - loss: 1.5429\n",
      "Epoch 531/600\n",
      "\n",
      "Epoch 00531: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 877ms/step - loss: 1.5789\n",
      "Epoch 532/600\n",
      "\n",
      "Epoch 00532: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 855ms/step - loss: 1.5415\n",
      "Epoch 533/600\n",
      "\n",
      "Epoch 00533: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 853ms/step - loss: 1.5586\n",
      "Epoch 534/600\n",
      "\n",
      "Epoch 00534: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 834ms/step - loss: 1.4292\n",
      "Epoch 535/600\n",
      "\n",
      "Epoch 00535: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 868ms/step - loss: 1.4249\n",
      "Epoch 536/600\n",
      "\n",
      "Epoch 00536: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 14s 911ms/step - loss: 1.5000\n",
      "Epoch 537/600\n",
      "\n",
      "Epoch 00537: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 862ms/step - loss: 1.5247\n",
      "Epoch 538/600\n",
      "\n",
      "Epoch 00538: LearningRateScheduler setting learning rate to 0.0001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 13s 834ms/step - loss: 1.5463\n",
      "Epoch 539/600\n",
      "\n",
      "Epoch 00539: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 854ms/step - loss: 1.4967\n",
      "Epoch 540/600\n",
      "\n",
      "Epoch 00540: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 838ms/step - loss: 1.4207\n",
      "Epoch 541/600\n",
      "\n",
      "Epoch 00541: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 12s 826ms/step - loss: 1.3947\n",
      "Epoch 542/600\n",
      "\n",
      "Epoch 00542: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 859ms/step - loss: 1.5765\n",
      "Epoch 543/600\n",
      "\n",
      "Epoch 00543: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 12s 831ms/step - loss: 1.5462\n",
      "Epoch 544/600\n",
      "\n",
      "Epoch 00544: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 834ms/step - loss: 1.5130\n",
      "Epoch 545/600\n",
      "\n",
      "Epoch 00545: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 12s 828ms/step - loss: 1.4352\n",
      "Epoch 546/600\n",
      "\n",
      "Epoch 00546: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 863ms/step - loss: 1.5561\n",
      "Epoch 547/600\n",
      "\n",
      "Epoch 00547: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 862ms/step - loss: 1.6024\n",
      "Epoch 548/600\n",
      "\n",
      "Epoch 00548: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 880ms/step - loss: 1.5856\n",
      "Epoch 549/600\n",
      "\n",
      "Epoch 00549: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 857ms/step - loss: 1.4669\n",
      "Epoch 550/600\n",
      "\n",
      "Epoch 00550: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 12s 817ms/step - loss: 1.5208\n",
      "Epoch 551/600\n",
      "\n",
      "Epoch 00551: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 12s 794ms/step - loss: 1.5061\n",
      "Epoch 552/600\n",
      "\n",
      "Epoch 00552: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 12s 812ms/step - loss: 1.4684\n",
      "Epoch 553/600\n",
      "\n",
      "Epoch 00553: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 14s 900ms/step - loss: 1.5180\n",
      "Epoch 554/600\n",
      "\n",
      "Epoch 00554: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 12s 809ms/step - loss: 1.4988\n",
      "Epoch 555/600\n",
      "\n",
      "Epoch 00555: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 880ms/step - loss: 1.5646\n",
      "Epoch 556/600\n",
      "\n",
      "Epoch 00556: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 900ms/step - loss: 1.5439\n",
      "Epoch 557/600\n",
      "\n",
      "Epoch 00557: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 871ms/step - loss: 1.5571\n",
      "Epoch 558/600\n",
      "\n",
      "Epoch 00558: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 899ms/step - loss: 1.5214\n",
      "Epoch 559/600\n",
      "\n",
      "Epoch 00559: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 869ms/step - loss: 1.5242\n",
      "Epoch 560/600\n",
      "\n",
      "Epoch 00560: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 867ms/step - loss: 1.5616\n",
      "Epoch 561/600\n",
      "\n",
      "Epoch 00561: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 14s 901ms/step - loss: 1.5955\n",
      "Epoch 562/600\n",
      "\n",
      "Epoch 00562: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 843ms/step - loss: 1.5420\n",
      "Epoch 563/600\n",
      "\n",
      "Epoch 00563: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 855ms/step - loss: 1.4766\n",
      "Epoch 564/600\n",
      "\n",
      "Epoch 00564: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 850ms/step - loss: 1.5808\n",
      "Epoch 565/600\n",
      "\n",
      "Epoch 00565: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 874ms/step - loss: 1.5493\n",
      "Epoch 566/600\n",
      "\n",
      "Epoch 00566: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 12s 813ms/step - loss: 1.3686\n",
      "Epoch 567/600\n",
      "\n",
      "Epoch 00567: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 844ms/step - loss: 1.5300\n",
      "Epoch 568/600\n",
      "\n",
      "Epoch 00568: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 874ms/step - loss: 1.4921\n",
      "Epoch 569/600\n",
      "\n",
      "Epoch 00569: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 12s 823ms/step - loss: 1.4360\n",
      "Epoch 570/600\n",
      "\n",
      "Epoch 00570: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 12s 829ms/step - loss: 1.6097\n",
      "Epoch 571/600\n",
      "\n",
      "Epoch 00571: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 841ms/step - loss: 1.4768\n",
      "Epoch 572/600\n",
      "\n",
      "Epoch 00572: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 12s 819ms/step - loss: 1.4340\n",
      "Epoch 573/600\n",
      "\n",
      "Epoch 00573: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 14s 917ms/step - loss: 1.5701\n",
      "Epoch 574/600\n",
      "\n",
      "Epoch 00574: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 888ms/step - loss: 1.5228\n",
      "Epoch 575/600\n",
      "\n",
      "Epoch 00575: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 835ms/step - loss: 1.4309\n",
      "Epoch 576/600\n",
      "\n",
      "Epoch 00576: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 853ms/step - loss: 1.4881\n",
      "Epoch 577/600\n",
      "\n",
      "Epoch 00577: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 887ms/step - loss: 1.4359\n",
      "Epoch 578/600\n",
      "\n",
      "Epoch 00578: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 845ms/step - loss: 1.5842\n",
      "Epoch 579/600\n",
      "\n",
      "Epoch 00579: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 840ms/step - loss: 1.5570\n",
      "Epoch 580/600\n",
      "\n",
      "Epoch 00580: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 884ms/step - loss: 1.4413\n",
      "Epoch 581/600\n",
      "\n",
      "Epoch 00581: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 14s 903ms/step - loss: 1.5404\n",
      "Epoch 582/600\n",
      "\n",
      "Epoch 00582: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 864ms/step - loss: 1.5671\n",
      "Epoch 583/600\n",
      "\n",
      "Epoch 00583: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 881ms/step - loss: 1.4834\n",
      "Epoch 584/600\n",
      "\n",
      "Epoch 00584: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 854ms/step - loss: 1.5827\n",
      "Epoch 585/600\n",
      "\n",
      "Epoch 00585: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 14s 906ms/step - loss: 1.6806\n",
      "Epoch 586/600\n",
      "\n",
      "Epoch 00586: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 886ms/step - loss: 1.5918\n",
      "Epoch 587/600\n",
      "\n",
      "Epoch 00587: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 14s 928ms/step - loss: 1.5705\n",
      "Epoch 588/600\n",
      "\n",
      "Epoch 00588: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 12s 830ms/step - loss: 1.4250\n",
      "Epoch 589/600\n",
      "\n",
      "Epoch 00589: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 860ms/step - loss: 1.5967\n",
      "Epoch 590/600\n",
      "\n",
      "Epoch 00590: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 893ms/step - loss: 1.4261\n",
      "Epoch 591/600\n",
      "\n",
      "Epoch 00591: LearningRateScheduler setting learning rate to 0.0001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 13s 861ms/step - loss: 1.5155\n",
      "Epoch 592/600\n",
      "\n",
      "Epoch 00592: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 891ms/step - loss: 1.4961\n",
      "Epoch 593/600\n",
      "\n",
      "Epoch 00593: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 12s 832ms/step - loss: 1.4943\n",
      "Epoch 594/600\n",
      "\n",
      "Epoch 00594: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 12s 815ms/step - loss: 1.5083\n",
      "Epoch 595/600\n",
      "\n",
      "Epoch 00595: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 12s 817ms/step - loss: 1.5021\n",
      "Epoch 596/600\n",
      "\n",
      "Epoch 00596: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 856ms/step - loss: 1.5099\n",
      "Epoch 597/600\n",
      "\n",
      "Epoch 00597: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 864ms/step - loss: 1.4755\n",
      "Epoch 598/600\n",
      "\n",
      "Epoch 00598: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 13s 837ms/step - loss: 1.4674\n",
      "Epoch 599/600\n",
      "\n",
      "Epoch 00599: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 12s 787ms/step - loss: 1.4298\n",
      "Epoch 600/600\n",
      "\n",
      "Epoch 00600: LearningRateScheduler setting learning rate to 0.0001.\n",
      "15/15 [==============================] - 12s 802ms/step - loss: 1.5984\n"
     ]
    }
   ],
   "source": [
    "scale_factors = [1.5]\n",
    "\n",
    "for factor in scale_factors:\n",
    "    # 1: Build the Keras model.\n",
    "    K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "    print('TRAINING MODEL WITH FACTOR:', factor)\n",
    "    \n",
    "    model = ssd_300(image_size=(img_height, img_width, img_channels),\n",
    "                n_classes=n_classes,\n",
    "                mode='training',\n",
    "                scale_factor=factor,\n",
    "                scales=scales,\n",
    "                aspect_ratios_per_layer=aspect_ratios,\n",
    "                two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                steps=steps,\n",
    "                offsets=offsets,\n",
    "                clip_boxes=clip_boxes,\n",
    "                variances=variances,\n",
    "                normalize_coords=normalize_coords,\n",
    "                subtract_mean=mean_color,\n",
    "                divide_by_stddev=divide_by_stddev,\n",
    "                swap_channels=swap_channels)\n",
    "\n",
    "    adam = Adam(lr=0.001)\n",
    "    ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "    model.load_weights('/home/aldo/Documents/weights/light_models/PASCAL/shufflenet_v2_ssdlayers_light_relu6_se_no_shuffle_factor_1.5.h5', by_name=True)\n",
    "    model.compile(optimizer=adam, loss=ssd_loss.compute_loss)\n",
    "    \n",
    "    # Define model callbacks.\n",
    "    main_path = '/home/aldo/Documents/'\n",
    "    # TODO: Set the filepath under which you want to save the model.\n",
    "\n",
    "    csv_logger = CSVLogger(filename=main_path + 'data-cic/history/light_models/CIC/shufflenet_v2_ssdlayers_light_relu6_se_no_shuffle_factor_' + \n",
    "                           str(factor) + '_4.csv',\n",
    "                           separator=',',\n",
    "                           append=True)\n",
    "\n",
    "    learning_rate_scheduler = LearningRateScheduler(schedule=lr_schedule, verbose=1)\n",
    "\n",
    "\n",
    "    callbacks = [csv_logger,\n",
    "                 learning_rate_scheduler]\n",
    "    \n",
    "    initial_epoch   = 0\n",
    "    final_epoch     = 600\n",
    "    steps_per_epoch = 15\n",
    "\n",
    "    history = model.fit_generator(generator=train_generator,\n",
    "                                  steps_per_epoch=steps_per_epoch,\n",
    "                                  epochs=final_epoch,\n",
    "                                  callbacks=callbacks,\n",
    "                                  initial_epoch=initial_epoch)\n",
    "    \n",
    "    model.save(main_path + 'weights/light_models/CIC/shufflenet_v2_ssdlayers_light_relu6_se_no_shuffle_factor_' + str(factor) + '_4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensor]",
   "language": "python",
   "name": "conda-env-tensor-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
