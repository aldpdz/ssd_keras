{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "sys.path.append(os.path.abspath('../../'))\n",
    "sys.path.append(os.path.abspath('../../extra_files'))\n",
    "import helper as hp\n",
    "from imageio import imwrite, imread\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "data_path = '/home/aldo/Documents/data-cic/'\n",
    "preprocess_path = data_path + 'preprocess_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training SSD300 trained with mobilenet backbone trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/aldo/Documents/ssd/data_generator/object_detection_2d_data_generator.py:43: UserWarning: 'BeautifulSoup' module is missing. The XML-parser will be unavailable.\n",
      "  warnings.warn(\"'BeautifulSoup' module is missing. The XML-parser will be unavailable.\")\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TerminateOnNaN, CSVLogger, EarlyStopping, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from light_models.keras_ssd300_shufflenetv1 import ssd_300\n",
    "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
    "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
    "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
    "from keras_layers.keras_layer_L2Normalization import L2Normalization\n",
    "\n",
    "from ssd_encoder_decoder.ssd_input_encoder import SSDInputEncoder\n",
    "from ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast\n",
    "\n",
    "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
    "from data_generator.object_detection_2d_geometric_ops import Resize\n",
    "from data_generator.object_detection_2d_photometric_ops import ConvertTo3Channels\n",
    "from data_generator.data_augmentation_chain_original_ssd import SSDDataAugmentation\n",
    "from data_generator.object_detection_2d_misc_utils import apply_inverse_transforms\n",
    "\n",
    "from extra_files.f1_callback import F1_callback as f1_call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters (original SSD300 architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameteres needed for ssd_300() and SSDInputEncoder()\n",
    "\n",
    "img_height = 300 # Height of the model input images\n",
    "img_width = 300 # Width of the model input images\n",
    "img_channels = 3 # Number of color channels of the model input images\n",
    "mean_color = [1., 1., 1.] # The per-channel mean of the images in the dataset. Do not change this value if you're using any of the pre-trained weights.\n",
    "divide_by_stddev = [127.5, 127.5, 127.5]\n",
    "swap_channels = False # The color channel order in the original SSD is BGR, so we'll have the model reverse the color channel order of the input images.\n",
    "n_classes = 1 # Number of positive classes, e.g. 20 for Pascal VOC, 80 for MS COCO\n",
    "scales_pascal = [0.1, 0.2, 0.37, 0.54, 0.71, 0.88, 1.05] # The anchor box scaling factors used in the original SSD300 for the Pascal VOC datasets\n",
    "scales = scales_pascal\n",
    "#scales = [0.07, 0.15, 0.33, 0.51, 0.69, 0.87, 1.05]\n",
    "aspect_ratios = [[1.0, 2.0, 0.5],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5],\n",
    "                 [1.0, 2.0, 0.5]] # The anchor box aspect ratios used in the original SSD300; the order matters\n",
    "two_boxes_for_ar1 = True\n",
    "steps = [16, 30, 60, 100, 150, 300] # The space between two adjacent anchor box center points for each predictor layer.\n",
    "offsets = [0.5, 0.5, 0.5, 0.5, 0.5, 0.5] # The offsets of the first anchor box center points from the top and left borders of the image as a fraction of the step size for each predictor layer.\n",
    "clip_boxes = False # Whether or not to clip the anchor boxes to lie entirely within the image boundaries\n",
    "variances = [0.1, 0.1, 0.2, 0.2] # The variances by which the encoded target coordinates are divided as in the original implementation\n",
    "normalize_coords = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new model with SSD weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Build the Keras model.\n",
    "\n",
    "K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "model = ssd_300(image_size=(img_height, img_width, img_channels),\n",
    "                n_classes=n_classes,\n",
    "                mode='training',\n",
    "                scale_factor=1.5,\n",
    "                scales=scales,\n",
    "                aspect_ratios_per_layer=aspect_ratios,\n",
    "                two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                steps=steps,\n",
    "                offsets=offsets,\n",
    "                clip_boxes=clip_boxes,\n",
    "                variances=variances,\n",
    "                normalize_coords=normalize_coords,\n",
    "                subtract_mean=mean_color,\n",
    "                divide_by_stddev=divide_by_stddev,\n",
    "                swap_channels=swap_channels)\n",
    "\n",
    "# 3: Instantiate an optimizer and the SSD loss function and compile the model.\n",
    "#    If you want to follow the original Caffe implementation, use the preset SGD\n",
    "#    optimizer, otherwise I'd recommend the commented-out Adam optimizer.\n",
    "\n",
    "adam = Adam(lr=0.001)\n",
    "#sgd = SGD(lr=0.001, momentum=0.9, decay=0.0, nesterov=False)\n",
    "\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "model.compile(optimizer=adam, loss=ssd_loss.compute_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 300, 300, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "identity_layer (Lambda)         (None, 300, 300, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_stddev_normalization (Lam (None, 300, 300, 3)  0           identity_layer[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "input_mean_normalization (Lambd (None, 300, 300, 3)  0           input_stddev_normalization[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 19, 19, 720)  803712      input_mean_normalization[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/relu_out (Activat (None, 19, 19, 720)  0           model_1[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/1x1_gconv_1/g0_sl (None, 19, 19, 240)  0           stage3/block8/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/1x1_gconv_1/g1_sl (None, 19, 19, 240)  0           stage3/block8/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/1x1_gconv_1/g2_sl (None, 19, 19, 240)  0           stage3/block8/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/1x1_gconv_1_/g0 ( (None, 19, 19, 120)  28800       stage4/block1/1x1_gconv_1/g0_slic\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/1x1_gconv_1_/g1 ( (None, 19, 19, 120)  28800       stage4/block1/1x1_gconv_1/g1_slic\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/1x1_gconv_1_/g2 ( (None, 19, 19, 120)  28800       stage4/block1/1x1_gconv_1/g2_slic\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/1x1_gconv_1/conca (None, 19, 19, 360)  0           stage4/block1/1x1_gconv_1_/g0[0][\n",
      "                                                                 stage4/block1/1x1_gconv_1_/g1[0][\n",
      "                                                                 stage4/block1/1x1_gconv_1_/g2[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/bn_gconv_1 (Batch (None, 19, 19, 360)  1440        stage4/block1/1x1_gconv_1/concat[\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/relu_gconv_1 (Act (None, 19, 19, 360)  0           stage4/block1/bn_gconv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/channel_shuffle ( (None, 19, 19, 360)  0           stage4/block1/relu_gconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/1x1_dwconv_1 (Dep (None, 10, 10, 360)  3240        stage4/block1/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/bn_dwconv_1 (Batc (None, 10, 10, 360)  1440        stage4/block1/1x1_dwconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/1x1_gconv_2/g0_sl (None, 10, 10, 120)  0           stage4/block1/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/1x1_gconv_2/g1_sl (None, 10, 10, 120)  0           stage4/block1/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/1x1_gconv_2/g2_sl (None, 10, 10, 120)  0           stage4/block1/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/1x1_gconv_2_/g0 ( (None, 10, 10, 240)  28800       stage4/block1/1x1_gconv_2/g0_slic\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/1x1_gconv_2_/g1 ( (None, 10, 10, 240)  28800       stage4/block1/1x1_gconv_2/g1_slic\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/1x1_gconv_2_/g2 ( (None, 10, 10, 240)  28800       stage4/block1/1x1_gconv_2/g2_slic\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/1x1_gconv_2/conca (None, 10, 10, 720)  0           stage4/block1/1x1_gconv_2_/g0[0][\n",
      "                                                                 stage4/block1/1x1_gconv_2_/g1[0][\n",
      "                                                                 stage4/block1/1x1_gconv_2_/g2[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/bn_gconv_2 (Batch (None, 10, 10, 720)  2880        stage4/block1/1x1_gconv_2/concat[\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/avg_pool (Average (None, 10, 10, 720)  0           stage3/block8/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/concat (Concatena (None, 10, 10, 1440) 0           stage4/block1/bn_gconv_2[0][0]   \n",
      "                                                                 stage4/block1/avg_pool[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/relu_out (Activat (None, 10, 10, 1440) 0           stage4/block1/concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/1x1_gconv_1/g0_sl (None, 10, 10, 480)  0           stage4/block1/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/1x1_gconv_1/g1_sl (None, 10, 10, 480)  0           stage4/block1/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/1x1_gconv_1/g2_sl (None, 10, 10, 480)  0           stage4/block1/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/1x1_gconv_1_/g0 ( (None, 10, 10, 120)  57600       stage4/block2/1x1_gconv_1/g0_slic\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/1x1_gconv_1_/g1 ( (None, 10, 10, 120)  57600       stage4/block2/1x1_gconv_1/g1_slic\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/1x1_gconv_1_/g2 ( (None, 10, 10, 120)  57600       stage4/block2/1x1_gconv_1/g2_slic\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/1x1_gconv_1/conca (None, 10, 10, 360)  0           stage4/block2/1x1_gconv_1_/g0[0][\n",
      "                                                                 stage4/block2/1x1_gconv_1_/g1[0][\n",
      "                                                                 stage4/block2/1x1_gconv_1_/g2[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/bn_gconv_1 (Batch (None, 10, 10, 360)  1440        stage4/block2/1x1_gconv_1/concat[\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/relu_gconv_1 (Act (None, 10, 10, 360)  0           stage4/block2/bn_gconv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/channel_shuffle ( (None, 10, 10, 360)  0           stage4/block2/relu_gconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/1x1_dwconv_1 (Dep (None, 10, 10, 360)  3240        stage4/block2/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/bn_dwconv_1 (Batc (None, 10, 10, 360)  1440        stage4/block2/1x1_dwconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/1x1_gconv_2/g0_sl (None, 10, 10, 120)  0           stage4/block2/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/1x1_gconv_2/g1_sl (None, 10, 10, 120)  0           stage4/block2/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/1x1_gconv_2/g2_sl (None, 10, 10, 120)  0           stage4/block2/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/1x1_gconv_2_/g0 ( (None, 10, 10, 480)  57600       stage4/block2/1x1_gconv_2/g0_slic\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/1x1_gconv_2_/g1 ( (None, 10, 10, 480)  57600       stage4/block2/1x1_gconv_2/g1_slic\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/1x1_gconv_2_/g2 ( (None, 10, 10, 480)  57600       stage4/block2/1x1_gconv_2/g2_slic\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/1x1_gconv_2/conca (None, 10, 10, 1440) 0           stage4/block2/1x1_gconv_2_/g0[0][\n",
      "                                                                 stage4/block2/1x1_gconv_2_/g1[0][\n",
      "                                                                 stage4/block2/1x1_gconv_2_/g2[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/bn_gconv_2 (Batch (None, 10, 10, 1440) 5760        stage4/block2/1x1_gconv_2/concat[\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/add (Add)         (None, 10, 10, 1440) 0           stage4/block2/bn_gconv_2[0][0]   \n",
      "                                                                 stage4/block1/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/relu_out (Activat (None, 10, 10, 1440) 0           stage4/block2/add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/1x1_gconv_1/g0_sl (None, 10, 10, 480)  0           stage4/block2/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/1x1_gconv_1/g1_sl (None, 10, 10, 480)  0           stage4/block2/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/1x1_gconv_1/g2_sl (None, 10, 10, 480)  0           stage4/block2/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/1x1_gconv_1_/g0 ( (None, 10, 10, 120)  57600       stage4/block3/1x1_gconv_1/g0_slic\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/1x1_gconv_1_/g1 ( (None, 10, 10, 120)  57600       stage4/block3/1x1_gconv_1/g1_slic\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/1x1_gconv_1_/g2 ( (None, 10, 10, 120)  57600       stage4/block3/1x1_gconv_1/g2_slic\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/1x1_gconv_1/conca (None, 10, 10, 360)  0           stage4/block3/1x1_gconv_1_/g0[0][\n",
      "                                                                 stage4/block3/1x1_gconv_1_/g1[0][\n",
      "                                                                 stage4/block3/1x1_gconv_1_/g2[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/bn_gconv_1 (Batch (None, 10, 10, 360)  1440        stage4/block3/1x1_gconv_1/concat[\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/relu_gconv_1 (Act (None, 10, 10, 360)  0           stage4/block3/bn_gconv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/channel_shuffle ( (None, 10, 10, 360)  0           stage4/block3/relu_gconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/1x1_dwconv_1 (Dep (None, 10, 10, 360)  3240        stage4/block3/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/bn_dwconv_1 (Batc (None, 10, 10, 360)  1440        stage4/block3/1x1_dwconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/1x1_gconv_2/g0_sl (None, 10, 10, 120)  0           stage4/block3/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/1x1_gconv_2/g1_sl (None, 10, 10, 120)  0           stage4/block3/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/1x1_gconv_2/g2_sl (None, 10, 10, 120)  0           stage4/block3/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/1x1_gconv_2_/g0 ( (None, 10, 10, 480)  57600       stage4/block3/1x1_gconv_2/g0_slic\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/1x1_gconv_2_/g1 ( (None, 10, 10, 480)  57600       stage4/block3/1x1_gconv_2/g1_slic\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/1x1_gconv_2_/g2 ( (None, 10, 10, 480)  57600       stage4/block3/1x1_gconv_2/g2_slic\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/1x1_gconv_2/conca (None, 10, 10, 1440) 0           stage4/block3/1x1_gconv_2_/g0[0][\n",
      "                                                                 stage4/block3/1x1_gconv_2_/g1[0][\n",
      "                                                                 stage4/block3/1x1_gconv_2_/g2[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/bn_gconv_2 (Batch (None, 10, 10, 1440) 5760        stage4/block3/1x1_gconv_2/concat[\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/add (Add)         (None, 10, 10, 1440) 0           stage4/block3/bn_gconv_2[0][0]   \n",
      "                                                                 stage4/block2/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/relu_out (Activat (None, 10, 10, 1440) 0           stage4/block3/add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/1x1_gconv_1/g0_sl (None, 10, 10, 480)  0           stage4/block3/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/1x1_gconv_1/g1_sl (None, 10, 10, 480)  0           stage4/block3/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/1x1_gconv_1/g2_sl (None, 10, 10, 480)  0           stage4/block3/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/1x1_gconv_1_/g0 ( (None, 10, 10, 120)  57600       stage4/block4/1x1_gconv_1/g0_slic\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/1x1_gconv_1_/g1 ( (None, 10, 10, 120)  57600       stage4/block4/1x1_gconv_1/g1_slic\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/1x1_gconv_1_/g2 ( (None, 10, 10, 120)  57600       stage4/block4/1x1_gconv_1/g2_slic\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/1x1_gconv_1/conca (None, 10, 10, 360)  0           stage4/block4/1x1_gconv_1_/g0[0][\n",
      "                                                                 stage4/block4/1x1_gconv_1_/g1[0][\n",
      "                                                                 stage4/block4/1x1_gconv_1_/g2[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/bn_gconv_1 (Batch (None, 10, 10, 360)  1440        stage4/block4/1x1_gconv_1/concat[\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/relu_gconv_1 (Act (None, 10, 10, 360)  0           stage4/block4/bn_gconv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/channel_shuffle ( (None, 10, 10, 360)  0           stage4/block4/relu_gconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/1x1_dwconv_1 (Dep (None, 10, 10, 360)  3240        stage4/block4/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/bn_dwconv_1 (Batc (None, 10, 10, 360)  1440        stage4/block4/1x1_dwconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/1x1_gconv_2/g0_sl (None, 10, 10, 120)  0           stage4/block4/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/1x1_gconv_2/g1_sl (None, 10, 10, 120)  0           stage4/block4/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/1x1_gconv_2/g2_sl (None, 10, 10, 120)  0           stage4/block4/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/1x1_gconv_2_/g0 ( (None, 10, 10, 480)  57600       stage4/block4/1x1_gconv_2/g0_slic\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/1x1_gconv_2_/g1 ( (None, 10, 10, 480)  57600       stage4/block4/1x1_gconv_2/g1_slic\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/1x1_gconv_2_/g2 ( (None, 10, 10, 480)  57600       stage4/block4/1x1_gconv_2/g2_slic\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/1x1_gconv_2/conca (None, 10, 10, 1440) 0           stage4/block4/1x1_gconv_2_/g0[0][\n",
      "                                                                 stage4/block4/1x1_gconv_2_/g1[0][\n",
      "                                                                 stage4/block4/1x1_gconv_2_/g2[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/bn_gconv_2 (Batch (None, 10, 10, 1440) 5760        stage4/block4/1x1_gconv_2/concat[\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/add (Add)         (None, 10, 10, 1440) 0           stage4/block4/bn_gconv_2[0][0]   \n",
      "                                                                 stage4/block3/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/relu_out (Activat (None, 10, 10, 1440) 0           stage4/block4/add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_18_1 (ZeroPadding2D)   (None, 12, 12, 1440) 0           stage4/block4/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv__18_1 (Conv2D)             (None, 12, 12, 256)  368640      conv_pad_18_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_18_bn_1 (BatchNormalizatio (None, 12, 12, 256)  1024        conv__18_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_18_relu_1 (Activation)     (None, 12, 12, 256)  0           conv_18_bn_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv__18_2 (Conv2D)             (None, 5, 5, 512)    1179648     conv_18_relu_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_18_bn_2 (BatchNormalizatio (None, 5, 5, 512)    2048        conv__18_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_18_relu_2 (Activation)     (None, 5, 5, 512)    0           conv_18_bn_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_19_1 (ZeroPadding2D)   (None, 7, 7, 512)    0           conv_18_relu_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv__19_1 (Conv2D)             (None, 7, 7, 128)    65536       conv_pad_19_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_19_bn_1 (BatchNormalizatio (None, 7, 7, 128)    512         conv__19_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_19_relu_1 (Activation)     (None, 7, 7, 128)    0           conv_19_bn_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv__19_2 (Conv2D)             (None, 3, 3, 256)    294912      conv_19_relu_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_19_bn_2 (BatchNormalizatio (None, 3, 3, 256)    1024        conv__19_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_19_relu_2 (Activation)     (None, 3, 3, 256)    0           conv_19_bn_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_20_1 (ZeroPadding2D)   (None, 5, 5, 256)    0           conv_19_relu_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv__20_1 (Conv2D)             (None, 5, 5, 128)    32768       conv_pad_20_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_20_bn_1 (BatchNormalizatio (None, 5, 5, 128)    512         conv__20_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_20_relu_1 (Activation)     (None, 5, 5, 128)    0           conv_20_bn_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv__20_2 (Conv2D)             (None, 2, 2, 256)    294912      conv_20_relu_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_20_bn_2 (BatchNormalizatio (None, 2, 2, 256)    1024        conv__20_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_20_relu_2 (Activation)     (None, 2, 2, 256)    0           conv_20_bn_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_21_1 (ZeroPadding2D)   (None, 4, 4, 256)    0           conv_20_relu_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv__21_1 (Conv2D)             (None, 4, 4, 64)     16384       conv_pad_21_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_21_bn_1 (BatchNormalizatio (None, 4, 4, 64)     256         conv__21_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_21_relu_1 (Activation)     (None, 4, 4, 64)     0           conv_21_bn_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv__21_2 (Conv2D)             (None, 1, 1, 128)    73728       conv_21_relu_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv13_mbox_conf (Conv2D)       (None, 19, 19, 8)    51848       model_1[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv17_mbox_conf (Conv2D)       (None, 10, 10, 12)   155532      stage4/block4/add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv18_2_mbox_conf (Conv2D)     (None, 5, 5, 12)     55308       conv__18_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv19_2_mbox_conf (Conv2D)     (None, 3, 3, 12)     27660       conv__19_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv20_2_mbox_conf (Conv2D)     (None, 2, 2, 8)      18440       conv__20_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv21_2_mbox_conf (Conv2D)     (None, 1, 1, 8)      9224        conv__21_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv13_mbox_loc (Conv2D)        (None, 19, 19, 16)   103696      model_1[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv17_mbox_loc (Conv2D)        (None, 10, 10, 24)   311064      stage4/block4/add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv18_2_mbox_loc (Conv2D)      (None, 5, 5, 24)     110616      conv__18_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv19_2_mbox_loc (Conv2D)      (None, 3, 3, 24)     55320       conv__19_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv20_2_mbox_loc (Conv2D)      (None, 2, 2, 16)     36880       conv__20_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv21_2_mbox_loc (Conv2D)      (None, 1, 1, 16)     18448       conv__21_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv13_mbox_conf_reshape (Resha (None, 1444, 2)      0           conv13_mbox_conf[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv17_mbox_conf_reshape (Resha (None, 600, 2)       0           conv17_mbox_conf[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv18_2_mbox_conf_reshape (Res (None, 150, 2)       0           conv18_2_mbox_conf[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv19_2_mbox_conf_reshape (Res (None, 54, 2)        0           conv19_2_mbox_conf[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv20_2_mbox_conf_reshape (Res (None, 16, 2)        0           conv20_2_mbox_conf[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv21_2_mbox_conf_reshape (Res (None, 4, 2)         0           conv21_2_mbox_conf[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv13_mbox_priorbox (AnchorBox (None, 19, 19, 4, 8) 0           conv13_mbox_loc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv17_mbox_priorbox (AnchorBox (None, 10, 10, 6, 8) 0           conv17_mbox_loc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv18_2_mbox_priorbox (AnchorB (None, 5, 5, 6, 8)   0           conv18_2_mbox_loc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv19_2_mbox_priorbox (AnchorB (None, 3, 3, 6, 8)   0           conv19_2_mbox_loc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv20_2_mbox_priorbox (AnchorB (None, 2, 2, 4, 8)   0           conv20_2_mbox_loc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv21_2_mbox_priorbox (AnchorB (None, 1, 1, 4, 8)   0           conv21_2_mbox_loc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "mbox_conf (Concatenate)         (None, 2268, 2)      0           conv13_mbox_conf_reshape[0][0]   \n",
      "                                                                 conv17_mbox_conf_reshape[0][0]   \n",
      "                                                                 conv18_2_mbox_conf_reshape[0][0] \n",
      "                                                                 conv19_2_mbox_conf_reshape[0][0] \n",
      "                                                                 conv20_2_mbox_conf_reshape[0][0] \n",
      "                                                                 conv21_2_mbox_conf_reshape[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv13_mbox_loc_reshape (Reshap (None, 1444, 4)      0           conv13_mbox_loc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv17_mbox_loc_reshape (Reshap (None, 600, 4)       0           conv17_mbox_loc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv18_2_mbox_loc_reshape (Resh (None, 150, 4)       0           conv18_2_mbox_loc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv19_2_mbox_loc_reshape (Resh (None, 54, 4)        0           conv19_2_mbox_loc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv20_2_mbox_loc_reshape (Resh (None, 16, 4)        0           conv20_2_mbox_loc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv21_2_mbox_loc_reshape (Resh (None, 4, 4)         0           conv21_2_mbox_loc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv13_mbox_priorbox_reshape (R (None, 1444, 8)      0           conv13_mbox_priorbox[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv17_mbox_priorbox_reshape (R (None, 600, 8)       0           conv17_mbox_priorbox[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv18_2_mbox_priorbox_reshape  (None, 150, 8)       0           conv18_2_mbox_priorbox[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv19_2_mbox_priorbox_reshape  (None, 54, 8)        0           conv19_2_mbox_priorbox[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv20_2_mbox_priorbox_reshape  (None, 16, 8)        0           conv20_2_mbox_priorbox[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv21_2_mbox_priorbox_reshape  (None, 4, 8)         0           conv21_2_mbox_priorbox[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mbox_conf_softmax (Activation)  (None, 2268, 2)      0           mbox_conf[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "mbox_loc (Concatenate)          (None, 2268, 4)      0           conv13_mbox_loc_reshape[0][0]    \n",
      "                                                                 conv17_mbox_loc_reshape[0][0]    \n",
      "                                                                 conv18_2_mbox_loc_reshape[0][0]  \n",
      "                                                                 conv19_2_mbox_loc_reshape[0][0]  \n",
      "                                                                 conv20_2_mbox_loc_reshape[0][0]  \n",
      "                                                                 conv21_2_mbox_loc_reshape[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mbox_priorbox (Concatenate)     (None, 2268, 8)      0           conv13_mbox_priorbox_reshape[0][0\n",
      "                                                                 conv17_mbox_priorbox_reshape[0][0\n",
      "                                                                 conv18_2_mbox_priorbox_reshape[0]\n",
      "                                                                 conv19_2_mbox_priorbox_reshape[0]\n",
      "                                                                 conv20_2_mbox_priorbox_reshape[0]\n",
      "                                                                 conv21_2_mbox_priorbox_reshape[0]\n",
      "__________________________________________________________________________________________________\n",
      "predictions (Concatenate)       (None, 2268, 14)     0           mbox_conf_softmax[0][0]          \n",
      "                                                                 mbox_loc[0][0]                   \n",
      "                                                                 mbox_priorbox[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 5,344,916\n",
      "Trainable params: 5,305,044\n",
      "Non-trainable params: 39,872\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generator for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images into memory: 100%|██████████| 6469/6469 [00:33<00:00, 192.25it/s]\n",
      "Loading images into memory: 100%|██████████| 1025/1025 [00:05<00:00, 191.99it/s]\n",
      "Number of images in the training dataset:\t  6469\n",
      "Number of images in the validation dataset:\t  1025\n"
     ]
    }
   ],
   "source": [
    "# 1: Instantiate two `DataGenerator` objects: One for training, one for validation.\n",
    "\n",
    "# Optional: If you have enough memory, consider loading the images into memory for the reasons explained above.\n",
    "\n",
    "train_dataset = DataGenerator(load_images_into_memory=True, hdf5_dataset_path=None)\n",
    "val_dataset = DataGenerator(load_images_into_memory=True, hdf5_dataset_path=None)\n",
    "\n",
    "# 2: Parse the image and label lists for the training and validation datasets.\n",
    "\n",
    "# TODO: Set the paths to your dataset here.\n",
    "\n",
    "# Images\n",
    "images_dir = data_path + 'PASCAL'\n",
    "#images_dir = data_path + 'COCO'\n",
    "\n",
    "# Ground truth\n",
    "#train_labels_filename = preprocess_path + '/PASCAL_train.csv'\n",
    "train_labels_filename = preprocess_path + '/PASCAL_train_val.csv'\n",
    "val_labels_filename   = preprocess_path + '/PASCAL_val.csv'\n",
    "\n",
    "train_dataset.parse_csv(images_dir=images_dir,\n",
    "                        labels_filename=train_labels_filename,\n",
    "                        input_format=['image_name', 'xmin', 'xmax', 'ymin', 'ymax', 'class_id'], # This is the order of the first six columns in the CSV file that contains the labels for your dataset. If your labels are in XML format, maybe the XML parser will be helpful, check the documentation.\n",
    "                        include_classes='all')\n",
    "\n",
    "val_dataset.parse_csv(#images_dir=images_dir,\n",
    "                      data_path + 'PASCAL',\n",
    "                      labels_filename=val_labels_filename,\n",
    "                      input_format=['image_name', 'xmin', 'xmax', 'ymin', 'ymax', 'class_id'],\n",
    "                      include_classes='all')\n",
    "\n",
    "# Get the number of samples in the training and validations datasets.\n",
    "train_dataset_size = train_dataset.get_dataset_size()\n",
    "val_dataset_size   = val_dataset.get_dataset_size()\n",
    "\n",
    "print(\"Number of images in the training dataset:\\t{:>6}\".format(train_dataset_size))\n",
    "print(\"Number of images in the validation dataset:\\t{:>6}\".format(val_dataset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the training dataset:\t  6469\n",
      "Number of images in the validation dataset:\t  1025\n"
     ]
    }
   ],
   "source": [
    "# 3: Set the batch size.\n",
    "batch_size = 32 # Change the batch size if you like, or if you run into GPU memory issues.\n",
    "\n",
    "# 4: Set the image transformations for pre-processing and data augmentation options.\n",
    "# For the training generator:\n",
    "ssd_data_augmentation = SSDDataAugmentation(img_height=img_height,\n",
    "                                            img_width=img_width,\n",
    "                                            background=mean_color)\n",
    "\n",
    "# For the validation generator:\n",
    "convert_to_3_channels = ConvertTo3Channels()\n",
    "resize = Resize(height=img_height, width=img_width)\n",
    "\n",
    "# 5: Instantiate an encoder that can encode ground truth labels into the format needed by the SSD loss function.\n",
    "# The encoder constructor needs the spatial dimensions of the model's predictor layers to create the anchor boxes.\n",
    "predictor_sizes = [model.get_layer('conv13_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv17_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv18_2_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv19_2_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv20_2_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv21_2_mbox_conf').output_shape[1:3]]\n",
    "\n",
    "ssd_input_encoder = SSDInputEncoder(img_height=img_height,\n",
    "                                    img_width=img_width,\n",
    "                                    n_classes=n_classes,\n",
    "                                    predictor_sizes=predictor_sizes,\n",
    "                                    scales=scales,\n",
    "                                    aspect_ratios_per_layer=aspect_ratios,\n",
    "                                    two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                                    steps=steps,\n",
    "                                    offsets=offsets,\n",
    "                                    clip_boxes=clip_boxes,\n",
    "                                    variances=variances,\n",
    "                                    matching_type='multi',\n",
    "                                    pos_iou_threshold=0.5,\n",
    "                                    neg_iou_limit=0.5,\n",
    "                                    normalize_coords=normalize_coords)\n",
    "\n",
    "# 6: Create the generator handles that will be passed to Keras' `fit_generator()` function.\n",
    "train_generator = train_dataset.generate(batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         transformations=[ssd_data_augmentation],\n",
    "                                         label_encoder=ssd_input_encoder,\n",
    "                                         returns={'processed_images',\n",
    "                                                  'encoded_labels'},\n",
    "                                         keep_images_without_gt=False)\n",
    "\n",
    "val_generator = val_dataset.generate(batch_size=batch_size,\n",
    "                                     shuffle=False,\n",
    "                                     transformations=[convert_to_3_channels,\n",
    "                                                      resize],\n",
    "                                     label_encoder=ssd_input_encoder,\n",
    "                                     returns={'processed_images',\n",
    "                                              'encoded_labels'},\n",
    "                                     keep_images_without_gt=False)\n",
    "\n",
    "# Get the number of samples in the training and validations datasets.\n",
    "train_dataset_size = train_dataset.get_dataset_size()\n",
    "val_dataset_size   = val_dataset.get_dataset_size()\n",
    "\n",
    "print(\"Number of images in the training dataset:\\t{:>6}\".format(train_dataset_size))\n",
    "print(\"Number of images in the validation dataset:\\t{:>6}\".format(val_dataset_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remaining training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a learning rate schedule.\n",
    "def lr_schedule(epoch):\n",
    "    if epoch < 60:\n",
    "        return 0.001\n",
    "    elif epoch < 70:\n",
    "        return 0.0001\n",
    "    else:\n",
    "        return 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING MODEL WITH LEARNING RATE: 0.01\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 129s 646ms/step - loss: 119.5895 - val_loss: 107.5510\n",
      "Number of images: 1025\n",
      "Presicion: 0.012\n",
      "Recall: 0.1561\n",
      "F1 score: 0.0223\n",
      "F1 score: 0.022255618821040844\n",
      "Improve F1 score from -inf to 0.022255618821040844\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 112s 559ms/step - loss: 107.4597 - val_loss: 106.7861\n",
      "Number of images: 1025\n",
      "Presicion: 0.014\n",
      "Recall: 0.178\n",
      "F1 score: 0.0259\n",
      "F1 score: 0.025949110973929528\n",
      "Improve F1 score from 0.022255618821040844 to 0.025949110973929528\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 113s 567ms/step - loss: 110.2785 - val_loss: 526226.5110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aldo/Documents/ssd/ssd_encoder_decoder/ssd_output_decoder.py:175: RuntimeWarning: overflow encountered in exp\n",
      "  y_pred_decoded_raw[:,:,[-2,-1]] = np.exp(y_pred_decoded_raw[:,:,[-2,-1]] * y_pred[:,:,[-2,-1]]) # exp(ln(w(pred)/w(anchor)) / w_variance * w_variance) == w(pred) / w(anchor), exp(ln(h(pred)/h(anchor)) / h_variance * h_variance) == h(pred) / h(anchor)\n",
      "/home/aldo/Documents/ssd/ssd_encoder_decoder/ssd_output_decoder.py:197: RuntimeWarning: overflow encountered in multiply\n",
      "  y_pred_decoded_raw[:,:,[-4,-2]] *= img_width # Convert xmin, xmax back to absolute coordinates\n",
      "/home/aldo/Documents/ssd/ssd_encoder_decoder/ssd_output_decoder.py:198: RuntimeWarning: overflow encountered in multiply\n",
      "  y_pred_decoded_raw[:,:,[-3,-1]] *= img_height # Convert ymin, ymax back to absolute coordinates\n",
      "/home/aldo/Documents/ssd/bounding_box_utils/bounding_box_utils.py:378: RuntimeWarning: overflow encountered in multiply\n",
      "  boxes1_areas = (boxes1[:,xmax] - boxes1[:,xmin] + d) * (boxes1[:,ymax] - boxes1[:,ymin] + d)\n",
      "/home/aldo/Documents/ssd/bounding_box_utils/bounding_box_utils.py:378: RuntimeWarning: invalid value encountered in multiply\n",
      "  boxes1_areas = (boxes1[:,xmax] - boxes1[:,xmin] + d) * (boxes1[:,ymax] - boxes1[:,ymin] + d)\n",
      "/home/aldo/Documents/ssd/bounding_box_utils/bounding_box_utils.py:383: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return intersection_areas / union_areas\n",
      "/home/aldo/Documents/ssd/ssd_encoder_decoder/ssd_output_decoder.py:91: RuntimeWarning: invalid value encountered in less_equal\n",
      "  boxes_left = boxes_left[similarities <= iou_threshold] # ...so that we can remove the ones that overlap too much with the maximum box\n",
      "/home/aldo/Documents/ssd/bounding_box_utils/bounding_box_utils.py:280: RuntimeWarning: overflow encountered in multiply\n",
      "  return side_lengths[:,0] * side_lengths[:,1]\n",
      "/home/aldo/Documents/ssd/bounding_box_utils/bounding_box_utils.py:379: RuntimeWarning: overflow encountered in multiply\n",
      "  boxes2_areas = (boxes2[:,xmax] - boxes2[:,xmin] + d) * (boxes2[:,ymax] - boxes2[:,ymin] + d)\n",
      "/home/aldo/Documents/ssd/bounding_box_utils/bounding_box_utils.py:381: RuntimeWarning: invalid value encountered in subtract\n",
      "  union_areas = boxes1_areas + boxes2_areas - intersection_areas\n",
      "/home/aldo/Documents/ssd/bounding_box_utils/bounding_box_utils.py:280: RuntimeWarning: invalid value encountered in multiply\n",
      "  return side_lengths[:,0] * side_lengths[:,1]\n",
      "/home/aldo/Documents/ssd/bounding_box_utils/bounding_box_utils.py:379: RuntimeWarning: invalid value encountered in multiply\n",
      "  boxes2_areas = (boxes2[:,xmax] - boxes2[:,xmin] + d) * (boxes2[:,ymax] - boxes2[:,ymin] + d)\n",
      "/home/aldo/Documents/ssd/bounding_box_utils/bounding_box_utils.py:378: RuntimeWarning: overflow encountered in subtract\n",
      "  boxes1_areas = (boxes1[:,xmax] - boxes1[:,xmin] + d) * (boxes1[:,ymax] - boxes1[:,ymin] + d)\n",
      "/home/aldo/Documents/ssd/bounding_box_utils/bounding_box_utils.py:278: RuntimeWarning: overflow encountered in subtract\n",
      "  side_lengths = np.maximum(0, max_xy - min_xy + d)\n",
      "/home/aldo/Documents/ssd/bounding_box_utils/bounding_box_utils.py:379: RuntimeWarning: overflow encountered in subtract\n",
      "  boxes2_areas = (boxes2[:,xmax] - boxes2[:,xmin] + d) * (boxes2[:,ymax] - boxes2[:,ymin] + d)\n",
      "/home/aldo/Documents/ssd/bounding_box_utils/bounding_box_utils.py:381: RuntimeWarning: overflow encountered in add\n",
      "  union_areas = boxes1_areas + boxes2_areas - intersection_areas\n",
      "/home/aldo/Documents/ssd/extra_files/helper.py:213: RuntimeWarning: overflow encountered in double_scalars\n",
      "  b = [box[0], box[1], box[2], box[3], box[4] - box[2], box[5] - box[3]]\n",
      "/home/aldo/Documents/ssd/extra_files/helper.py:230: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  yB = min(boxA[3] + boxA[1], boxB[3] + boxB[1])\n",
      "/home/aldo/Documents/ssd/extra_files/helper.py:237: RuntimeWarning: overflow encountered in double_scalars\n",
      "  boxAArea = boxA[2] * boxA[3]\n",
      "/home/aldo/Documents/ssd/extra_files/helper.py:229: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  xB = min(boxA[2] + boxA[0], boxB[2] + boxB[0])\n",
      "/home/aldo/Documents/ssd/extra_files/helper.py:237: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  boxAArea = boxA[2] * boxA[3]\n",
      "/home/aldo/Documents/ssd/extra_files/helper.py:238: RuntimeWarning: overflow encountered in double_scalars\n",
      "  boxBArea = boxB[2] * boxB[3]\n",
      "/home/aldo/Documents/ssd/extra_files/helper.py:238: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  boxBArea = boxB[2] * boxB[3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 1025\n",
      "Presicion: 0.0002\n",
      "Recall: 0.0058\n",
      "F1 score: 0.0004\n",
      "F1 score: 0.0004355285849459122\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 114s 570ms/step - loss: 108.8831 - val_loss: 123.8342\n",
      "Number of images: 1025\n",
      "Presicion: 0.0247\n",
      "Recall: 0.2375\n",
      "F1 score: 0.0447\n",
      "F1 score: 0.04470209956532777\n",
      "Improve F1 score from 0.025949110973929528 to 0.04470209956532777\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 111s 557ms/step - loss: 109.3710 - val_loss: 137.2526\n",
      "Number of images: 1025\n",
      "Presicion: 0.0086\n",
      "Recall: 0.1738\n",
      "F1 score: 0.0165\n",
      "F1 score: 0.016472913716781102\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 108s 538ms/step - loss: 85.1231 - val_loss: 1297575.5532\n",
      "Number of images: 1025\n",
      "Presicion: 0.0243\n",
      "Recall: 0.099\n",
      "F1 score: 0.039\n",
      "F1 score: 0.039018634988945505\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 36.6497 - val_loss: 1632.7361\n",
      "Number of images: 1025\n",
      "Presicion: 0.1261\n",
      "Recall: 0.3251\n",
      "F1 score: 0.1817\n",
      "F1 score: 0.1816790244222341\n",
      "Improve F1 score from 0.04470209956532777 to 0.1816790244222341\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 37.3667 - val_loss: 38.6695\n",
      "Number of images: 1025\n",
      "Presicion: 0.1463\n",
      "Recall: 0.2947\n",
      "F1 score: 0.1956\n",
      "F1 score: 0.19555152810450288\n",
      "Improve F1 score from 0.1816790244222341 to 0.19555152810450288\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 108s 538ms/step - loss: 26.2985 - val_loss: 60.0625\n",
      "Number of images: 1025\n",
      "Presicion: 0.2628\n",
      "Recall: 0.1492\n",
      "F1 score: 0.1903\n",
      "F1 score: 0.19033039807008942\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 106s 532ms/step - loss: 24.3821 - val_loss: 31.8556\n",
      "Number of images: 1025\n",
      "Presicion: 0.1441\n",
      "Recall: 0.2305\n",
      "F1 score: 0.1774\n",
      "F1 score: 0.1773675616010905\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 108s 538ms/step - loss: 26.6543 - val_loss: 27.2299\n",
      "Number of images: 1025\n",
      "Presicion: 0.2747\n",
      "Recall: 0.1474\n",
      "F1 score: 0.1918\n",
      "F1 score: 0.19182321641780165\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 23.4067 - val_loss: 23.4379\n",
      "Number of images: 1025\n",
      "Presicion: 0.2744\n",
      "Recall: 0.1475\n",
      "F1 score: 0.1919\n",
      "F1 score: 0.19187967118461335\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 108s 539ms/step - loss: 22.8624 - val_loss: 23.0985\n",
      "Number of images: 1025\n",
      "Presicion: 0.156\n",
      "Recall: 0.1964\n",
      "F1 score: 0.1738\n",
      "F1 score: 0.17383810363379368\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 107s 537ms/step - loss: 23.7263 - val_loss: 28.7458\n",
      "Number of images: 1025\n",
      "Presicion: 0.2619\n",
      "Recall: 0.1506\n",
      "F1 score: 0.1912\n",
      "F1 score: 0.19121238200788232\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 109s 543ms/step - loss: 25.2213 - val_loss: 28.3239\n",
      "Number of images: 1025\n",
      "Presicion: 0.1409\n",
      "Recall: 0.2283\n",
      "F1 score: 0.1743\n",
      "F1 score: 0.17429772876946395\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 107s 537ms/step - loss: 23.6937 - val_loss: 24.6530\n",
      "Number of images: 1025\n",
      "Presicion: 0.2756\n",
      "Recall: 0.1479\n",
      "F1 score: 0.1925\n",
      "F1 score: 0.19248458529372006\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 107s 537ms/step - loss: 26.4699 - val_loss: 30.9109\n",
      "Number of images: 1025\n",
      "Presicion: 0.1576\n",
      "Recall: 0.1595\n",
      "F1 score: 0.1586\n",
      "F1 score: 0.15857284936497254\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 108s 539ms/step - loss: 25.0460 - val_loss: 25.0441\n",
      "Number of images: 1025\n",
      "Presicion: 0.2751\n",
      "Recall: 0.1476\n",
      "F1 score: 0.1922\n",
      "F1 score: 0.19215578893876264\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 107s 534ms/step - loss: 24.0193 - val_loss: 25.7790\n",
      "Number of images: 1025\n",
      "Presicion: 0.2748\n",
      "Recall: 0.1474\n",
      "F1 score: 0.1918\n",
      "F1 score: 0.19184031748913774\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 107s 536ms/step - loss: 24.9985 - val_loss: 85.8916\n",
      "Number of images: 1025\n",
      "Presicion: 0.2138\n",
      "Recall: 0.1554\n",
      "F1 score: 0.18\n",
      "F1 score: 0.1800151329940668\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 108s 539ms/step - loss: 31.6654 - val_loss: 1814.5064\n",
      "Number of images: 1025\n",
      "Presicion: 0.0716\n",
      "Recall: 0.1544\n",
      "F1 score: 0.0978\n",
      "F1 score: 0.09784900057026097\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 108s 539ms/step - loss: 29.9761 - val_loss: 37.1993\n",
      "Number of images: 1025\n",
      "Presicion: 0.2762\n",
      "Recall: 0.148\n",
      "F1 score: 0.1927\n",
      "F1 score: 0.1926912214181472\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 109s 543ms/step - loss: 22.5697 - val_loss: 21.3340\n",
      "Number of images: 1025\n",
      "Presicion: 0.2762\n",
      "Recall: 0.1481\n",
      "F1 score: 0.1928\n",
      "F1 score: 0.19284161932889787\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 107s 537ms/step - loss: 21.7078 - val_loss: 20.2788\n",
      "Number of images: 1025\n",
      "Presicion: 0.276\n",
      "Recall: 0.1484\n",
      "F1 score: 0.1931\n",
      "F1 score: 0.19305745417158937\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 107s 537ms/step - loss: 20.8229 - val_loss: 20.4243\n",
      "Number of images: 1025\n",
      "Presicion: 0.2763\n",
      "Recall: 0.1481\n",
      "F1 score: 0.1928\n",
      "F1 score: 0.19280912447377926\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 107s 536ms/step - loss: 20.3535 - val_loss: 21.5205\n",
      "Number of images: 1025\n",
      "Presicion: 0.2728\n",
      "Recall: 0.1475\n",
      "F1 score: 0.1915\n",
      "F1 score: 0.19145711181172212\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 108s 540ms/step - loss: 19.7348 - val_loss: 19.8061\n",
      "Number of images: 1025\n",
      "Presicion: 0.2751\n",
      "Recall: 0.1476\n",
      "F1 score: 0.1921\n",
      "F1 score: 0.1921087923575619\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 107s 535ms/step - loss: 19.6555 - val_loss: 19.5818\n",
      "Number of images: 1025\n",
      "Presicion: 0.2754\n",
      "Recall: 0.1478\n",
      "F1 score: 0.1924\n",
      "F1 score: 0.1923724392309414\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 108s 540ms/step - loss: 20.3450 - val_loss: 20.7468\n",
      "Number of images: 1025\n",
      "Presicion: 0.2762\n",
      "Recall: 0.1481\n",
      "F1 score: 0.1928\n",
      "F1 score: 0.1928445509110222\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 19.9788 - val_loss: 27435.6170\n",
      "Number of images: 1025\n",
      "Presicion: 0.0275\n",
      "Recall: 0.1152\n",
      "F1 score: 0.0444\n",
      "F1 score: 0.04439685237383317\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 107s 535ms/step - loss: 19.8743 - val_loss: 19.6163\n",
      "Number of images: 1025\n",
      "Presicion: 0.2743\n",
      "Recall: 0.1472\n",
      "F1 score: 0.1916\n",
      "F1 score: 0.1915839004798308\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 108s 538ms/step - loss: 20.5762 - val_loss: 22.5392\n",
      "Number of images: 1025\n",
      "Presicion: 0.2768\n",
      "Recall: 0.1486\n",
      "F1 score: 0.1934\n",
      "F1 score: 0.19341389776351173\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 107s 536ms/step - loss: 20.0912 - val_loss: 24.4450\n",
      "Number of images: 1025\n",
      "Presicion: 0.1468\n",
      "Recall: 0.2752\n",
      "F1 score: 0.1915\n",
      "F1 score: 0.19148580077143137\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 108s 539ms/step - loss: 24.9835 - val_loss: 20.4592\n",
      "Number of images: 1025\n",
      "Presicion: 0.2761\n",
      "Recall: 0.1481\n",
      "F1 score: 0.1928\n",
      "F1 score: 0.19279201323830022\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 107s 536ms/step - loss: 21.4438 - val_loss: 19.9787\n",
      "Number of images: 1025\n",
      "Presicion: 0.2756\n",
      "Recall: 0.1476\n",
      "F1 score: 0.1923\n",
      "F1 score: 0.19227284922036655\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 109s 544ms/step - loss: 20.7642 - val_loss: 21.8472\n",
      "Number of images: 1025\n",
      "Presicion: 0.2714\n",
      "Recall: 0.1474\n",
      "F1 score: 0.191\n",
      "F1 score: 0.19103294045179867\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 108s 539ms/step - loss: 22.2467 - val_loss: 29.3322\n",
      "Number of images: 1025\n",
      "Presicion: 0.2748\n",
      "Recall: 0.1475\n",
      "F1 score: 0.1919\n",
      "F1 score: 0.19191625200082715\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 107s 535ms/step - loss: 22.2245 - val_loss: 20.3562\n",
      "Number of images: 1025\n",
      "Presicion: 0.2749\n",
      "Recall: 0.1473\n",
      "F1 score: 0.1918\n",
      "F1 score: 0.1918372321641719\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 108s 540ms/step - loss: 20.7096 - val_loss: 20.2129\n",
      "Number of images: 1025\n",
      "Presicion: 0.2756\n",
      "Recall: 0.1477\n",
      "F1 score: 0.1924\n",
      "F1 score: 0.19236876592132798\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 108s 539ms/step - loss: 20.3254 - val_loss: 20.0648\n",
      "Number of images: 1025\n",
      "Presicion: 0.2744\n",
      "Recall: 0.1471\n",
      "F1 score: 0.1915\n",
      "F1 score: 0.1915336467248988\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 109s 546ms/step - loss: 60.5476 - val_loss: 114.6155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 1025\n",
      "Presicion: 0.0399\n",
      "Recall: 0.3282\n",
      "F1 score: 0.0712\n",
      "F1 score: 0.07120879861164414\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 108s 539ms/step - loss: 114.8885 - val_loss: 114.0511\n",
      "Number of images: 1025\n",
      "Presicion: 0.0725\n",
      "Recall: 0.4314\n",
      "F1 score: 0.1242\n",
      "F1 score: 0.12417522571742816\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 109s 543ms/step - loss: 114.7552 - val_loss: 114.1446\n",
      "Number of images: 1025\n",
      "Presicion: 0.0431\n",
      "Recall: 0.3291\n",
      "F1 score: 0.0762\n",
      "F1 score: 0.07624126277674372\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 108s 541ms/step - loss: 94.5087 - val_loss: 24.7686\n",
      "Number of images: 1025\n",
      "Presicion: 0.1333\n",
      "Recall: 0.3165\n",
      "F1 score: 0.1876\n",
      "F1 score: 0.18758850703924468\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 108s 542ms/step - loss: 23.2906 - val_loss: 121.6824\n",
      "Number of images: 1025\n",
      "Presicion: 0.0507\n",
      "Recall: 0.3604\n",
      "F1 score: 0.0888\n",
      "F1 score: 0.08883109959938425\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 109s 545ms/step - loss: 115.7939 - val_loss: 113.8785\n",
      "Number of images: 1025\n",
      "Presicion: 0.0561\n",
      "Recall: 0.3326\n",
      "F1 score: 0.0959\n",
      "F1 score: 0.09593446620779833\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 108s 538ms/step - loss: 42.3006 - val_loss: 42848.6700\n",
      "Number of images: 1025\n",
      "Presicion: 0.0105\n",
      "Recall: 0.0635\n",
      "F1 score: 0.018\n",
      "F1 score: 0.018011616122145135\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 107s 535ms/step - loss: 23.2378 - val_loss: 39.5399\n",
      "Number of images: 1025\n",
      "Presicion: 0.224\n",
      "Recall: 0.1493\n",
      "F1 score: 0.1792\n",
      "F1 score: 0.17916980727666404\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 108s 541ms/step - loss: 23.5746 - val_loss: 27.7164\n",
      "Number of images: 1025\n",
      "Presicion: 0.2723\n",
      "Recall: 0.147\n",
      "F1 score: 0.1909\n",
      "F1 score: 0.19091168801746514\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 108s 541ms/step - loss: 20.5991 - val_loss: 20.1023\n",
      "Number of images: 1025\n",
      "Presicion: 0.2625\n",
      "Recall: 0.1477\n",
      "F1 score: 0.189\n",
      "F1 score: 0.18902827898560381\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 108s 541ms/step - loss: 20.0608 - val_loss: 20.1916\n",
      "Number of images: 1025\n",
      "Presicion: 0.2741\n",
      "Recall: 0.1476\n",
      "F1 score: 0.1919\n",
      "F1 score: 0.19190474546653088\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 107s 535ms/step - loss: 20.2051 - val_loss: 19.5377\n",
      "Number of images: 1025\n",
      "Presicion: 0.2667\n",
      "Recall: 0.1478\n",
      "F1 score: 0.1902\n",
      "F1 score: 0.19021366158961364\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 109s 545ms/step - loss: 23.7873 - val_loss: 36.7683\n",
      "Number of images: 1025\n",
      "Presicion: 0.1276\n",
      "Recall: 0.1543\n",
      "F1 score: 0.1397\n",
      "F1 score: 0.13969546595791052\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 108s 538ms/step - loss: 24.1945 - val_loss: 32.3297\n",
      "Number of images: 1025\n",
      "Presicion: 0.2253\n",
      "Recall: 0.1484\n",
      "F1 score: 0.1789\n",
      "F1 score: 0.17891643927387568\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 108s 542ms/step - loss: 20.8240 - val_loss: 21.8026\n",
      "Number of images: 1025\n",
      "Presicion: 0.2748\n",
      "Recall: 0.1475\n",
      "F1 score: 0.192\n",
      "F1 score: 0.19198024162614447\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 108s 541ms/step - loss: 22.0056 - val_loss: 21.7334\n",
      "Number of images: 1025\n",
      "Presicion: 0.2702\n",
      "Recall: 0.1474\n",
      "F1 score: 0.1908\n",
      "F1 score: 0.1907631621621896\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 108s 539ms/step - loss: 20.2566 - val_loss: 21.3379\n",
      "Number of images: 1025\n",
      "Presicion: 0.2744\n",
      "Recall: 0.1475\n",
      "F1 score: 0.1919\n",
      "F1 score: 0.19187943692532236\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 109s 543ms/step - loss: 20.9766 - val_loss: 19.7353\n",
      "Number of images: 1025\n",
      "Presicion: 0.2712\n",
      "Recall: 0.1474\n",
      "F1 score: 0.191\n",
      "F1 score: 0.19100397827305518\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 108s 538ms/step - loss: 20.0878 - val_loss: 19.6738\n",
      "Number of images: 1025\n",
      "Presicion: 0.2758\n",
      "Recall: 0.148\n",
      "F1 score: 0.1926\n",
      "F1 score: 0.19264658323260753\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 109s 543ms/step - loss: 20.8518 - val_loss: 23.2444\n",
      "Number of images: 1025\n",
      "Presicion: 0.2562\n",
      "Recall: 0.1471\n",
      "F1 score: 0.1869\n",
      "F1 score: 0.18692265076745979\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 107s 535ms/step - loss: 20.7847 - val_loss: 20.0763\n",
      "Number of images: 1025\n",
      "Presicion: 0.2318\n",
      "Recall: 0.1482\n",
      "F1 score: 0.1808\n",
      "F1 score: 0.18076819844527708\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 108s 542ms/step - loss: 20.0198 - val_loss: 23.4115\n",
      "Number of images: 1025\n",
      "Presicion: 0.1775\n",
      "Recall: 0.1477\n",
      "F1 score: 0.1613\n",
      "F1 score: 0.16125300416895624\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 106s 530ms/step - loss: 19.7486 - val_loss: 26.6648\n",
      "Number of images: 1025\n",
      "Presicion: 0.1581\n",
      "Recall: 0.1486\n",
      "F1 score: 0.1532\n",
      "F1 score: 0.15320144214540207\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 108s 538ms/step - loss: 26.1728 - val_loss: 21.6749\n",
      "Number of images: 1025\n",
      "Presicion: 0.2281\n",
      "Recall: 0.1491\n",
      "F1 score: 0.1803\n",
      "F1 score: 0.180325750080694\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 107s 535ms/step - loss: 21.1282 - val_loss: 38.8560\n",
      "Number of images: 1025\n",
      "Presicion: 0.1484\n",
      "Recall: 0.1525\n",
      "F1 score: 0.1504\n",
      "F1 score: 0.15041336939237393\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 108s 542ms/step - loss: 20.3842 - val_loss: 19.4527\n",
      "Number of images: 1025\n",
      "Presicion: 0.2763\n",
      "Recall: 0.1484\n",
      "F1 score: 0.1931\n",
      "F1 score: 0.193083973971137\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 108s 541ms/step - loss: 19.8888 - val_loss: 19.4313\n",
      "Number of images: 1025\n",
      "Presicion: 0.2753\n",
      "Recall: 0.1477\n",
      "F1 score: 0.1922\n",
      "F1 score: 0.1922318360882573\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 108s 539ms/step - loss: 20.0416 - val_loss: 19.9212\n",
      "Number of images: 1025\n",
      "Presicion: 0.2703\n",
      "Recall: 0.1476\n",
      "F1 score: 0.191\n",
      "F1 score: 0.19098024642596534\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 107s 535ms/step - loss: 19.7256 - val_loss: 19.5988\n",
      "Number of images: 1025\n",
      "Presicion: 0.2568\n",
      "Recall: 0.1487\n",
      "F1 score: 0.1884\n",
      "F1 score: 0.1883507719634402\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 109s 543ms/step - loss: 81.9012 - val_loss: 114.0597\n",
      "Number of images: 1025\n",
      "Presicion: 0.0385\n",
      "Recall: 0.3091\n",
      "F1 score: 0.0685\n",
      "F1 score: 0.06850709559777116\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 108s 538ms/step - loss: 114.8714 - val_loss: 113.9289\n",
      "Number of images: 1025\n",
      "Presicion: 0.0687\n",
      "Recall: 0.4146\n",
      "F1 score: 0.1179\n",
      "F1 score: 0.11792093322755143\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 108s 540ms/step - loss: 114.1706 - val_loss: 113.5361\n",
      "Number of images: 1025\n",
      "Presicion: 0.0642\n",
      "Recall: 0.4235\n",
      "F1 score: 0.1114\n",
      "F1 score: 0.11142795452005505\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 108s 541ms/step - loss: 111.5819 - val_loss: 145.7674\n",
      "Number of images: 1025\n",
      "Presicion: 0.0213\n",
      "Recall: 0.215\n",
      "F1 score: 0.0388\n",
      "F1 score: 0.03884126999080462\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 108s 542ms/step - loss: 106.7948 - val_loss: 106.6055\n",
      "Number of images: 1025\n",
      "Presicion: 0.0167\n",
      "Recall: 0.1857\n",
      "F1 score: 0.0306\n",
      "F1 score: 0.03064759241159941\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 108s 541ms/step - loss: 107.0168 - val_loss: 107.9945\n",
      "Number of images: 1025\n",
      "Presicion: 0.013\n",
      "Recall: 0.1721\n",
      "F1 score: 0.0242\n",
      "F1 score: 0.02422227263737463\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 108s 540ms/step - loss: 106.6436 - val_loss: 106.4493\n",
      "Number of images: 1025\n",
      "Presicion: 0.023\n",
      "Recall: 0.2326\n",
      "F1 score: 0.0418\n",
      "F1 score: 0.041841840934774305\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 107s 536ms/step - loss: 106.7244 - val_loss: 108.4117\n",
      "Number of images: 1025\n",
      "Presicion: 0.0156\n",
      "Recall: 0.1586\n",
      "F1 score: 0.0284\n",
      "F1 score: 0.028439663721894992\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 107s 534ms/step - loss: 106.7325 - val_loss: 106.7210\n",
      "Number of images: 1025\n",
      "Presicion: 0.0214\n",
      "Recall: 0.2208\n",
      "F1 score: 0.039\n",
      "F1 score: 0.03902595543405527\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 108s 538ms/step - loss: 106.5878 - val_loss: 106.9101\n",
      "Number of images: 1025\n",
      "Presicion: 0.0199\n",
      "Recall: 0.2091\n",
      "F1 score: 0.0364\n",
      "F1 score: 0.03635976068687963\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 109s 544ms/step - loss: 106.5729 - val_loss: 106.4682\n",
      "Number of images: 1025\n",
      "Presicion: 0.0207\n",
      "Recall: 0.1835\n",
      "F1 score: 0.0372\n",
      "F1 score: 0.03716185304128732\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 106s 530ms/step - loss: 106.8916 - val_loss: 108.3369\n",
      "Number of images: 1025\n",
      "Presicion: 0.0224\n",
      "Recall: 0.1981\n",
      "F1 score: 0.0403\n",
      "F1 score: 0.04026616661798287\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 108s 540ms/step - loss: 106.7188 - val_loss: 106.5181\n",
      "Number of images: 1025\n",
      "Presicion: 0.0217\n",
      "Recall: 0.2047\n",
      "F1 score: 0.0393\n",
      "F1 score: 0.03930509730603836\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 106.6557 - val_loss: 106.4270\n",
      "Number of images: 1025\n",
      "Presicion: 0.0188\n",
      "Recall: 0.178\n",
      "F1 score: 0.0339\n",
      "F1 score: 0.03394194243796122\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 108s 541ms/step - loss: 106.6158 - val_loss: 106.6566\n",
      "Number of images: 1025\n",
      "Presicion: 0.024\n",
      "Recall: 0.2161\n",
      "F1 score: 0.0432\n",
      "F1 score: 0.04317212935736591\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 109s 544ms/step - loss: 106.5269 - val_loss: 106.4236\n",
      "Number of images: 1025\n",
      "Presicion: 0.018\n",
      "Recall: 0.2021\n",
      "F1 score: 0.0331\n",
      "F1 score: 0.03312071158741022\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 110s 548ms/step - loss: 106.5472 - val_loss: 104.5204\n",
      "Number of images: 1025\n",
      "Presicion: 0.0094\n",
      "Recall: 0.1563\n",
      "F1 score: 0.0177\n",
      "F1 score: 0.01774018711024421\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 107s 536ms/step - loss: 106.5568 - val_loss: 103.6522\n",
      "Number of images: 1025\n",
      "Presicion: 0.0342\n",
      "Recall: 0.3303\n",
      "F1 score: 0.0619\n",
      "F1 score: 0.06190698936267312\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 108s 540ms/step - loss: 106.5086 - val_loss: 105.7462\n",
      "Number of images: 1025\n",
      "Presicion: 0.0241\n",
      "Recall: 0.2383\n",
      "F1 score: 0.0438\n",
      "F1 score: 0.04377982470986672\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 107s 535ms/step - loss: 106.5039 - val_loss: 106.2858\n",
      "Number of images: 1025\n",
      "Presicion: 0.0257\n",
      "Recall: 0.2534\n",
      "F1 score: 0.0466\n",
      "F1 score: 0.046627592884712236\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 108s 538ms/step - loss: 106.5051 - val_loss: 106.5389\n",
      "Number of images: 1025\n",
      "Presicion: 0.0505\n",
      "Recall: 0.3293\n",
      "F1 score: 0.0876\n",
      "F1 score: 0.08762939589875705\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 109s 545ms/step - loss: 106.5722 - val_loss: 106.3782\n",
      "Number of images: 1025\n",
      "Presicion: 0.0215\n",
      "Recall: 0.2102\n",
      "F1 score: 0.0389\n",
      "F1 score: 0.038935332653116356\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 107s 536ms/step - loss: 107.7563 - val_loss: 111.3688\n",
      "Number of images: 1025\n",
      "Presicion: 0.0136\n",
      "Recall: 0.2885\n",
      "F1 score: 0.026\n",
      "F1 score: 0.025968019328548943\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 108s 542ms/step - loss: 107.1475 - val_loss: 374.4982\n",
      "Number of images: 1025\n",
      "Presicion: 0.0095\n",
      "Recall: 0.1586\n",
      "F1 score: 0.0179\n",
      "F1 score: 0.017862364863861085\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 106s 532ms/step - loss: 107.2601 - val_loss: 107.1109\n",
      "Number of images: 1025\n",
      "Presicion: 0.0261\n",
      "Recall: 0.2998\n",
      "F1 score: 0.048\n",
      "F1 score: 0.04804192676740514\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 109s 544ms/step - loss: 106.6861 - val_loss: 99.8606\n",
      "Number of images: 1025\n",
      "Presicion: 0.037\n",
      "Recall: 0.2906\n",
      "F1 score: 0.0656\n",
      "F1 score: 0.0656337362842264\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 107s 535ms/step - loss: 106.9195 - val_loss: 613.8964\n",
      "Number of images: 1025\n",
      "Presicion: 0.0246\n",
      "Recall: 0.2739\n",
      "F1 score: 0.0452\n",
      "F1 score: 0.045195872424054775\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 108s 538ms/step - loss: 106.5369 - val_loss: 106.3925\n",
      "Number of images: 1025\n",
      "Presicion: 0.0498\n",
      "Recall: 0.3553\n",
      "F1 score: 0.0873\n",
      "F1 score: 0.08730088221674852\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 109s 543ms/step - loss: 106.5358 - val_loss: 106.7898\n",
      "Number of images: 1025\n",
      "Presicion: 0.0522\n",
      "Recall: 0.3496\n",
      "F1 score: 0.0908\n",
      "F1 score: 0.09083563535442327\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 107s 534ms/step - loss: 106.4628 - val_loss: 106.4683\n",
      "Number of images: 1025\n",
      "Presicion: 0.0419\n",
      "Recall: 0.3401\n",
      "F1 score: 0.0746\n",
      "F1 score: 0.07464561976518092\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 109s 545ms/step - loss: 106.5436 - val_loss: 105.6327\n",
      "Number of images: 1025\n",
      "Presicion: 0.0322\n",
      "Recall: 0.3034\n",
      "F1 score: 0.0582\n",
      "F1 score: 0.05819568435006013\n",
      "TRAINING MODEL WITH LEARNING RATE: 0.001\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 122s 610ms/step - loss: 23.1224 - val_loss: 88.1791\n",
      "Number of images: 1025\n",
      "Presicion: 0.1663\n",
      "Recall: 0.1002\n",
      "F1 score: 0.1251\n",
      "F1 score: 0.12507233871355797\n",
      "Improve F1 score from -inf to 0.12507233871355797\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 107s 534ms/step - loss: 8.1101 - val_loss: 6.2644\n",
      "Number of images: 1025\n",
      "Presicion: 0.0584\n",
      "Recall: 0.4506\n",
      "F1 score: 0.1034\n",
      "F1 score: 0.10342938257927524\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 107s 536ms/step - loss: 5.4428 - val_loss: 5.3383\n",
      "Number of images: 1025\n",
      "Presicion: 0.0909\n",
      "Recall: 0.4441\n",
      "F1 score: 0.1509\n",
      "F1 score: 0.1509150782410964\n",
      "Improve F1 score from 0.12507233871355797 to 0.1509150782410964\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 107s 536ms/step - loss: 5.1190 - val_loss: 5.1872\n",
      "Number of images: 1025\n",
      "Presicion: 0.0886\n",
      "Recall: 0.4644\n",
      "F1 score: 0.1488\n",
      "F1 score: 0.1487805151873184\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 108s 538ms/step - loss: 4.9650 - val_loss: 5.0134\n",
      "Number of images: 1025\n",
      "Presicion: 0.1059\n",
      "Recall: 0.4701\n",
      "F1 score: 0.1729\n",
      "F1 score: 0.17291166082245354\n",
      "Improve F1 score from 0.1509150782410964 to 0.17291166082245354\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 108s 540ms/step - loss: 4.9139 - val_loss: 7.7218\n",
      "Number of images: 1025\n",
      "Presicion: 0.0701\n",
      "Recall: 0.415\n",
      "F1 score: 0.1199\n",
      "F1 score: 0.11990832530260344\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 107s 534ms/step - loss: 5.2176 - val_loss: 5.3514\n",
      "Number of images: 1025\n",
      "Presicion: 0.0786\n",
      "Recall: 0.421\n",
      "F1 score: 0.1325\n",
      "F1 score: 0.1324997646264457\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 108s 539ms/step - loss: 4.7994 - val_loss: 4.8622\n",
      "Number of images: 1025\n",
      "Presicion: 0.0977\n",
      "Recall: 0.4644\n",
      "F1 score: 0.1614\n",
      "F1 score: 0.16143031103558653\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 107s 536ms/step - loss: 4.7412 - val_loss: 4.7457\n",
      "Number of images: 1025\n",
      "Presicion: 0.1069\n",
      "Recall: 0.4569\n",
      "F1 score: 0.1732\n",
      "F1 score: 0.1732066953380385\n",
      "Improve F1 score from 0.17291166082245354 to 0.1732066953380385\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 107s 534ms/step - loss: 4.6674 - val_loss: 4.6645\n",
      "Number of images: 1025\n",
      "Presicion: 0.0766\n",
      "Recall: 0.5115\n",
      "F1 score: 0.1333\n",
      "F1 score: 0.13330967927613593\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 106s 531ms/step - loss: 4.6313 - val_loss: 4.7098\n",
      "Number of images: 1025\n",
      "Presicion: 0.1028\n",
      "Recall: 0.4667\n",
      "F1 score: 0.1684\n",
      "F1 score: 0.1684370311793132\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 106s 530ms/step - loss: 4.5777 - val_loss: 4.6636\n",
      "Number of images: 1025\n",
      "Presicion: 0.0765\n",
      "Recall: 0.5201\n",
      "F1 score: 0.1334\n",
      "F1 score: 0.13341940103888925\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 107s 537ms/step - loss: 4.5508 - val_loss: 4.7757\n",
      "Number of images: 1025\n",
      "Presicion: 0.0836\n",
      "Recall: 0.5079\n",
      "F1 score: 0.1436\n",
      "F1 score: 0.14361436186517038\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 106s 532ms/step - loss: 4.5680 - val_loss: 4.6609\n",
      "Number of images: 1025\n",
      "Presicion: 0.0876\n",
      "Recall: 0.521\n",
      "F1 score: 0.15\n",
      "F1 score: 0.1499822739537522\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 107s 537ms/step - loss: 4.4852 - val_loss: 4.4903\n",
      "Number of images: 1025\n",
      "Presicion: 0.0655\n",
      "Recall: 0.5375\n",
      "F1 score: 0.1168\n",
      "F1 score: 0.11681364252724707\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 106s 531ms/step - loss: 4.4286 - val_loss: 4.5435\n",
      "Number of images: 1025\n",
      "Presicion: 0.0744\n",
      "Recall: 0.528\n",
      "F1 score: 0.1305\n",
      "F1 score: 0.13049298657007488\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 106s 530ms/step - loss: 4.4864 - val_loss: 4.5022\n",
      "Number of images: 1025\n",
      "Presicion: 0.0649\n",
      "Recall: 0.5334\n",
      "F1 score: 0.1158\n",
      "F1 score: 0.11577524307238884\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 107s 533ms/step - loss: 4.4921 - val_loss: 4.5352\n",
      "Number of images: 1025\n",
      "Presicion: 0.0662\n",
      "Recall: 0.5264\n",
      "F1 score: 0.1176\n",
      "F1 score: 0.11756536239827146\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 106s 531ms/step - loss: 4.4473 - val_loss: 4.4742\n",
      "Number of images: 1025\n",
      "Presicion: 0.0656\n",
      "Recall: 0.5321\n",
      "F1 score: 0.1168\n",
      "F1 score: 0.11675263412670212\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 107s 535ms/step - loss: 4.4789 - val_loss: 4.6191\n",
      "Number of images: 1025\n",
      "Presicion: 0.0502\n",
      "Recall: 0.5173\n",
      "F1 score: 0.0915\n",
      "F1 score: 0.09145362704492006\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 107s 535ms/step - loss: 4.4418 - val_loss: 4.4411\n",
      "Number of images: 1025\n",
      "Presicion: 0.0582\n",
      "Recall: 0.5333\n",
      "F1 score: 0.1049\n",
      "F1 score: 0.10491757169059956\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 4.3622 - val_loss: 4.3829\n",
      "Number of images: 1025\n",
      "Presicion: 0.0673\n",
      "Recall: 0.5378\n",
      "F1 score: 0.1196\n",
      "F1 score: 0.11959374897780661\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 107s 536ms/step - loss: 4.3928 - val_loss: 4.4374\n",
      "Number of images: 1025\n",
      "Presicion: 0.0735\n",
      "Recall: 0.5227\n",
      "F1 score: 0.1289\n",
      "F1 score: 0.1288562486589894\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 105s 527ms/step - loss: 5.0936 - val_loss: 12908.2538\n",
      "Number of images: 1025\n",
      "Presicion: 0.0021\n",
      "Recall: 0.0129\n",
      "F1 score: 0.0036\n",
      "F1 score: 0.003627106628983511\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 106s 528ms/step - loss: 6.5898 - val_loss: 153.1902\n",
      "Number of images: 1025\n",
      "Presicion: 0.1126\n",
      "Recall: 0.2956\n",
      "F1 score: 0.1631\n",
      "F1 score: 0.16306253562698633\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 106s 530ms/step - loss: 4.8927 - val_loss: 4.8424\n",
      "Number of images: 1025\n",
      "Presicion: 0.1009\n",
      "Recall: 0.4288\n",
      "F1 score: 0.1634\n",
      "F1 score: 0.1633657528976698\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 108s 539ms/step - loss: 4.7386 - val_loss: 4.6047\n",
      "Number of images: 1025\n",
      "Presicion: 0.0584\n",
      "Recall: 0.5259\n",
      "F1 score: 0.1052\n",
      "F1 score: 0.10519099128756818\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 109s 543ms/step - loss: 4.5657 - val_loss: 4.5044\n",
      "Number of images: 1025\n",
      "Presicion: 0.0617\n",
      "Recall: 0.5443\n",
      "F1 score: 0.1108\n",
      "F1 score: 0.11081212523133947\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 107s 537ms/step - loss: 4.5157 - val_loss: 4.5137\n",
      "Number of images: 1025\n",
      "Presicion: 0.0728\n",
      "Recall: 0.5165\n",
      "F1 score: 0.1276\n",
      "F1 score: 0.12764528346048634\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 108s 540ms/step - loss: 4.5258 - val_loss: 4.5190\n",
      "Number of images: 1025\n",
      "Presicion: 0.0882\n",
      "Recall: 0.5253\n",
      "F1 score: 0.1511\n",
      "F1 score: 0.15109712704529238\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 107s 537ms/step - loss: 4.4101 - val_loss: 4.4027\n",
      "Number of images: 1025\n",
      "Presicion: 0.0478\n",
      "Recall: 0.5422\n",
      "F1 score: 0.0879\n",
      "F1 score: 0.08785111958846868\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 107s 537ms/step - loss: 4.4897 - val_loss: 4.6015\n",
      "Number of images: 1025\n",
      "Presicion: 0.0648\n",
      "Recall: 0.4977\n",
      "F1 score: 0.1147\n",
      "F1 score: 0.11473321719514477\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 4.4153 - val_loss: 4.4352\n",
      "Number of images: 1025\n",
      "Presicion: 0.0533\n",
      "Recall: 0.5321\n",
      "F1 score: 0.0968\n",
      "F1 score: 0.09683096539896467\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 4.3448 - val_loss: 4.4234\n",
      "Number of images: 1025\n",
      "Presicion: 0.0585\n",
      "Recall: 0.5364\n",
      "F1 score: 0.1055\n",
      "F1 score: 0.10550958764096424\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 107s 534ms/step - loss: 4.3204 - val_loss: 4.3918\n",
      "Number of images: 1025\n",
      "Presicion: 0.0681\n",
      "Recall: 0.5454\n",
      "F1 score: 0.1211\n",
      "F1 score: 0.12108322193398778\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 106s 528ms/step - loss: 4.3079 - val_loss: 4.3880\n",
      "Number of images: 1025\n",
      "Presicion: 0.0715\n",
      "Recall: 0.551\n",
      "F1 score: 0.1266\n",
      "F1 score: 0.12662727378445243\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 108s 540ms/step - loss: 4.3049 - val_loss: 4.3009\n",
      "Number of images: 1025\n",
      "Presicion: 0.0609\n",
      "Recall: 0.5617\n",
      "F1 score: 0.1099\n",
      "F1 score: 0.10991530240718346\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 108s 541ms/step - loss: 4.3294 - val_loss: 4.3062\n",
      "Number of images: 1025\n",
      "Presicion: 0.0504\n",
      "Recall: 0.5579\n",
      "F1 score: 0.0925\n",
      "F1 score: 0.09246378406406115\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 106s 530ms/step - loss: 4.2567 - val_loss: 4.3186\n",
      "Number of images: 1025\n",
      "Presicion: 0.056\n",
      "Recall: 0.5491\n",
      "F1 score: 0.1017\n",
      "F1 score: 0.10165038982775138\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 108s 541ms/step - loss: 4.2826 - val_loss: 4.3125\n",
      "Number of images: 1025\n",
      "Presicion: 0.0659\n",
      "Recall: 0.5522\n",
      "F1 score: 0.1177\n",
      "F1 score: 0.11774647510027991\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 107s 535ms/step - loss: 4.2539 - val_loss: 4.3868\n",
      "Number of images: 1025\n",
      "Presicion: 0.0572\n",
      "Recall: 0.5529\n",
      "F1 score: 0.1037\n",
      "F1 score: 0.10365645385346423\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 108s 542ms/step - loss: 4.2978 - val_loss: 4.4005\n",
      "Number of images: 1025\n",
      "Presicion: 0.0931\n",
      "Recall: 0.5235\n",
      "F1 score: 0.1581\n",
      "F1 score: 0.15808839518546336\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 108s 540ms/step - loss: 4.2336 - val_loss: 4.3343\n",
      "Number of images: 1025\n",
      "Presicion: 0.0576\n",
      "Recall: 0.5646\n",
      "F1 score: 0.1045\n",
      "F1 score: 0.10454803560924845\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 108s 542ms/step - loss: 4.2169 - val_loss: 4.2906\n",
      "Number of images: 1025\n",
      "Presicion: 0.0601\n",
      "Recall: 0.5582\n",
      "F1 score: 0.1086\n",
      "F1 score: 0.1085817789023749\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 108s 539ms/step - loss: 4.2121 - val_loss: 4.3097\n",
      "Number of images: 1025\n",
      "Presicion: 0.1092\n",
      "Recall: 0.5215\n",
      "F1 score: 0.1806\n",
      "F1 score: 0.18063042354525569\n",
      "Improve F1 score from 0.1732066953380385 to 0.18063042354525569\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 109s 544ms/step - loss: 4.2668 - val_loss: 4.3145\n",
      "Number of images: 1025\n",
      "Presicion: 0.0968\n",
      "Recall: 0.5196\n",
      "F1 score: 0.1633\n",
      "F1 score: 0.16325335341344124\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 107s 535ms/step - loss: 4.2143 - val_loss: 4.3078\n",
      "Number of images: 1025\n",
      "Presicion: 0.0826\n",
      "Recall: 0.5259\n",
      "F1 score: 0.1427\n",
      "F1 score: 0.14274960788379887\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 108s 539ms/step - loss: 4.3068 - val_loss: 5.8649\n",
      "Number of images: 1025\n",
      "Presicion: 0.1748\n",
      "Recall: 0.3562\n",
      "F1 score: 0.2345\n",
      "F1 score: 0.23447699004301298\n",
      "Improve F1 score from 0.18063042354525569 to 0.23447699004301298\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 108s 540ms/step - loss: 4.3144 - val_loss: 4.2573\n",
      "Number of images: 1025\n",
      "Presicion: 0.0825\n",
      "Recall: 0.539\n",
      "F1 score: 0.1432\n",
      "F1 score: 0.14317082974337353\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 108s 541ms/step - loss: 4.2039 - val_loss: 4.2654\n",
      "Number of images: 1025\n",
      "Presicion: 0.0917\n",
      "Recall: 0.5069\n",
      "F1 score: 0.1552\n",
      "F1 score: 0.15523838567390577\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 107s 534ms/step - loss: 4.2951 - val_loss: 4.4158\n",
      "Number of images: 1025\n",
      "Presicion: 0.1579\n",
      "Recall: 0.4618\n",
      "F1 score: 0.2353\n",
      "F1 score: 0.23530610797973317\n",
      "Improve F1 score from 0.23447699004301298 to 0.23530610797973317\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 108s 538ms/step - loss: 4.2026 - val_loss: 4.2092\n",
      "Number of images: 1025\n",
      "Presicion: 0.0843\n",
      "Recall: 0.5418\n",
      "F1 score: 0.1459\n",
      "F1 score: 0.14593369847495702\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 4.1453 - val_loss: 4.2178\n",
      "Number of images: 1025\n",
      "Presicion: 0.063\n",
      "Recall: 0.5533\n",
      "F1 score: 0.1131\n",
      "F1 score: 0.11313609150784106\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 107s 537ms/step - loss: 4.1835 - val_loss: 4.2742\n",
      "Number of images: 1025\n",
      "Presicion: 0.0543\n",
      "Recall: 0.5563\n",
      "F1 score: 0.0989\n",
      "F1 score: 0.09889478944219657\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 109s 545ms/step - loss: 4.1469 - val_loss: 4.2052\n",
      "Number of images: 1025\n",
      "Presicion: 0.046\n",
      "Recall: 0.5623\n",
      "F1 score: 0.085\n",
      "F1 score: 0.08495741676168361\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 107s 536ms/step - loss: 4.1234 - val_loss: 4.2028\n",
      "Number of images: 1025\n",
      "Presicion: 0.1128\n",
      "Recall: 0.5234\n",
      "F1 score: 0.1856\n",
      "F1 score: 0.18558962327698003\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 109s 543ms/step - loss: 4.1144 - val_loss: 4.1930\n",
      "Number of images: 1025\n",
      "Presicion: 0.1007\n",
      "Recall: 0.5124\n",
      "F1 score: 0.1683\n",
      "F1 score: 0.168254174207619\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 107s 536ms/step - loss: 4.1000 - val_loss: 4.2163\n",
      "Number of images: 1025\n",
      "Presicion: 0.0473\n",
      "Recall: 0.5649\n",
      "F1 score: 0.0873\n",
      "F1 score: 0.08734676315654046\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 106s 531ms/step - loss: 4.0796 - val_loss: 4.2635\n",
      "Number of images: 1025\n",
      "Presicion: 0.0535\n",
      "Recall: 0.556\n",
      "F1 score: 0.0976\n",
      "F1 score: 0.09757205054867403\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 108s 538ms/step - loss: 4.0647 - val_loss: 4.1347\n",
      "Number of images: 1025\n",
      "Presicion: 0.0823\n",
      "Recall: 0.555\n",
      "F1 score: 0.1433\n",
      "F1 score: 0.14328309582909535\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 107s 537ms/step - loss: 4.0590 - val_loss: 4.2079\n",
      "Number of images: 1025\n",
      "Presicion: 0.0594\n",
      "Recall: 0.5369\n",
      "F1 score: 0.107\n",
      "F1 score: 0.10704048615447492\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 109s 547ms/step - loss: 4.3137 - val_loss: 4.8780\n",
      "Number of images: 1025\n",
      "Presicion: 0.16\n",
      "Recall: 0.3545\n",
      "F1 score: 0.2205\n",
      "F1 score: 0.22046361785695576\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 107s 535ms/step - loss: 4.4818 - val_loss: 4.6389\n",
      "Number of images: 1025\n",
      "Presicion: 0.1151\n",
      "Recall: 0.4459\n",
      "F1 score: 0.183\n",
      "F1 score: 0.18296151349400852\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 106s 528ms/step - loss: 4.2148 - val_loss: 4.3357\n",
      "Number of images: 1025\n",
      "Presicion: 0.0902\n",
      "Recall: 0.5112\n",
      "F1 score: 0.1534\n",
      "F1 score: 0.1533970698549741\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 106s 529ms/step - loss: 4.1446 - val_loss: 4.2185\n",
      "Number of images: 1025\n",
      "Presicion: 0.0558\n",
      "Recall: 0.5514\n",
      "F1 score: 0.1014\n",
      "F1 score: 0.10140469693310014\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 107s 536ms/step - loss: 4.1765 - val_loss: 4.1712\n",
      "Number of images: 1025\n",
      "Presicion: 0.1108\n",
      "Recall: 0.4866\n",
      "F1 score: 0.1805\n",
      "F1 score: 0.1804825854709815\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 108s 540ms/step - loss: 4.1433 - val_loss: 4.1623\n",
      "Number of images: 1025\n",
      "Presicion: 0.0971\n",
      "Recall: 0.5139\n",
      "F1 score: 0.1633\n",
      "F1 score: 0.16331301039436716\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 107s 535ms/step - loss: 4.1920 - val_loss: 4.3548\n",
      "Number of images: 1025\n",
      "Presicion: 0.0678\n",
      "Recall: 0.5195\n",
      "F1 score: 0.12\n",
      "F1 score: 0.1199637369882553\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 4.1773 - val_loss: 4.1505\n",
      "Number of images: 1025\n",
      "Presicion: 0.0517\n",
      "Recall: 0.5612\n",
      "F1 score: 0.0946\n",
      "F1 score: 0.0946100138214333\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 108s 540ms/step - loss: 4.0878 - val_loss: 4.2298\n",
      "Number of images: 1025\n",
      "Presicion: 0.1048\n",
      "Recall: 0.4988\n",
      "F1 score: 0.1733\n",
      "F1 score: 0.1732634231067293\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 107s 536ms/step - loss: 4.2388 - val_loss: 4.1930\n",
      "Number of images: 1025\n",
      "Presicion: 0.0752\n",
      "Recall: 0.522\n",
      "F1 score: 0.1315\n",
      "F1 score: 0.13148177400873126\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 108s 541ms/step - loss: 4.0803 - val_loss: 4.1429\n",
      "Number of images: 1025\n",
      "Presicion: 0.0444\n",
      "Recall: 0.5551\n",
      "F1 score: 0.0823\n",
      "F1 score: 0.0822610251318514\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 108s 540ms/step - loss: 4.0687 - val_loss: 4.1318\n",
      "Number of images: 1025\n",
      "Presicion: 0.0812\n",
      "Recall: 0.5543\n",
      "F1 score: 0.1416\n",
      "F1 score: 0.14163226296952294\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 106s 532ms/step - loss: 4.0243 - val_loss: 4.0845\n",
      "Number of images: 1025\n",
      "Presicion: 0.0592\n",
      "Recall: 0.5507\n",
      "F1 score: 0.1069\n",
      "F1 score: 0.10690325064159333\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 108s 538ms/step - loss: 4.0556 - val_loss: 4.1070\n",
      "Number of images: 1025\n",
      "Presicion: 0.121\n",
      "Recall: 0.5075\n",
      "F1 score: 0.1954\n",
      "F1 score: 0.19543999807698306\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 108s 539ms/step - loss: 4.0295 - val_loss: 4.0847\n",
      "Number of images: 1025\n",
      "Presicion: 0.1357\n",
      "Recall: 0.5167\n",
      "F1 score: 0.215\n",
      "F1 score: 0.21499650709560528\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 106s 531ms/step - loss: 4.0123 - val_loss: 4.0959\n",
      "Number of images: 1025\n",
      "Presicion: 0.0875\n",
      "Recall: 0.545\n",
      "F1 score: 0.1508\n",
      "F1 score: 0.15084168536191808\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 108s 539ms/step - loss: 4.0897 - val_loss: 4.7203\n",
      "Number of images: 1025\n",
      "Presicion: 0.0806\n",
      "Recall: 0.448\n",
      "F1 score: 0.1366\n",
      "F1 score: 0.13656048183116049\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 106s 530ms/step - loss: 4.2129 - val_loss: 4.1966\n",
      "Number of images: 1025\n",
      "Presicion: 0.0393\n",
      "Recall: 0.5501\n",
      "F1 score: 0.0734\n",
      "F1 score: 0.07339041384941697\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 107s 536ms/step - loss: 4.0978 - val_loss: 6.1905\n",
      "Number of images: 1025\n",
      "Presicion: 0.1567\n",
      "Recall: 0.341\n",
      "F1 score: 0.2148\n",
      "F1 score: 0.21477365924453312\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 106s 531ms/step - loss: 4.1625 - val_loss: 4.1337\n",
      "Number of images: 1025\n",
      "Presicion: 0.0423\n",
      "Recall: 0.5555\n",
      "F1 score: 0.0785\n",
      "F1 score: 0.07853091241517406\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 107s 537ms/step - loss: 4.0939 - val_loss: 4.2573\n",
      "Number of images: 1025\n",
      "Presicion: 0.127\n",
      "Recall: 0.4608\n",
      "F1 score: 0.1992\n",
      "F1 score: 0.19917552940685182\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 108s 539ms/step - loss: 4.0284 - val_loss: 4.1770\n",
      "Number of images: 1025\n",
      "Presicion: 0.036\n",
      "Recall: 0.5475\n",
      "F1 score: 0.0676\n",
      "F1 score: 0.06761532168744853\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 108s 540ms/step - loss: 4.0233 - val_loss: 4.1051\n",
      "Number of images: 1025\n",
      "Presicion: 0.0306\n",
      "Recall: 0.5517\n",
      "F1 score: 0.058\n",
      "F1 score: 0.05796932513042341\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 108s 541ms/step - loss: 3.9810 - val_loss: 4.0292\n",
      "Number of images: 1025\n",
      "Presicion: 0.0458\n",
      "Recall: 0.5571\n",
      "F1 score: 0.0846\n",
      "F1 score: 0.08457016126797873\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 106s 529ms/step - loss: 3.9948 - val_loss: 3.9941\n",
      "Number of images: 1025\n",
      "Presicion: 0.0548\n",
      "Recall: 0.5726\n",
      "F1 score: 0.1001\n",
      "F1 score: 0.1000746021748741\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 3.9793 - val_loss: 4.0318\n",
      "Number of images: 1025\n",
      "Presicion: 0.0389\n",
      "Recall: 0.5621\n",
      "F1 score: 0.0728\n",
      "F1 score: 0.072841217584251\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 109s 544ms/step - loss: 4.0196 - val_loss: 4.0711\n",
      "Number of images: 1025\n",
      "Presicion: 0.0386\n",
      "Recall: 0.5685\n",
      "F1 score: 0.0723\n",
      "F1 score: 0.07230435159659558\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 108s 538ms/step - loss: 3.9689 - val_loss: 4.0439\n",
      "Number of images: 1025\n",
      "Presicion: 0.078\n",
      "Recall: 0.547\n",
      "F1 score: 0.1365\n",
      "F1 score: 0.1365071931166726\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 109s 544ms/step - loss: 3.9728 - val_loss: 4.0734\n",
      "Number of images: 1025\n",
      "Presicion: 0.0738\n",
      "Recall: 0.5358\n",
      "F1 score: 0.1298\n",
      "F1 score: 0.12979900812928954\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 108s 539ms/step - loss: 3.9850 - val_loss: 4.0358\n",
      "Number of images: 1025\n",
      "Presicion: 0.0729\n",
      "Recall: 0.5645\n",
      "F1 score: 0.1292\n",
      "F1 score: 0.1291539057463006\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 107s 535ms/step - loss: 3.9465 - val_loss: 3.9912\n",
      "Number of images: 1025\n",
      "Presicion: 0.1149\n",
      "Recall: 0.5312\n",
      "F1 score: 0.189\n",
      "F1 score: 0.1889700803817484\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 107s 534ms/step - loss: 3.9626 - val_loss: 4.0234\n",
      "Number of images: 1025\n",
      "Presicion: 0.0794\n",
      "Recall: 0.5058\n",
      "F1 score: 0.1373\n",
      "F1 score: 0.13729688952066574\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 108s 540ms/step - loss: 3.9669 - val_loss: 3.9899\n",
      "Number of images: 1025\n",
      "Presicion: 0.158\n",
      "Recall: 0.4944\n",
      "F1 score: 0.2395\n",
      "F1 score: 0.23947811879701766\n",
      "Improve F1 score from 0.23530610797973317 to 0.23947811879701766\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 108s 539ms/step - loss: 3.9413 - val_loss: 4.1049\n",
      "Number of images: 1025\n",
      "Presicion: 0.106\n",
      "Recall: 0.5173\n",
      "F1 score: 0.1759\n",
      "F1 score: 0.1759269984678181\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 108s 538ms/step - loss: 3.9124 - val_loss: 4.0116\n",
      "Number of images: 1025\n",
      "Presicion: 0.0784\n",
      "Recall: 0.5322\n",
      "F1 score: 0.1367\n",
      "F1 score: 0.13669439213398524\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 107s 537ms/step - loss: 4.0264 - val_loss: 4.2589\n",
      "Number of images: 1025\n",
      "Presicion: 0.0341\n",
      "Recall: 0.5378\n",
      "F1 score: 0.0641\n",
      "F1 score: 0.06405410054799278\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 106s 530ms/step - loss: 3.9406 - val_loss: 4.0997\n",
      "Number of images: 1025\n",
      "Presicion: 0.1867\n",
      "Recall: 0.4594\n",
      "F1 score: 0.2655\n",
      "F1 score: 0.26554925570419996\n",
      "Improve F1 score from 0.23947811879701766 to 0.26554925570419996\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 109s 544ms/step - loss: 3.9502 - val_loss: 3.9374\n",
      "Number of images: 1025\n",
      "Presicion: 0.1402\n",
      "Recall: 0.5316\n",
      "F1 score: 0.2218\n",
      "F1 score: 0.221818848426063\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 3.9364 - val_loss: 3.9909\n",
      "Number of images: 1025\n",
      "Presicion: 0.2953\n",
      "Recall: 0.4328\n",
      "F1 score: 0.3511\n",
      "F1 score: 0.3510681460089795\n",
      "Improve F1 score from 0.26554925570419996 to 0.3510681460089795\n",
      "TRAINING MODEL WITH LEARNING RATE: 0.0001\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 122s 608ms/step - loss: 12.3939 - val_loss: 9.3728\n",
      "Number of images: 1025\n",
      "Presicion: 0.1457\n",
      "Recall: 0.3024\n",
      "F1 score: 0.1967\n",
      "F1 score: 0.19668773481681068\n",
      "Improve F1 score from -inf to 0.19668773481681068\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 109s 543ms/step - loss: 8.5063 - val_loss: 8.2249\n",
      "Number of images: 1025\n",
      "Presicion: 0.133\n",
      "Recall: 0.3069\n",
      "F1 score: 0.1856\n",
      "F1 score: 0.18556704484351833\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 108s 538ms/step - loss: 7.3712 - val_loss: 7.2716\n",
      "Number of images: 1025\n",
      "Presicion: 0.1353\n",
      "Recall: 0.3079\n",
      "F1 score: 0.188\n",
      "F1 score: 0.18803358269811274\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 107s 537ms/step - loss: 6.6767 - val_loss: 6.6865\n",
      "Number of images: 1025\n",
      "Presicion: 0.1442\n",
      "Recall: 0.3231\n",
      "F1 score: 0.1994\n",
      "F1 score: 0.19939176283512713\n",
      "Improve F1 score from 0.19668773481681068 to 0.19939176283512713\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 106s 529ms/step - loss: 6.2952 - val_loss: 6.2627\n",
      "Number of images: 1025\n",
      "Presicion: 0.1367\n",
      "Recall: 0.3673\n",
      "F1 score: 0.1993\n",
      "F1 score: 0.1992637340112129\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 106s 530ms/step - loss: 6.0209 - val_loss: 6.1704\n",
      "Number of images: 1025\n",
      "Presicion: 0.1562\n",
      "Recall: 0.3454\n",
      "F1 score: 0.2151\n",
      "F1 score: 0.21510421584040137\n",
      "Improve F1 score from 0.19939176283512713 to 0.21510421584040137\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 107s 536ms/step - loss: 5.7668 - val_loss: 5.8524\n",
      "Number of images: 1025\n",
      "Presicion: 0.1155\n",
      "Recall: 0.3832\n",
      "F1 score: 0.1775\n",
      "F1 score: 0.17746493972563931\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 108s 538ms/step - loss: 5.6241 - val_loss: 5.6010\n",
      "Number of images: 1025\n",
      "Presicion: 0.1369\n",
      "Recall: 0.3863\n",
      "F1 score: 0.2021\n",
      "F1 score: 0.2021354593044478\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 106s 530ms/step - loss: 5.4828 - val_loss: 5.4662\n",
      "Number of images: 1025\n",
      "Presicion: 0.1396\n",
      "Recall: 0.3848\n",
      "F1 score: 0.2049\n",
      "F1 score: 0.20492383918449422\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 107s 535ms/step - loss: 5.4325 - val_loss: 5.4271\n",
      "Number of images: 1025\n",
      "Presicion: 0.1354\n",
      "Recall: 0.3936\n",
      "F1 score: 0.2015\n",
      "F1 score: 0.20153083689255416\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 5.3245 - val_loss: 5.3301\n",
      "Number of images: 1025\n",
      "Presicion: 0.1467\n",
      "Recall: 0.3943\n",
      "F1 score: 0.2138\n",
      "F1 score: 0.21383760932299345\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 5.2263 - val_loss: 5.3484\n",
      "Number of images: 1025\n",
      "Presicion: 0.1463\n",
      "Recall: 0.3883\n",
      "F1 score: 0.2125\n",
      "F1 score: 0.21251846976772015\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 5.1491 - val_loss: 5.2399\n",
      "Number of images: 1025\n",
      "Presicion: 0.1422\n",
      "Recall: 0.3951\n",
      "F1 score: 0.2092\n",
      "F1 score: 0.2091823048123278\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 107s 534ms/step - loss: 5.1386 - val_loss: 5.1309\n",
      "Number of images: 1025\n",
      "Presicion: 0.129\n",
      "Recall: 0.4239\n",
      "F1 score: 0.1978\n",
      "F1 score: 0.19780123020239535\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 108s 538ms/step - loss: 5.1064 - val_loss: 5.1032\n",
      "Number of images: 1025\n",
      "Presicion: 0.1099\n",
      "Recall: 0.4398\n",
      "F1 score: 0.1758\n",
      "F1 score: 0.17583236144288647\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 107s 536ms/step - loss: 5.0439 - val_loss: 4.9980\n",
      "Number of images: 1025\n",
      "Presicion: 0.1187\n",
      "Recall: 0.4449\n",
      "F1 score: 0.1874\n",
      "F1 score: 0.18744572514412003\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 106s 528ms/step - loss: 4.9870 - val_loss: 5.0015\n",
      "Number of images: 1025\n",
      "Presicion: 0.1439\n",
      "Recall: 0.4167\n",
      "F1 score: 0.214\n",
      "F1 score: 0.21395938475924464\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 4.9769 - val_loss: 4.9661\n",
      "Number of images: 1025\n",
      "Presicion: 0.1418\n",
      "Recall: 0.4136\n",
      "F1 score: 0.2112\n",
      "F1 score: 0.21123479313409935\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 108s 539ms/step - loss: 4.9322 - val_loss: 4.9739\n",
      "Number of images: 1025\n",
      "Presicion: 0.1306\n",
      "Recall: 0.4348\n",
      "F1 score: 0.2008\n",
      "F1 score: 0.2008344426310986\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 4.8567 - val_loss: 4.9181\n",
      "Number of images: 1025\n",
      "Presicion: 0.136\n",
      "Recall: 0.4243\n",
      "F1 score: 0.206\n",
      "F1 score: 0.20599742111675723\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 107s 536ms/step - loss: 4.8431 - val_loss: 4.8323\n",
      "Number of images: 1025\n",
      "Presicion: 0.1074\n",
      "Recall: 0.4561\n",
      "F1 score: 0.1739\n",
      "F1 score: 0.17390215822708086\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 107s 537ms/step - loss: 4.7975 - val_loss: 4.8151\n",
      "Number of images: 1025\n",
      "Presicion: 0.1308\n",
      "Recall: 0.4344\n",
      "F1 score: 0.201\n",
      "F1 score: 0.20100927521402964\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 107s 535ms/step - loss: 4.7575 - val_loss: 4.7654\n",
      "Number of images: 1025\n",
      "Presicion: 0.1261\n",
      "Recall: 0.4488\n",
      "F1 score: 0.1969\n",
      "F1 score: 0.19685943824394994\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 107s 534ms/step - loss: 4.7572 - val_loss: 4.8102\n",
      "Number of images: 1025\n",
      "Presicion: 0.1149\n",
      "Recall: 0.4538\n",
      "F1 score: 0.1833\n",
      "F1 score: 0.18334457676748012\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 107s 536ms/step - loss: 4.7174 - val_loss: 4.7596\n",
      "Number of images: 1025\n",
      "Presicion: 0.1374\n",
      "Recall: 0.4357\n",
      "F1 score: 0.2089\n",
      "F1 score: 0.20892265396156406\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 4.6939 - val_loss: 4.7022\n",
      "Number of images: 1025\n",
      "Presicion: 0.1083\n",
      "Recall: 0.479\n",
      "F1 score: 0.1766\n",
      "F1 score: 0.17661549012513136\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 4.6643 - val_loss: 4.6858\n",
      "Number of images: 1025\n",
      "Presicion: 0.1181\n",
      "Recall: 0.4679\n",
      "F1 score: 0.1886\n",
      "F1 score: 0.18858450671039817\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 107s 534ms/step - loss: 4.7066 - val_loss: 4.7077\n",
      "Number of images: 1025\n",
      "Presicion: 0.1118\n",
      "Recall: 0.4626\n",
      "F1 score: 0.1801\n",
      "F1 score: 0.18014571861356268\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 108s 541ms/step - loss: 4.6343 - val_loss: 4.6525\n",
      "Number of images: 1025\n",
      "Presicion: 0.1111\n",
      "Recall: 0.4738\n",
      "F1 score: 0.18\n",
      "F1 score: 0.18004086837674355\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 107s 534ms/step - loss: 4.6047 - val_loss: 4.6370\n",
      "Number of images: 1025\n",
      "Presicion: 0.1112\n",
      "Recall: 0.4717\n",
      "F1 score: 0.18\n",
      "F1 score: 0.18002349169050055\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 107s 534ms/step - loss: 4.6235 - val_loss: 4.6447\n",
      "Number of images: 1025\n",
      "Presicion: 0.1288\n",
      "Recall: 0.4503\n",
      "F1 score: 0.2003\n",
      "F1 score: 0.20030906403724305\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 107s 536ms/step - loss: 4.5648 - val_loss: 4.6061\n",
      "Number of images: 1025\n",
      "Presicion: 0.093\n",
      "Recall: 0.4873\n",
      "F1 score: 0.1562\n",
      "F1 score: 0.15616483556474098\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 107s 533ms/step - loss: 4.5386 - val_loss: 4.5765\n",
      "Number of images: 1025\n",
      "Presicion: 0.1166\n",
      "Recall: 0.4848\n",
      "F1 score: 0.188\n",
      "F1 score: 0.18796212153044697\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 4.5275 - val_loss: 4.5805\n",
      "Number of images: 1025\n",
      "Presicion: 0.1028\n",
      "Recall: 0.4834\n",
      "F1 score: 0.1695\n",
      "F1 score: 0.16947958185209708\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 4.5306 - val_loss: 4.5827\n",
      "Number of images: 1025\n",
      "Presicion: 0.1019\n",
      "Recall: 0.4901\n",
      "F1 score: 0.1688\n",
      "F1 score: 0.16877009991826136\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 108s 538ms/step - loss: 4.4782 - val_loss: 4.5528\n",
      "Number of images: 1025\n",
      "Presicion: 0.1201\n",
      "Recall: 0.4631\n",
      "F1 score: 0.1908\n",
      "F1 score: 0.19076676256578043\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 4.4885 - val_loss: 4.5146\n",
      "Number of images: 1025\n",
      "Presicion: 0.1154\n",
      "Recall: 0.488\n",
      "F1 score: 0.1866\n",
      "F1 score: 0.18661280753772022\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 106s 531ms/step - loss: 4.4545 - val_loss: 4.5247\n",
      "Number of images: 1025\n",
      "Presicion: 0.0819\n",
      "Recall: 0.5134\n",
      "F1 score: 0.1413\n",
      "F1 score: 0.14127703505449613\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 108s 541ms/step - loss: 4.5027 - val_loss: 4.5327\n",
      "Number of images: 1025\n",
      "Presicion: 0.0949\n",
      "Recall: 0.5014\n",
      "F1 score: 0.1596\n",
      "F1 score: 0.15957675693837803\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 108s 542ms/step - loss: 4.4631 - val_loss: 4.5081\n",
      "Number of images: 1025\n",
      "Presicion: 0.0683\n",
      "Recall: 0.526\n",
      "F1 score: 0.1209\n",
      "F1 score: 0.1208608420312698\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 107s 536ms/step - loss: 4.4404 - val_loss: 4.4974\n",
      "Number of images: 1025\n",
      "Presicion: 0.131\n",
      "Recall: 0.4656\n",
      "F1 score: 0.2044\n",
      "F1 score: 0.20442880095399707\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 106s 532ms/step - loss: 4.4811 - val_loss: 4.4635\n",
      "Number of images: 1025\n",
      "Presicion: 0.1163\n",
      "Recall: 0.4788\n",
      "F1 score: 0.1871\n",
      "F1 score: 0.1870995213984974\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 107s 537ms/step - loss: 4.4292 - val_loss: 4.4661\n",
      "Number of images: 1025\n",
      "Presicion: 0.0933\n",
      "Recall: 0.5012\n",
      "F1 score: 0.1573\n",
      "F1 score: 0.15734560573559786\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 107s 534ms/step - loss: 4.3815 - val_loss: 4.4499\n",
      "Number of images: 1025\n",
      "Presicion: 0.1048\n",
      "Recall: 0.5053\n",
      "F1 score: 0.1736\n",
      "F1 score: 0.17362032397744032\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 108s 538ms/step - loss: 4.4407 - val_loss: 4.4106\n",
      "Number of images: 1025\n",
      "Presicion: 0.0923\n",
      "Recall: 0.5068\n",
      "F1 score: 0.1562\n",
      "F1 score: 0.15620903880900525\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 107s 535ms/step - loss: 4.3173 - val_loss: 4.4245\n",
      "Number of images: 1025\n",
      "Presicion: 0.0829\n",
      "Recall: 0.5099\n",
      "F1 score: 0.1426\n",
      "F1 score: 0.14256559479887088\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 106s 531ms/step - loss: 4.3689 - val_loss: 4.4870\n",
      "Number of images: 1025\n",
      "Presicion: 0.0988\n",
      "Recall: 0.4774\n",
      "F1 score: 0.1638\n",
      "F1 score: 0.16376852068517006\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 108s 539ms/step - loss: 4.3959 - val_loss: 4.4179\n",
      "Number of images: 1025\n",
      "Presicion: 0.0904\n",
      "Recall: 0.5236\n",
      "F1 score: 0.1542\n",
      "F1 score: 0.15424857956253796\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 106s 529ms/step - loss: 4.3127 - val_loss: 4.4957\n",
      "Number of images: 1025\n",
      "Presicion: 0.0871\n",
      "Recall: 0.5071\n",
      "F1 score: 0.1486\n",
      "F1 score: 0.14861393783423957\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 108s 541ms/step - loss: 4.4064 - val_loss: 4.3655\n",
      "Number of images: 1025\n",
      "Presicion: 0.0847\n",
      "Recall: 0.534\n",
      "F1 score: 0.1463\n",
      "F1 score: 0.14627889053567705\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 106s 529ms/step - loss: 4.3136 - val_loss: 4.4267\n",
      "Number of images: 1025\n",
      "Presicion: 0.1181\n",
      "Recall: 0.4868\n",
      "F1 score: 0.1901\n",
      "F1 score: 0.19011047198608622\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 107s 535ms/step - loss: 4.3345 - val_loss: 4.3714\n",
      "Number of images: 1025\n",
      "Presicion: 0.0946\n",
      "Recall: 0.5204\n",
      "F1 score: 0.1601\n",
      "F1 score: 0.16006587896305963\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 106s 530ms/step - loss: 4.3176 - val_loss: 4.3579\n",
      "Number of images: 1025\n",
      "Presicion: 0.082\n",
      "Recall: 0.5339\n",
      "F1 score: 0.1421\n",
      "F1 score: 0.14212404140959164\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 107s 534ms/step - loss: 4.2882 - val_loss: 4.3435\n",
      "Number of images: 1025\n",
      "Presicion: 0.0786\n",
      "Recall: 0.5336\n",
      "F1 score: 0.1371\n",
      "F1 score: 0.13705353646410767\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 106s 530ms/step - loss: 4.2848 - val_loss: 4.3508\n",
      "Number of images: 1025\n",
      "Presicion: 0.0807\n",
      "Recall: 0.5311\n",
      "F1 score: 0.1401\n",
      "F1 score: 0.14005536851895625\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 106s 532ms/step - loss: 4.2914 - val_loss: 4.3338\n",
      "Number of images: 1025\n",
      "Presicion: 0.0895\n",
      "Recall: 0.5393\n",
      "F1 score: 0.1535\n",
      "F1 score: 0.15350468915030163\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 107s 534ms/step - loss: 4.2837 - val_loss: 4.3343\n",
      "Number of images: 1025\n",
      "Presicion: 0.1013\n",
      "Recall: 0.5084\n",
      "F1 score: 0.169\n",
      "F1 score: 0.16899620765057397\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 106s 528ms/step - loss: 4.2476 - val_loss: 4.3148\n",
      "Number of images: 1025\n",
      "Presicion: 0.0917\n",
      "Recall: 0.5368\n",
      "F1 score: 0.1566\n",
      "F1 score: 0.15657162724883444\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 107s 537ms/step - loss: 4.2574 - val_loss: 4.8215\n",
      "Number of images: 1025\n",
      "Presicion: 0.0892\n",
      "Recall: 0.4827\n",
      "F1 score: 0.1506\n",
      "F1 score: 0.15059715959000922\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 107s 536ms/step - loss: 4.2754 - val_loss: 4.3368\n",
      "Number of images: 1025\n",
      "Presicion: 0.0639\n",
      "Recall: 0.5475\n",
      "F1 score: 0.1144\n",
      "F1 score: 0.11436320434564518\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 107s 537ms/step - loss: 4.2486 - val_loss: 4.2885\n",
      "Number of images: 1025\n",
      "Presicion: 0.0831\n",
      "Recall: 0.5387\n",
      "F1 score: 0.144\n",
      "F1 score: 0.14398859069630424\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 107s 535ms/step - loss: 4.2686 - val_loss: 4.2794\n",
      "Number of images: 1025\n",
      "Presicion: 0.0578\n",
      "Recall: 0.5479\n",
      "F1 score: 0.1046\n",
      "F1 score: 0.10456531792268743\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 107s 537ms/step - loss: 4.2418 - val_loss: 4.2767\n",
      "Number of images: 1025\n",
      "Presicion: 0.0798\n",
      "Recall: 0.5375\n",
      "F1 score: 0.139\n",
      "F1 score: 0.13898481628471476\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 107s 534ms/step - loss: 4.2264 - val_loss: 4.2994\n",
      "Number of images: 1025\n",
      "Presicion: 0.0838\n",
      "Recall: 0.5175\n",
      "F1 score: 0.1442\n",
      "F1 score: 0.14421052262065406\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 108s 539ms/step - loss: 4.2376 - val_loss: 4.3208\n",
      "Number of images: 1025\n",
      "Presicion: 0.0908\n",
      "Recall: 0.5234\n",
      "F1 score: 0.1548\n",
      "F1 score: 0.15482159697449652\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 106s 530ms/step - loss: 4.2036 - val_loss: 4.2814\n",
      "Number of images: 1025\n",
      "Presicion: 0.1124\n",
      "Recall: 0.5096\n",
      "F1 score: 0.1842\n",
      "F1 score: 0.18419654016966325\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 108s 538ms/step - loss: 4.2626 - val_loss: 4.2576\n",
      "Number of images: 1025\n",
      "Presicion: 0.0671\n",
      "Recall: 0.5316\n",
      "F1 score: 0.1191\n",
      "F1 score: 0.11912452572378006\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 107s 535ms/step - loss: 4.1925 - val_loss: 4.2752\n",
      "Number of images: 1025\n",
      "Presicion: 0.0875\n",
      "Recall: 0.5299\n",
      "F1 score: 0.1503\n",
      "F1 score: 0.15026471057043475\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 106s 531ms/step - loss: 4.2071 - val_loss: 4.2755\n",
      "Number of images: 1025\n",
      "Presicion: 0.0891\n",
      "Recall: 0.528\n",
      "F1 score: 0.1525\n",
      "F1 score: 0.1524530261140519\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 108s 538ms/step - loss: 4.2109 - val_loss: 4.2413\n",
      "Number of images: 1025\n",
      "Presicion: 0.09\n",
      "Recall: 0.5263\n",
      "F1 score: 0.1537\n",
      "F1 score: 0.1536859820596825\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 106s 530ms/step - loss: 4.1785 - val_loss: 4.2581\n",
      "Number of images: 1025\n",
      "Presicion: 0.1039\n",
      "Recall: 0.5045\n",
      "F1 score: 0.1724\n",
      "F1 score: 0.17236192552036658\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 108s 540ms/step - loss: 4.2170 - val_loss: 4.2513\n",
      "Number of images: 1025\n",
      "Presicion: 0.0731\n",
      "Recall: 0.5186\n",
      "F1 score: 0.1281\n",
      "F1 score: 0.1281169972127753\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 4.1545 - val_loss: 4.2047\n",
      "Number of images: 1025\n",
      "Presicion: 0.077\n",
      "Recall: 0.5436\n",
      "F1 score: 0.1349\n",
      "F1 score: 0.13491099671480275\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 109s 543ms/step - loss: 4.1827 - val_loss: 4.2139\n",
      "Number of images: 1025\n",
      "Presicion: 0.0714\n",
      "Recall: 0.5454\n",
      "F1 score: 0.1263\n",
      "F1 score: 0.12630973038884766\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 107s 534ms/step - loss: 4.1689 - val_loss: 4.2061\n",
      "Number of images: 1025\n",
      "Presicion: 0.0696\n",
      "Recall: 0.5534\n",
      "F1 score: 0.1236\n",
      "F1 score: 0.12359840921115002\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 106s 530ms/step - loss: 4.1864 - val_loss: 4.2150\n",
      "Number of images: 1025\n",
      "Presicion: 0.0674\n",
      "Recall: 0.5407\n",
      "F1 score: 0.1199\n",
      "F1 score: 0.11992901150567187\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 106s 532ms/step - loss: 4.1411 - val_loss: 4.2127\n",
      "Number of images: 1025\n",
      "Presicion: 0.1311\n",
      "Recall: 0.5026\n",
      "F1 score: 0.208\n",
      "F1 score: 0.20800245351174704\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 106s 531ms/step - loss: 4.1337 - val_loss: 4.1958\n",
      "Number of images: 1025\n",
      "Presicion: 0.0917\n",
      "Recall: 0.5274\n",
      "F1 score: 0.1562\n",
      "F1 score: 0.15620008848487082\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 4.1804 - val_loss: 4.2029\n",
      "Number of images: 1025\n",
      "Presicion: 0.0675\n",
      "Recall: 0.5279\n",
      "F1 score: 0.1197\n",
      "F1 score: 0.11973886481550292\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 4.1445 - val_loss: 4.1759\n",
      "Number of images: 1025\n",
      "Presicion: 0.0786\n",
      "Recall: 0.544\n",
      "F1 score: 0.1374\n",
      "F1 score: 0.13741240495269647\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 108s 540ms/step - loss: 4.1250 - val_loss: 4.2010\n",
      "Number of images: 1025\n",
      "Presicion: 0.0544\n",
      "Recall: 0.556\n",
      "F1 score: 0.0991\n",
      "F1 score: 0.09909564039458556\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 4.1042 - val_loss: 4.1698\n",
      "Number of images: 1025\n",
      "Presicion: 0.0746\n",
      "Recall: 0.5557\n",
      "F1 score: 0.1315\n",
      "F1 score: 0.13152815803585197\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 108s 540ms/step - loss: 4.1403 - val_loss: 4.2088\n",
      "Number of images: 1025\n",
      "Presicion: 0.1206\n",
      "Recall: 0.5038\n",
      "F1 score: 0.1946\n",
      "F1 score: 0.19462350953344124\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 107s 535ms/step - loss: 4.1105 - val_loss: 4.1778\n",
      "Number of images: 1025\n",
      "Presicion: 0.0687\n",
      "Recall: 0.5599\n",
      "F1 score: 0.1223\n",
      "F1 score: 0.12234276541318853\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 107s 534ms/step - loss: 4.0740 - val_loss: 4.1482\n",
      "Number of images: 1025\n",
      "Presicion: 0.1378\n",
      "Recall: 0.4872\n",
      "F1 score: 0.2149\n",
      "F1 score: 0.21485286604531117\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 106s 532ms/step - loss: 4.0855 - val_loss: 4.1610\n",
      "Number of images: 1025\n",
      "Presicion: 0.0995\n",
      "Recall: 0.5346\n",
      "F1 score: 0.1677\n",
      "F1 score: 0.16774102510153646\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 106s 532ms/step - loss: 4.1139 - val_loss: 4.1335\n",
      "Number of images: 1025\n",
      "Presicion: 0.0612\n",
      "Recall: 0.5548\n",
      "F1 score: 0.1102\n",
      "F1 score: 0.11024211696734038\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 107s 535ms/step - loss: 4.1089 - val_loss: 4.1761\n",
      "Number of images: 1025\n",
      "Presicion: 0.08\n",
      "Recall: 0.5304\n",
      "F1 score: 0.139\n",
      "F1 score: 0.13900026337241456\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 106s 528ms/step - loss: 4.1042 - val_loss: 4.1952\n",
      "Number of images: 1025\n",
      "Presicion: 0.0915\n",
      "Recall: 0.5258\n",
      "F1 score: 0.1559\n",
      "F1 score: 0.155857995350754\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 106s 530ms/step - loss: 4.0640 - val_loss: 4.1469\n",
      "Number of images: 1025\n",
      "Presicion: 0.1144\n",
      "Recall: 0.5099\n",
      "F1 score: 0.1869\n",
      "F1 score: 0.1868994841393189\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 108s 540ms/step - loss: 4.1089 - val_loss: 4.1340\n",
      "Number of images: 1025\n",
      "Presicion: 0.0619\n",
      "Recall: 0.5528\n",
      "F1 score: 0.1113\n",
      "F1 score: 0.1112909326279044\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 107s 536ms/step - loss: 4.0602 - val_loss: 4.1438\n",
      "Number of images: 1025\n",
      "Presicion: 0.0878\n",
      "Recall: 0.5377\n",
      "F1 score: 0.151\n",
      "F1 score: 0.15096454910775287\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 107s 537ms/step - loss: 4.0815 - val_loss: 4.1637\n",
      "Number of images: 1025\n",
      "Presicion: 0.0591\n",
      "Recall: 0.5399\n",
      "F1 score: 0.1065\n",
      "F1 score: 0.1065260808162333\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 106s 531ms/step - loss: 4.0702 - val_loss: 4.1417\n",
      "Number of images: 1025\n",
      "Presicion: 0.1195\n",
      "Recall: 0.5127\n",
      "F1 score: 0.1938\n",
      "F1 score: 0.19382380089882503\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 106s 531ms/step - loss: 4.0691 - val_loss: 4.1107\n",
      "Number of images: 1025\n",
      "Presicion: 0.0585\n",
      "Recall: 0.5476\n",
      "F1 score: 0.1058\n",
      "F1 score: 0.10575582968552692\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 107s 535ms/step - loss: 4.0622 - val_loss: 4.1046\n",
      "Number of images: 1025\n",
      "Presicion: 0.0745\n",
      "Recall: 0.5625\n",
      "F1 score: 0.1315\n",
      "F1 score: 0.13150673530746598\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 107s 536ms/step - loss: 4.0428 - val_loss: 4.1088\n",
      "Number of images: 1025\n",
      "Presicion: 0.0918\n",
      "Recall: 0.5212\n",
      "F1 score: 0.1561\n",
      "F1 score: 0.1561027906001383\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 107s 536ms/step - loss: 4.0410 - val_loss: 4.1048\n",
      "Number of images: 1025\n",
      "Presicion: 0.0681\n",
      "Recall: 0.5495\n",
      "F1 score: 0.1211\n",
      "F1 score: 0.1211342196357617\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 106s 530ms/step - loss: 4.0338 - val_loss: 4.1539\n",
      "Number of images: 1025\n",
      "Presicion: 0.0903\n",
      "Recall: 0.5233\n",
      "F1 score: 0.154\n",
      "F1 score: 0.1540175252496985\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 105s 526ms/step - loss: 4.0268 - val_loss: 4.1084\n",
      "Number of images: 1025\n",
      "Presicion: 0.0693\n",
      "Recall: 0.5432\n",
      "F1 score: 0.1229\n",
      "F1 score: 0.12293618679275442\n"
     ]
    }
   ],
   "source": [
    "lr_list = [0.01, 0.001, 0.0001]\n",
    "\n",
    "for lr in lr_list:\n",
    "    # 1: Build the Keras model.\n",
    "    K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "    print('TRAINING MODEL WITH LEARNING RATE:', lr)\n",
    "    \n",
    "    model = ssd_300(image_size=(img_height, img_width, img_channels),\n",
    "                n_classes=n_classes,\n",
    "                mode='training',\n",
    "                scale_factor=1.5,\n",
    "                scales=scales,\n",
    "                aspect_ratios_per_layer=aspect_ratios,\n",
    "                two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                steps=steps,\n",
    "                offsets=offsets,\n",
    "                clip_boxes=clip_boxes,\n",
    "                variances=variances,\n",
    "                normalize_coords=normalize_coords,\n",
    "                subtract_mean=mean_color,\n",
    "                divide_by_stddev=divide_by_stddev,\n",
    "                swap_channels=swap_channels)\n",
    "\n",
    "    adam = Adam(lr=lr)\n",
    "    ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "    model.compile(optimizer=adam, loss=ssd_loss.compute_loss)\n",
    "    \n",
    "    # Define model callbacks.\n",
    "    main_path = '/home/aldo/Downloads/shufflenetv1/'\n",
    "    # TODO: Set the filepath under which you want to save the model.\n",
    "\n",
    "    csv_logger = CSVLogger(filename=main_path + 'model_' + str(lr) + '.csv',\n",
    "                           separator=',',\n",
    "                           append=True)\n",
    "\n",
    "\n",
    "    f1_callback = f1_call(0.20, \n",
    "                           0.45, \n",
    "                           200, \n",
    "                           normalize_coords, \n",
    "                           img_height, \n",
    "                           img_width, \n",
    "                           (1, 2268, 14),\n",
    "                           main_path + 'f1_' + str(lr) + '.csv',\n",
    "                           main_path + 'model.h5',\n",
    "                           label_csv='/home/aldo/Documents/data-cic/preprocess_data/PASCAL_val.csv',\n",
    "                           path_img='/home/aldo/Documents/data-cic/PASCAL',\n",
    "                           verborse=True)\n",
    "\n",
    "\n",
    "    callbacks = [csv_logger,\n",
    "                 f1_callback]\n",
    "    \n",
    "    initial_epoch   = 0\n",
    "    final_epoch     = 100\n",
    "    steps_per_epoch = 200\n",
    "\n",
    "    history = model.fit_generator(generator=train_generator,\n",
    "                                  steps_per_epoch=steps_per_epoch,\n",
    "                                  epochs=final_epoch,\n",
    "                                  callbacks=callbacks,\n",
    "                                  validation_data=val_generator,\n",
    "                                  validation_steps=ceil(val_dataset_size/batch_size),\n",
    "                                  initial_epoch=initial_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1d6a9bb400>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "mob_01 = pd.read_csv(main_path + 'model_0.01.csv')\n",
    "mob_001 = pd.read_csv(main_path + 'model_0.001.csv')\n",
    "mob_0001 = pd.read_csv(main_path + 'model_0.0001.csv')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(mob_01['epoch'][10:], mob_01['val_loss'][10:], color='r')\n",
    "ax.plot(mob_001['epoch'][10:], mob_001['val_loss'][10:], color='b')\n",
    "ax.plot(mob_0001['epoch'][10:], mob_0001['val_loss'][10:], color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1d6b9f3748>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzsnXd8W9Xd/99H8t47dpzEznD2IBDCCBBGIOzRQh+gUFYfCAXa/to+QB8oLbSUVfYokJbSlodVRhIgbEIgECAOibOnVxLb8ZLlIVm2pPP74+hKV8uWE2dAzvv18kvW1b1XV9K9n/s9n/M93yOklGg0Go3m0MByoA9Ao9FoNPsPLfoajUZzCKFFX6PRaA4htOhrNBrNIYQWfY1GozmE0KKv0Wg0hxBa9DUajeYQQou+RqPRHEJo0ddoNJpDiLgDfQCh5OXlydLS0gN9GBqNRvOdYuXKlc1Syvz+1jvoRL+0tJTy8vIDfRgajUbznUIIURPLetre0Wg0mkMILfoajUZzCKFFX6PRaA4htOhrNBrNIYQWfY1GozmEiEn0hRCnCyE2CyG2CSFujfD6PCHEWiHEaiHEMiHERN/yUiGE07d8tRDi6cH+ABqNRqOJnX5TNoUQVuBJ4FRgJ7BCCLFISrnBtNqLUsqnfeufCzwEnO57bbuU8rDBPWyNRqPR7AmxRPozgW1SykopZQ/wMnCeeQUpZbvpaSqg52DUaDSaAfDPf8L8+fv+fWIR/WJgh+n5Tt+yIIQQNwghtgP3Az83vTRSCLFKCLFUCHH8Xh2tRqPRfE/597/h+ef3/fsMWkeulPJJKeVo4Bbgdt/iemCElHI68CvgRSFERui2QohrhRDlQojypqamwTokjUaj+c7Q1QUpKfv+fWIR/V3AcNPzYb5l0XgZOB9ASumSUrb4/l8JbAfGhm4gpXxWSjlDSjkjP7/f0hEajUbzvaOrC1JT9/37xCL6K4AyIcRIIUQCcDGwyLyCEKLM9PQsYKtveb6vIxghxCigDKgcjAPXaDSa7xP7S/T7zd6RUrqFEDcC7wNW4Dkp5XohxF1AuZRyEXCjEGIO0AvYgCt8m58A3CWE6AW8wDwpZeu++CAajUbzXcbhOEhEH0BKuRhYHLLsDtP/v4iy3evA63tzgBqNRnMocDDZOxqNRqPZh0h5cHXkajQajWYf4nKB16sjfY1Gozkk6OpSj1r0NRqN5hDA4VCPWvQ1Go3mEEBH+hqNRnMIYYi+7sjVaDSaQwAd6Ws0Gs0hhBZ9jUajOYTQHbkajUZzCKEjfY1GozmE0B25Go1GcwihI32NRqM5hNCir9FoNIcQDgckJoLVuu/fS4u+RqPRHGD2V1ll0KKv0Wg0B5z9VVYZtOhrNBrNAUdH+hqNRnMIoUVfo9FoDiH21/y4EKPoCyFOF0JsFkJsE0LcGuH1eUKItUKI1UKIZUKIiabXfuvbbrMQYu5gHrxGo9F8HzioIn0hhBV4EjgDmAhcYhZ1Hy9KKadIKQ8D7gce8m07EbgYmAScDjzl259Go9FofBxsHbkzgW1SykopZQ/wMnCeeQUpZbvpaSogff+fB7wspXRJKauAbb79aTQajcbH/oz042JYpxjYYXq+EzgqdCUhxA3Ar4AE4GTTtl+FbFu8R0eq0Wg031MOKnsnVqSUT0opRwO3ALcPZFshxLVCiHIhRHlTU9NgHZJGo9F8JzjYOnJ3AcNNz4f5lkXjZeD8gWwrpXxWSjlDSjkjPz8/hkPSaDSa7wde78En+iuAMiHESCFEAqpjdpF5BSFEmenpWcBW3/+LgIuFEIlCiJFAGfDN3h+2RqPRfD9wOtXj/urI7dfTl1K6hRA3Au8DVuA5KeV6IcRdQLmUchFwoxBiDtAL2IArfNuuF0K8CmwA3MANUkrPPvosGo1G851jf1bYhNg6cpFSLgYWhyy7w/T/L/rY9m7g7j09QI1Go/k+s79FX4/I1Wg0mgPI/pwfF7ToazQazQFFR/oajUZzCLE/58cFLfoajUZzQNGRvkaj0RxCaNHXaDSaQwjdkavRaDSHEDrS12g0mkMI3ZGr0Wg0hxCG6Ccn75/306Kv0Wg0BxBjAhXLflJjLfoajUZzANmfFTZBi75Go9EcUPbnBCqgRV+j0WgOKPtzflzQoq/RaDT7lR07oK0t8FxH+hqNRvM95qyz4De/CTzXoq/RaDTfY5qbYePGwHPdkavRaDTfY1wuqK4OPN/fkX5MM2dpNBqNZnBwuaC1VT0mJuqOXI1Go/le43Kpxx071KP29DUajeZ7itcLbrf637B4DkrRF0KcLoTYLITYJoS4NcLrvxJCbBBCrBFCfCyEKDG95hFCrPb9LRrMg9doNJrvEkaUD0r03W7o6TnIPH0hhBV4EjgV2AmsEEIsklJuMK22CpghpXQIIa4H7gf+y/eaU0p52CAft0aj0XznCBX9/V1LH2KL9GcC26SUlVLKHuBl4DzzClLKJVJK3+HzFTBscA9To9FovvuEiv7+LqsMsYl+MbDD9Hynb1k0rgHeNT1PEkKUCyG+EkKcH2kDIcS1vnXKm5qaYjgkjUaj+e4RTfQPKntnIAghLgNmALNNi0uklLuEEKOAT4QQa6WU283bSSmfBZ4FmDFjhhzMY9JoNJqDBUP0ExIOnOjHEunvAoabng/zLQtCCDEHuA04V0rpv59JKXf5HiuBT4Hpe3G8Go1G853FEP0xY6CuLlCD52AT/RVAmRBipBAiAbgYCMrCEUJMB55BCX6jaXm2ECLR938eMAswdwBrNBrNIYMh+uPGgZSwaZN6flDZO1JKtxDiRuB9wAo8J6VcL4S4CyiXUi4CHgDSgP8IIQBqpZTnAhOAZ4QQXtQN5t6QrB+NRqM5ZOjpUY/jxqnH9evV4/7syI3J05dSLgYWhyy7w/T/nCjbfQlM2ZsD1Gg0moMVrxceeADmzYPMzP7XN0f6EBD9g83e0Wg0Gk0E1q6FW2+FhQtjW98Q/VGjwGrVoq/RHPR4vVBTc6CPQnOwYLerx8bGvtczMEQ/NRWGDYPduwPP9xda9DUaH+++C3fc0fc6b78No0dDff3+OSbNwU1Hh3qMdXiRIfqJiVBaGliuRV+jOQC88go8/HDf61RVgcej0u00mvZ29TjQSN8s+haLytvfX2jR12h82O3Q2alEPRo2m3o0z3GqOXQZDNFPTQWV9Lh/0KKv0fgw/FnjQo5Ea2vwuppDG8Pe2VvR359o0ddofBhC3peg60hfY2awIv39iRZ9jcaHIfZ9CbqO9DVmzKIvY6gapkVfozmIMMReR/qaWDHsne5u1R/UH2bRHzZM5ervz9G4oEVfowFUlBaLvWNE+lr0NRDc/xOLxeNyQVycytiJi1PCryN9jeYA4HQG5i7tS9CNSP9A2zsLFsCPf3xgj0GzZ6KfmBh4ftVVcN550dffF2jR12gIFvFogi7lwRPpf/QRvPhi35lGmn1PRwfk5Kj/YxH9np5g0f/97+Gmm/bNsUVDi75GQ2yi39UVaA0c6Ejf8I+3bj2wx3Go096uRmjDnkX6BwIt+j4e+OIBfr/k93u8fVNXEzKW7vt+aHW20tXTtdf70QwMc+QeTdANayd0/QOBIfpbthzY44iFTz+F666LfX2XC37zmz2/sT5T/gxvbX5rzzYeIFr0v6O43C7u/vxu/rH6H3u0/SvrXqHgLwUMfWgo//Xaf/F0+dM4eh39bxiClJKZ82cy4pER/PnzP9Pu0m33/YVZYKIJumHtpKQceNE3ska+C5H+I4/As88Gpgbsj5Ur4cEHYcmSPXu/+764jydWPLFnGw+Qjg7Iz1dllWMV/f1ZciESWvSB97a9h91lZ0f7Dpy9zgFtK6Xkvi/uY1T2KE4ZeQpf7viS69+5nklPTeLtLW8PaF91HXVst20nMzGT2z65jdJHSnl53csD2odmzzBEX4j+I/2RI7W9Eys9PfDJJ+r/WAcwOXzxknNgl6Ifu8tOrb12zzYeAFKqSD89HQoKdKT/neLl9QFh3da6bUDbLq1ZyqqGVdw661Ze+MEL1P6yliVXLCE5LplzXjqHC165AHt3bAqxom4FAC/+8EVW/PcKRmWPYt7b87A5bf1sGTte6eWTqk8GxYr6PmGI+NCh0QXdiPQN0T+QX+F3RfSXLx94JUpD9GNtGZiRUmLvtrPDvmOfn+MOhyq1nZGhRf87RVdPF4s2L+LIoUcCsLV1YFfRw189TF5KHpdNvQwAIQQnlp7I6nmrufeUe1m4aSH3f3F/TPtasWsFcZY4pg2ZxoyhM3juvOewu+w88OUDA/tQffDGxjc45V+n8M2ubwZtn98HDLtmxIj+I/1Ro9TFHstgnH3Fd8Xeef/9wP+NjfDNrm+44JUL6PX0Rt3GEH3HwB1SHL0OPNJDV28Xtu7BC5YiYfwGWvS/Y7y95W0cvQ5+d8LvANjaEv0q8kovbq/b/3xLyxbe2vwW18+4nuT45KB1E6wJ3HLcLfxw4g95YsUTtHX3bwKX15czuWCyf19Th0zlksmX8OjXj9LQ2eBf7+/f/p2ny58e0Oc0+HLHlwCsbli9R9t/X7Hb1YCZ4uL+Pf2RI9XjgfT1OzuVFdXaCi0tB+44+uO996CkRP3f2AifVH3Cgk0L+rRfDFtnT0Tf7grcsfe1xWOky34v7R0hxOlCiM1CiG1CiFsjvP4rIcQGIcQaIcTHQogS02tXCCG2+v6uGMyDHwxeWvcSQ9OHcmbZmRSkFkSM9KWULNi0gOnPTCftz2nc/dnd9Hh6ePSrR4m3xvOzI38Wdf//e9z/0u5q58lvnuzzOKSUlNeV+1scBneddJfqaP7sbqSU/O6T3/HTt37K7Z/cvkfN1693fQ3A+qb1A972YMHldnHOS+fwbf23g7ZPu111xmVl9R3px8WpGwMceNE35lk9WKP93bth1Sq4TDWCaWzEH/zs6tgVdbu9ifTNVuoO+46B72AAhEb6zc19l+WG74joCyGswJPAGcBE4BIhxMSQ1VYBM6SUU4HXgPt92+YAvweOAmYCvxdCZA/e4e8dbd1tvLvtXX408UdYLVbKcsrCRH9j00aOnH8kF7xyAc5eJ6eNPo3bl9zOYU8fxvMVz3PplEspTCuM+h7Ti6ZzxpgzeOTrR/pMxay0VdLqbGXG0BlBy8fkjOGa6dfwzMpnuGrhVfzp8z9RmlVKi7OFxq4Ye8Z89Hp6/UL5XRb9GnsNb295u98b6UAwRD8zs29PPztb/RnbHAjcbhUNT5+unh+sov/hh+rxggtUqYGmJpPot/cv+nvi6R+ISN8Qfa830BqMxndC9FFivU1KWSml7AFeBoIGDkspl0gpjfvyV8Aw3/9zgQ+llK1SShvwIXD64Bz63rNg0wJ6PD1cPPliAMpyy8LsnT9+9ke2tm7lH+f9gw03bGDRJYt459J3cLqdOHud/PKoX/b7PrcdfxvNjmbmfzs/6jrldeUAYZE+wO9m/w6LsPDPin/yy6N+yfxz1H7WNa4LWu/NjW8y+/nZrN29NuJ7rG1cS7e7m+ykbNY37r3of1T5UdT32pcYHduLtiwKstv2BnOk73SqrJOw97Upwc/MVM8PVKRviOHUqcqSOlhF/733VDrj9OkB+8MQ5f0R6e9vewf6t3i+K6JfDJjbSTt9y6JxDfDuQLYVQlwrhCgXQpQ3xdrFvwd4pZfj/3E8cXfFkXJ3Cte+dS2lWaXMLJ4JQFlOGfWd9XT2BHrovtr5FaeNPo0rD7uSOEscAGeWncn6n61n3c/WMa1wWr/vO2vELGaXzOaBLx/A5XZFXGdF3QoSrYlMLpgc9tqwjGHMP2c+T5zxBA/NfYgpBVOA8Gj9xXUv8lnNZxz1t6N4fvXzYfv5eqeydn485cfs7tpNs6O532OPhtvr5sJXL+SOT/uZVHYfYHTQNTua/X0Ue0tbWyDSh8hRvM2mhtxnZQW2ORAYHcg5Oao878Eo+l4vfPABnHqqujEZoj+QSD9U9N1uOPdc+LKPn9y4qQgEO9r3r70D3x/RjxkhxGXADGBA6SZSymellDOklDPy8/P36L07XB3c/dndfaZcvr3lbZbVLuOSKZdw48wbuX7G9Txz9jMI31xlY3PHAoG0zd2du6lqq+Lo4qPD9pUSn8LE/FCXKzr/e/z/UtdRx2sbXov4+oq6FRxWeBjx1viIr18+7XJumHkDQggKUgvITc4Ni/TL68qZM2oOxww/hqsWXsW1b10b5Pt/U/cN+Sn5nD32bIC9ivbL68qxu+xU2ar2eB97ijmF9c2Nbw7KPs32jvE8FMPe6Wud/YEhNunpUFZ2cI7KXbVK2Tmn+9r1YaK/B5F+ayu89RZ89ln09zUi/TE5Y/a7vQPfH9HfBQw3PR/mWxaEEGIOcBtwrpTSNZBtB4POnk7++NkfuefzeyK+LqXk7s/vpjSrlOfOfY77T72fR894lNNGn+ZfpyynDFBZOaCifIBj5r+712HdnFFzyEnO4eOqj8Ne83g9rKxbGdHaiYQQgskFk4Mi/RZHC9Vt1Zw66lQ+uOwDZQN9O5/Paz/3r/P1zq+ZWTyTSQWTgL3z9T/crgzbGnvNHu9jTzGE44iiI1iwecGg5GPb7SqCN6L4viL9A23vGJF+WpoS/a1bD+yYgUh88IF6PM13eeXnD1z0Qz1943Mbr29t2RrWT2bsf3LBZG3vRCEW0V8BlAkhRgohEoCLgUXmFYQQ04FnUIJv/tjvA6cJIbJ9Hbin+ZYNOkXpRVx7xLX8a82/qG6rDnv946qP+WbXN9wy65ao0fSYnDFAIG1z+Y4viffA4S98DCefrLrn9xCLsDC7ZDafVn8a9trmhnV09XZxZHFsog8wKX8S6xrX+QVvZf1KAGbYkrF+upS73SeQaUnhmdd+C/PnY3/8L2xq3sRRbakUf7WBjIT06JG+lOrKqq2F8nLVIxdyBX5YqUS/rbsN+7dfwh/+AHffDdu3B+9n82ZYulQ9trcPXJ16w/O5DXvnqsOuorqtmordFQPbZwRCI/1Igm5E+omJkJy8DyP9xsY+y2eGin5HRwzpgm43PP88vP02bNsWqBy3j9i6VQ10GzJEPS8oGHhHbmikb3zuri5l1R7x7BE8/NXDQevYXXYswsKEvAnUddQNWp9PJDo6wJLcwfmvn0aL3IrF0v/vEFpl80AQ198KUkq3EOJGlFhbgeeklOuFEHcB5VLKRSg7Jw34j88qqZVSniulbBVC/BF14wC4S0rZT//2nnPzrJt5ZuUz3LvsXp4+OziP/c+f/5mitCKuPOzKqNunJqQyNH2oP4Pnqw0fML0eki6/Cl56CWbPVjVti4qCN9y+HX7+88AQvZQU+Oc/A7d/H7NdRbzZ9ia19lpGZI5QC3t7WXHZyTCbsMwdrr0WFi8OqNHVV8NPfwqoSKbd1c6ujl0MyxjGyjol+odf9HPohhTgJ2fAM0d8yaN3fEnFEJBXwFEPvYrY/iqTr4Z1df+Ct71KvWpqYMcOJTadneG5Z/feC7fcAigrbfnO5YyJK2Cbu5GaM2cxtcmiPvvtt8NRR6m8xmXLwq+C7Gw45hjkMcfgKh1G0vYa2LhR3WCEUDmRXq/K96uvV8dSVATjx8PkyXDnndicNpLjkrlo0kX8/L2f8+bGNzms8LCov2t/GBOoBNk7Lb1QtdOflO/xgN0uyalcCWf/gcy4l2mrdgNZfe+8uxsuukidE8ceCzNnquBhxQr49lt195gwQX2+ykrlX3zzjRoB9vnnSjlDMMTPsHdAiawhsBFZskQVbzdITITDD4dZs+C442DuXEhKiu0LiwGj5WRQUKDu321OJfp1HXV4pReLCI87o+XpG3FHV5cqTNjR0xGWlmnvtpORmEFJVgke6aG+o57hmcPZF7S3Q2rJJj6s/JDlu74gP7/sOxHp9yv6AFLKxcDikGV3mP6f08e2zwHP7ekBDoRhGcO4+rCr+fuqv3Pb8bf5f+zlO5azpHoJD572IElxfZ/YRtqm2+tmReta/rsxAV56Ai6/HM45B046CdasCa6a9MgjKho+2uf9v/cevPoq3HhjYJ1vv+XEm5+C62Fp9VIun3a5Wv7556xIbiXNE8e43HGB9aWEV15RU+uMHw8bNqj9nXMODBnit2jWNa5jWMYwyuvLGePOJCtBwnuLIDGR63p28fiSC3n+tdvpwQPf3MORry4DWzeTlt3MG71rkU+8iMjNUyNoTjpJiXJamvrLz1dX60UXBY0AWlqzFLfXzTUrevntEVB96zymXvIHFca8/LIq9L5qlRKSE05Q+25sVCK+eTMsX85fmxbzq7nw+LvwU9tIxMhRaucej+r5mz4dzjxTKUd1tfrOH38cTjiBtoQ2spKyKEgtYNbwWSzYvIA7T7pzT04ZQImo1xsi+vP/A//1Y5g0CS65BHt6CVJehmf5k1xx5hIynNto+88WmHyXKi4TcoP388orKrouLFTnhIHFosTe5YI33lAHAOqm8Nvfqs86Z45qJYX0cxmeflpaIH1061al3VHZ5uvrWrhQ/Zbr1sFXX8Fjj8Ff/qJurL/+tSqHmZY2sC8wAm1t4aKP1UW3p5vCtEIaOhtodjRTkBr+vfUX6Tscqr8NoNkZ3Pq2u+xkJmb6g6pae+2giX6oYLe3Q1JWGx2oFoxhYUXD61UNrANdcC0m0f8ucetxt/K3VX/j/i/u5/EzH6euo45bP76V3ORcrjui//quZTllLNy8kLVbv8Bh8XD0qJNUlHbSSfDCCyrp+I034GKV5onLpUTuBz9QggdKpBctChb9N99kSiNk91j5tPrTgOi/9RblQ+HwlnisFmtg/fp6dVZdf73az9atajTOY4/B3XczKd/nyzeu5/Qxp7OybiVHO7Mg16JaJMAkYNa2WTy77RUm5E9gbO5Ysg+fpV5L/Qnz3/8ljTt3MCRtCA2dDVz82sXceeLVzC6dHfylpKYGVb/6cPuHJMUlcekGqxL9YyYEwsz/+R++vHgWHa4O5o6ZG/V7XviPk3HVLuHac+Dzqcfx17P+SmpCH/PGVVerqLuzE1uKjexkpXbnjz+fX3/wayptlYzKHhW8zdatShXz8qLvl4BNY6RsAtiXrlIqKiXcfjs2RgGXUX1dPv+X5GDiic3YKw+H9esDN7hIPPmkEvf166GuTtlleXlw2GGBefK6u5Uo5+WpmwOoHtDTT1em+CefBNSdYHunsFA1jvrtzK2qUmpz9tnqhmPQ3a16Ru+/X9UzvuceVTvhiCP62WHftLUFPgr47ltJ6ouelD+Jhs4GdrXv6lP0Qz19c6RvjFFpcQQPR7a77GQmZTI8Qwn9YGXwLF8OJ56ovmdjhHFHByRlqpZLW3dbv6NyzfPjHki+d2UYSrJKuHLalcz/dj4/efMnlD5SyrLaZfzp5D/1LSo+ynLLaHI08d6iBwE45kJTHv6556ri2U+Yyra+9ZYye81N53POUUXEzb7sggVYEJxQ6WHpdl9nrpTs/vBNVhXC0du6g5PDN2xQjxMm+A6sTN1YnnoKOjrITcmlMK2QdU3raHY0U2OvYYY9NRCq+pg3Yx5bW7fyzpZ3/KmpQFhn7mNfP8bSmqVcseCKoJRVQFkQprDro6qPOKHkBIY3uUiWcdS0BXfm3vzhzVz+5uV4pTfSV0yvp5cv6r/h+hnXc+eJd/LCmheY9dwsejwRkuMNjOizsxNbt43sJCWCF4y/ACBy/fSzzoI7+k8pNUQ/K0tlYgC09aaqesDLlkFNDa1P/weAjhGqj8FbvIm2dF8EuSuKP71ihfr72c+UdVVczO6jz8N91KzgiVGTkpR1ZVbJE06AN99UN4uzzgr6/s32TlyccoL6TdusrlZqZQm55JOS1I3lo49ULmRLizqn95KIkX6SEkgjYInWmRtLpO8XfWeI6HerSN+I7gfamfvOlnc45u/HhPUFrF2rLk/jsgR1eSdktPnfV4v+AeS3x/8Wj/Tw+sbXue6I69hy4xbmzZgX07ZGBs+/Gz6gsDuOEceeGXjRYlEX8BdfwGpf7Zrnn1f+9RyTw3XuucrANFIYtm1Tzemf/YzZ1bC9o4ad7Tth82YeLayh1wo/LZeBJjgonxtgoikt9H/+R11Nf/sboHz99Y3r/X7+EY1xYaJ/4cQLyUnOwSM9HFV8lH+5uaXQ4ergr+V/ZdqQadTYa7j9k9uDv5SUFH+kv6t9FxuaNnDqqFMRDiclMpNqe7V/VSkl6xrX0eRoYsWuFURiZf1Kunq7OHnkydwx+w4ePf1RKnZX9F3h1BDJzk7aupW9AzAyeyRFaUX+juwgdu+Ghobw5SGYI31rdxdpdGIfdXjghjtiBLaRhwNgk+qz9mRVYHf62uk7d0be8VNPqeO+XLXqpFQ/5x//2O8hKebOVX1JX32lJsT19bMY9o7xlRgZPH3hrarkzSNSot6IATjmGHWDH4RKckYfiUGQ6PsCjmidudFEP1KkHzrWxIj0MxIzyErKGrDoL9y8kK92fhXWgtit3KSg+3t7O1jTfJG+S0f6B5RR2aNYM28NO/7fDh4/83FG54yOeduyXCX6GzNcHJM52Z/D7+eqq9SF8eSTyoJ59134yU/AarJmjjlG5fYt8iU5LVigHn/zG06MUxlCS6uXYl/0Kk8eCRdmHUtZKwGhBxVSZGUFR39HHaWsm4cegt5eJuVPYn3Ten9J5sN3eQOhqo+kuCSumKZKHpkj/cK0QnKSc1jXuI6/r/o7bd1tPHP2M9xw5A089vVjLN+xPLATU6T/UeVHAMwZMRvcbkot2UGR/q6OXf4BMtHmEzAymE4oOQGAI4YqKyG0xRD8QZLUTberC5szYO8ATCucxprda4LXl1KJVwyTyBqZOpmZwN/+RhY27BOCx2YYFTabeqsB6EhdQ5tdKDWLJPotLcruu/xyv/p1dalG4csvDyCJ6Yc/hEcfVefQz38OUtLZqb6OOJ85W1am4gVvH3r+vncLPxhfwdLqpX2/X1rantU/MCFleKSfl4df9MfljsMiLDFF+ubvyZy9Y7Z3zCm79m67PyAYnjF8wPbO2kY1wrzVGZxvYsQOZtHv6ABLSrC9096uHLNIaNHfx0zIn0BOcs6AtxudHbhBHH3kBeErZGerClL/93/KX/d64corg9eJi1NN8sX50W1fAAAgAElEQVSLVc/NggXKwy0tZeopl5DZDZ9ufJdn1vyD9iS49Vxf6WWz6G/cqCLN0JvOzTcrkXn5ZSYXTMbR6+D1ja9TllNGZmtXWKQPamDYY6c/FpQdJIRgUv4kKnZX8PBXD3P8iOM5athR3HPKPQzLGMZP3/op21q3UWuvpT7Lym53G41djSzetpj8lHympqubY2lcflCKrDFgLD0hnXe2vhPxO15as5SJ+RP9fm5JpjJJ+8z5F0KFtiH2DsC0IdPY0LQh2B5yOtVv4xP9iorghpQZf6Sf0gsPPURmSi9tCcFes1FTpcGpjtEWvxab3aM62iPZO889p67+G27wLzIi9C1bYNOm6B81jJtuUq28p56Cv/yFzk5l7RhMmKAEsqYG9ZmrQgbMdXSwMlW9eV1Hfd/vlZa215F+V5dqlJhFPyEBUnKUQOal5DEkdUi/kb7XGxBKiGzv9Hp7g+xIoyMXYETmiAFF+l7p9Z+/obZRtEhfJAWLPkSfN0CL/kFKcnwyw3tUaeNjxpwUeaUbblCict99Kg1v7Njwdc45R0V7Cxcqr/QCdQOx/vAiTqiBjzct5uHCak7zjuLwUbNUIffQSN9s7RiccYbKKHn6ab9Fs7phtRL00Da1j7yUPG466qaw9LhJ+ZP4etfX1Npr+c2xvwEgPTGdp89+mg1NGyh7vIySR0oYevIqCo9cypC/DOHV9a8yZ9QcLN3qDC5JLKDF2eK/8IyLZt6MeaxqWBV2Ybu9bpbVLmN2SaCzuCi9iHhLfN+RPkBaGt6uzqBoDpTo93p72dRsUlJDIXyif+WVfpclDL/oL10EtbVklmSF5eDbbECinTaXjYn5E3ELJz2p2+kuLA2P9D0e+OtflS8/OVBWw9zoeHOgA4nvvVfZhnfeSUebJyjBZpqvEsjq1ahU4bFjVaexQXU1nxSqAOiTr/vJKfTdWPcGo+VkFn2AtDz1QlZSFsUZxVEjfacT4n1DacwWT5C94wh8DsPiMSZQMYv+QCpt1rTV+M/j0Eg/muh7E8NFP5rFo0X/IKbMmUKcN2A7hDFtWiCzw9yBa2buXHXm/vKXar3zz1fLJ09mdmcuVdhoSIdbj/61Wj5hQkD0m5tVuBBJ9IVQaX21tX5vFGBG0RFRRT8axvbjcsf5SzOAqi30+VWf88/z/8nfzvkbf62axJNrhvPEGU/wxBlPcN+c+/xXY2myGrNgCPa6xnUUpRXxk2k/AWDx1qBMX76t/5bOnk5OLD3Rv8wiLAzLGNb/6N60NNodNiQyONL31T+qaDAN0jLCap/S1tcra9yshQb+jtxVSyAnh8yS7DDRb22FxCHq+M4de65aOKQCe/6Y8Eh/wwYVbYecG4boW617IPoWixqj0dVFZ21rkOhPmaJerqhA5fa73WqiWYOqKjYVqlbQN+v6qW01CPaOuWPcjBHpZyVlUZweWfSNcYFGwpVZ9CNF+hCIyo0JVDKT1DUwPGM4Lc6WPqvbmjGsHQjPCgq1d4xJdDzxWvS/F1xan8e8XUWkxKdEX+l3v4Mjj4Qf/Sjy6xkZKsdrp2+AzxRVJA0hOHGSEtiZu+M48TRfGunEiarN7/UGxN/oSAwlOxtsNjISM/ypaUfkTlYRZoin3xfTC1Vt3t8c+5uwVsBxI47jJ9N+wjWHX8O8rgn8bFM6N8y8gRtm3qAyI3wdu6Wpqn6eYfGsa1zH5ILJTMqfxIjMEby9NdjXD/XzDUqySvpviqemYvON6DR7+mNzx5JoTQwemWsSfSkDwwyMbhYzdrty5JJ77JCRQVa2iBjppxarz3hm2ZlYsMKQNbRlj1Q7N0/oavhIxm+O/1AAFQ+Ul6uxcAPipJMgPp7OnW1B9k5KivL1KyoIiP2aQB9HZ+UmGnKUYm7Z1RhpkHOAQbB3gvpITCRktoE3jpT4FCX6Eewdww+PJPqhHblGLr4h0MZoX3OkD7GnbZorxvYX6RtfkdsanL1jXjcULfoHAdE6066pzOTxnVPDlrvdpgv1tNPUyMm+RPacc9Tj+ecHefOHnX8dl1XAg5yGMDqAJ0xQwlFTEzlzx0x2tjrze3uZXDAZgWB6km86pwFE+scOP5bPrvyMq6df3feKISmbgP95ie+mU2OvweP1sKFpgzomITi77Gw+qvyIbnegZ2tpzVLG540Pm4OgJLMkpkjf1quU0xzpx1nimFQwKVj0OztZUgpbE7voaPP4qw4YfepmjAqbwtUNyclkZoaXYVCRfjUA4/PGMyxpHBRWYM+IkLZpiP7o4AQCQ/R/ohpBLFzY98cNIy0NjjuOjiZn2PipadOgYrVXpXiC7w6gWLtzJdJ3+vXEN/Hpp328h8ne2bFjz8obR7N34lLtCFcWQgiKM4qxddtw9gbPfm68nyH65kaHIbTd3WpwllHw0LB3jAQCI9L3i36MFs/axrWUZJYQZ4kL8vQdDhVDpKaqRrjLFfgtXZY2/3sXFqme9Gg3cy36BwE/+AHMi5TJ6XQqoQvh1luVDkfrnQ/jwgvVIJerg0XVOvNo/n3YnRx3018CC42ofuNGZQ+kpMDwKCMJjYE6NhuXTrmUq6dfTYbTl7oxANEXQnB8yfERh8IHkZwcHMmC//mQ9CISrYlUt1VT1VaF0+30l4c+a+xZOHod/uje7XXzec3nQX6+QUlmCXUddX3OnUpqKm29KoI3e/qgfP2Khgp/JkdXWxNnXwo3nQnNNUo5iorUOKfQKN7vivl+d2MiFXNQYLOBJaea5Lhk8lLyKMucqiL9FF+ZBLPob98OublhqmcIxZFHqvF7A7Z4AE4/nU6HhbS44N9j2jSoqrZg96Sqm4Mp0l/d5uvraCnDkt7Y9/ua7J0jj4Q//1ktvmvpXSzYFOGOGYFoom9JbkM6M/F4oDhdtRBDLR5D9I1ByJEifeKcdPR0MDFPib4h0EaFTSPSH2iu/trGtUwdMpWc5JygSN+I3I1Ja+rqAg3JbtSH9UovHmsnxcXREwa06B9genpUtuWKSKnkDocSXROtrfD00yraqK6O8U2KilQ73tSZB6io/447gu0bs+gbmTuhA2kMTKJ/2dTL+Nu5fwso2QDsnZgx5en78V2NltQ0RmSOoLqt2t+Ja4j+SaUnkRyXzMJNC5FSsrphNR09HUF+vkFJVgle6VXjF6KRlobNo658s70DSvSbHE3s7lJX6DsNn+FIgE9GQk2Vyli58ko1fGJxcDdDsOgnJZGVpdYz39xbW8GbUU1pVilCCKbkT4OsGuoSfFewuTN32zYYMybs8M2leC+4QFVY6G+mpTDmzqWTNNLtwWJpdOauYaqyHLdu9f9Gq907SXClkdR6BMl5TSxY0Ed6p8/ecbmU2K1bp+yTO5feyXOrYqumEs3T9ya2QXcWra1QnOET/fbIot+Xp0+q6pcYlzcOgfDbO6GRfnF6MQIRk+i73C42N29mSsGUqKJ/uBqqwa5dgd/S4Q2MGWnrbmPMmOCag2aMsZda9A8Qq1apO2/EwZQRRP+ppwKRRuiP2tGhBun2lSfdL7m5KrzZsCF65o6BSfT9GGfhACL9mIlk7xg3geRkSrNKqbHX+EXfaHYnxydz6uhTeXrl06T+OZWzX1R9GZEifaMp3qfFk5aGzesT/aQQ0Q/pzH219XPiPdBrhferVWHXM89U1SJCLR5/cbDugL0DwRaPzQauZCX6ANOHKvtvg/T1DIeK/ujwsSHmUrznnSfxnHcZN7/0j+ifNxJTp9IpMkhrDD4JD/PVm6tIO06lC3u9SrGlpCKxjUzbeFJkAd7kRurr4euvo+zfSIv1nVpVVfDB9g/wSm/MZbSjefruOCX6jY39R/p9i77qKS1KKyIrKStqpB9vjacovSgmT39zy2Y80sOUIVPITc4NsncM0TcqU/hF39qDy+vwnxNt3W2MHq0j/YMWY/adxsYI1XtDRN/pVCn5R/oqH4eK/ssvq1TqiK2GgTBhguon2LkzeicuRBZ987DSwSYlRXVomL8o42pMSaE0q9Qf6ZdmlZKWEDCcnzzzSR4/43Gun3E9xw4/lptm3kRRekiVUky5+n2lbaam0oYKvyPZOwAVuyvo7OlksXMNP/0WhnTCp23vAWoc1XnnqUjfnP8dyd4xlhvYbOCIr/Ff4EeXqvfb2r1ZbWxEDy6XMnWjRPqJib6/EWth6v/x0u7b+i4/EYoQdIh00nZsCqqEOnQo5FptVGTNNoX9a/C0NLMm30uibRpplnyc3nasia7oFk9aGjgctDarCKayEv94i0glyyPR1qY+Y2jRTpcIiP7QdGWL9Rfpmz39ri5fsTKf6BekFpCXkhfV04fYc/WNTtxIkb6RuWOO9Ds6gET1fsa5a0T6u3dH7gs3zrkDXXDtkBd9KSP0toeI/vPPqwzKBx5QgVCo6BsDbQY04CYSEyeq6Mz4Pxp9if6+sHeM/g2zxWOK9EsyS2jsamRF3Yqw6R6HZQzjxpk38uDcB3njv97gsTMei/gWMfmvaWnYLC6swhp0YwFl9wzPGE7F7gre2fIOTnq5eB2ctwlWsxSsLnJzVZ96Zyd8bJrLxujINeydUNHv6YEudzvdlla/6I8ZMhQcOVS7KlQZDiPSr65WUXYE0e/oCPw8L69/EQCHtZ5X178atm40enqgxxtPenejsg59CKeDaZ5vWe2ZorLF0tKgooJt6z/DGQ+i5XCy4lV6yXGnNfHGG1ESGXw9xK116uba2eXh3a3vEWeJo93V7s+Q6YvQ0bgGTm9A9DMSM0iNT6WuIziH1jitInn6nZ2+cg4m0c9NyQ2L9M0BQVFaEQ2d/ZfiWNu4lnhLPGNzx6p9OsIj/bFj1aXgj/R9A7OMc8Lebff/7JEsHh3pH0CkVKKf4xuwG2TxGBGtT+jcblV59qij1Fib0aPDf9DNm9XjXot+JI8/EnsR6Xd2qtovN96oBitdfnlQ1eTIRBL9kEgfoNJWyeT88Dl+YyEpLonCtML+7Z14D9nJ2eHlMVAWT0VDBa9ueJVCmcqsWjh/E7gsDhj1CVlZai6c9PRAJ+r9X9xP/ayLyciUfnsndPYsmw3IVMdlfFaLRRDXMo16z5rgUbnGyRHF3snIUJ1+L617iaym00lxjOfhrx6OefYvI/JNo0tVwzSoqGAaFaxrKcTttah00TVrWL1tGQC99UeSk6SUdNZpTWzfHogvgvAV9Gmt9ynUsK9p7W7xF7aLJdoPraVv0OlWot/UhD+DZyD2TldXBNFPzg3y9K3CSmp8oJhdUVoR9Z39jEJGif6E/AnEW+PJSQqP9HNyVIReXBxd9A17ByJbPFr0DyC1taoH3jdINnjAjiFsvkj/jTdUE/eWW1T/ayTRH7RI3xD6hARVOjEafXn65gTuCCxZovqQX3hBZbK88ILqUOwTo9UTJdI3Tnog4sTusTIic0Tfop+aSlsSZCVEbs1MGzKNTc2bWLx1MRd2j8Iq4eQqiHenkDhtAVaruuDmzlVTHkgJz658Fvf4V9iV9Z8we8fwpltbgaxqgKDPmtIxlWbrWjzDhgYifeNqj2LvZGTAlzu+pNZeS0n7ZeRu/SXf1n/LstplMX1H/lr6I/NUJoLBypVMo4LuHqsqvjZtGlRUUNFQQZwHOnZOoSBFRfpl01RHaEQ70hfp2xp9Vl7ZO1iw8t+H/zfQj/3mw99yMtHr6cXhdiBcmf7BS5EGaBkin5sb/NwopWSIfqIlhdSE1GB7xzeBijkgKEwrpNXZistt8vMisHb3WqYUqHEVuSm5dPV2+bfZvTtQAssQ/Y4O+hR9HekfZBjWzoUXqscg0TdFsKAG8xQWqhHwoES/qirQadvdHSh1YkT8e4wh+uPGBappRSI+XkVkoZF+enpw4bcIGJHi8uWBcTz9FqI0In1z2GW2d7JK/Iv3RvRLMkuCRKXb3c3Dyx8OeN5padiSIDs+uuh7pIdudzc/shVDdjaJHihsmI179EJ/hclTT1Ua/emqWrbbtoPXwhLrzTh7HRHtHZsNv+gb/i1AlmsqHouDbcXJ6kt0u5Xop6eHTXwCSvTT0+HFtS+SHJfMOHkelrWXk5OcwyNfPxLTd+SvpX/0ZDXE+D3VX0F5OYflqA7LigqU6NvtrG5Zx4RWK132JAozfMeU1ojFEiULzbB3dvtEf+w7jBCz/DOTxRLpR7J3DL89NS4rIPoZ4QO0jFMsO1sFWcb56nQq4TdEP8OqbmDmTlejwqYZYzyIeQRv2PF2t7GjfYdf9I2aXUa0v3t3YLoIc6Qfl65E3+zpZ2aqVoqO9A8yvvxSaebJJyttDbJ3QkR/9WqYMSOgpaNHB2f9GNUNS0vV/32OduyP4mIVCvbl5xv4RuX6sdtj8vNNWk1+vsoK7Vf0I0X6Doc6ey0WitJU7RyrsDIub1zkfcRASaYalWuI80trX+JXH/zKPwk7qanYkiHbGvDzpVQTTa1dG8jgKUorYlZzsj88S99+Gp7k3f6J7o0q2M8tWaL+ef9hbLKGh6Y6Ito7RqSfaEkKmvSjqFdNSPNRtk2dBA0NKsQbPTq8UB5KKNIye3l1/aucN/48CrLSsDencN0R17Fg0wKqbFVh24Tir6X/ozPVeXLNNeo8WLmSCTPTiY/31eDxdeZWWJqY0KXEvjhLHbutu4lhw6KIvmHvNHsRmbugsIKCtrPIS8kjOS45pgyeSKLvHy2bkBUU6RvTJhoYl19qqvoLnVBFif5u0oRP9FNycfQ6cPY6legmRhb9vnz90FRjQ/SNm0lDQ7Do19Wpc8OYQCU/NZ/U+FT/Z4yWtqlF/wCyfLny6BMSVCp9NHvH6VSWjTEoAwhrvhnR/fnnK8EPLXA4IIRQ0+v94Q/9rxsq+u3tMWXuGB8vKUndyPLz9yLS990MrBYrIzJHUJZb1u90lH1RklWCy+OiqUvZD0YJB3+d/bQ02pIg2xLoZG9uVrXIXn5ZVUjNT8nnx1N+jKXTV3E0PR3L5rkIbzxvblRG/qhRqq9zac0nZCfkwzc3MjP9fO451kNdci9paepmGBrpF6eVBlkHQxPHkdAxlkX4ToKdO6Pm6IP6iboKP6TF2cKlky8lJ0cJ5LzDb8AiLNz12V39evt+eycnAf71LxWGXnstbNhAwszDmDDBF+lPnkxTCtSlw0ipjqc4N5N4SzyNXY2UlvYT6bdKUqapAQ1i25kIIfxZWv0RydM3BDEnNctfhbI4vZheb29QTXxzzJWSEnhu3OyGDAFSG0mVSoXzUpT53+JsiRjpG5liffn6/sydIT57J1l5S+ZI32zvuFzqu0vIDNQSykrKChL90Ej/n6v/yY6etcTFRR9+s7+I6e2FEKcLITYLIbYJIW6N8PoJQohvhRBuIcSFIa95hBCrfX8RKp/sX7q6VCR07LHq+dChUeyd5GTWrVNZcUYONISLvuHjG/bPXvv6p5+uhmv2R6RIPwbRNwYcGTpeWDgA0Q+N9E2jli+behlXHRal+FyMmEssu9wuPtiuJqExi74tCbII3FiM366uTt181v9sPXefcrdSx7Q0yMigrW0Ixd2n8eK6F/0zIp0yR7Iz4ROmZpwI0sLPRvyJXgvcbPkEkGRkBDz96mogq4aRJj8f1NedWHUuSzrW0p6IKqFRVRWxExeU6NflvEhOcg5zx8z1d82kyWJ+fcyveX7189yz7J4+vyPzVIkccQTcdhu89ppqaRxxhGHlQ3o6K45QSlVsVVF/bq4gLyWPJkcTpaVRAhSf6LfYvMixC0npHUHjelWYrySrZI/tHUMQ89MCkb5hC5pbOKbLL0j0gyP9RpK9AXsH1AAyc4VNg1gi/WU7lpGXkuevY+WP9B0tdHWp79wc6YMaPxmfFug4zkzK9FtYo0errF0jsu9wdXD1oqtZzoNhUf66xnVsbelv2rPBpV/RF0JYgSeBM4CJwCVCiFD/oRa4Engxwi6cUsrDfH/n7uXx7jUrVighN4t+NHvHmBzLLPojRihLyCz6w4cHcnj3WvRjJStrr+0diFH0o3XkmtJa/3DiH7h51s0xHHh0/AO02mpYWrOUzp5OrMLKNpsSfZmSouwdGbhyzKIPqqmdYE3AX3Q+M5Pm7lRmiP+mrqOOd7aonPPJJ2xDpu8keffJAEzIHMYtX8D/eVfzx8/+SFaW+kp7e2H+fIjLr6YsvzToeLOywLPxXHqlm/dHozz23t6okb69u53qpAVcOOFCEqwJQf3xfz7lz1w29TJu++Q25q+cH/U7Mk+VCCjRN05Qn+jX16sW0IMzPRR0wtD4EwEVJxSkFvgj/V27gmforLXX8qfK5zn1cnht9mQcw95hkvgBO2oFbjeUZpb2a+90dyuxC40/DNEfkhUQ/bG5qiT5lpbABL++rFksFnV6GWJvfO7cXAmpjSS4A/YORI/0DTsumui73C7e3vI25407z9+KM/bZ6mz1p2uGin5trZpAJStJ1RIKjfSlDNxUV9StwCu9tIjNYaJ/6euXcv0710c8tn1FLJH+TGCblLJSStkDvAycZ15BSlktpVwD7M2Y1H3GI4+oHPvduwOduEf7JkYyPDo/IaKfkaH8eoO4ODXVqFn0x49XJ3lhYd+i394+gBmT+mMPI32nU11QRr3yAUX6Dge33urrOwyJ9AcDI/Krsdfw9pa3SY5L5syyM/2RviPZSq8Vsr2BK6fe12oPK5nsi/Qdqfl0exOZkXkWQ9OH8uy3zwLgHvYJAFveU6KflejkD5/ClcnH8vtPf49rxn3Y7fCf/8CO3R2441uCMndAib5j8zHkJueyaKIFfyWzCKLf0wM9416kV3RxzeHXAMFJWBZh4blzn+OMMWcw7515LNocuVHst3eMbo2EBJViNn8+FBcz0ld37/Vvl/BJehO/XQaOVHU8OTnqptjkaGLkSHUu7tgBH1d+zNkvns3IR0dyx5pHaU6B3G0XMXXrC1w14l7cbuVclWaV0upspcPVEfHYIHrdHUMQh2Zn0damvo9R2aOwCmuQ6JuHyETy9EVyG1jdxLuCI/1mR3PESD/BmkBuci71USaP+ajyI9pd7fxgwg/8y8yeviH6yblN3LT4JnKHBGpziJRACQaz6IembRqz0Nmsm0hIDAhAr6eXjc0bWd2wOuaU3cEgFtEvBszjmHf6lsVKkhCiXAjxlRDi/AEd3SDg8cBvfqMmnBo2DB58UCXJGBfc0KHqRPXb1SbRX7VKBVGhHpyRtiml8vQNN2b8+Oii//77qlf/9dcH6YPthaefnBzoZzREv89zzncVtjR5ue8+1e0QrSjd3pCVlEVGYgY1bUr054yaw5SCKVTZquj19NIWr0agZvUGMpRCI30/vki/JXkYAEPy47hm+jW8u/Vdau21fNP8CfHOYipXqBnAMuMdWCT8rfBaLpl8CfWTb2Vtxv088KCbkdODc/QNMjMBbxynlpzF4jJwr/E1DSPm6EuY8TTDrNM5cqga2m2MEzHq78Rb4/nPRf9hbO5Y7l12b8TvKMjeMRg5UtXax4hEJY+u+R3FifnMW5OALWOE//3MkT5A+eZdzH1hLivrV/Lb435L5U/XsuoZSP/oISbLHzN2lLrBVlUF35SjEa3ujiGI08arc/Szz5Qgj8weyZbWyKIfydPvjlPNBKtP9A1Pv9nRTLurPUz0Qfn6DV2RI5s3Nr5BRmIGp4w8xb8sNT6VBGtCUKS/0fsWT6x4gh3erwN99ImRRT90gNbynUr0eyxtxGcGsoi2tm7F7XXT4myJaQDZYLE/uhRKpJQzgEuBR4QQYVeEEOJa342hvCnaXGN7SENDQPh/8QsV4Rr5+aBEH0yi4bMwPIkprFkTbO0YGKJfX68ir3G+hBVD9EMFdO1auOgi1fL/5ptB+mDZ2epKMNKFBuDpm4fHFxaqXZjvH2H4xP3L9Wr/u3cTsT7RYFCSWcJ729+jqq2Ks8eezZicMXikhxp7DTar+qzZEUS/tTWk+qkv0m+OVx15ublwzXQVYc9fOZ8lVUsoizsZUFdwZrxSF2tKKv88/58U2n5A1ZhbWD17FHk/+JM6NlNqKgSE7YTCc2lN9PLlcFRqRnF4TPRZ5ddQWMGcrHl+GyHScIvUhFRml8xmc0vk/F9D/FJTI76s3nr0B2zs+oLb59xFUms7rTLHf7z5Kfk0dTX5Rf+LylV4pIfXLnqNP538J0qLVNqwzZFIdjb+lkNlZeCm15evHy3St3fbsQgLPzwnjexsNZskKIsnNNI3YomIom9RoikcwfbODvsOPNITVp4DlK8fSVTdXjcLNy/knLHnkBgXaD0KIfylGIxWsA2l4Lu6avx18z3xJtFPDIh+Xp5yCLZtU7N5fbXzK39/AXmB33VD0wb//+YJXPY1sYj+LsBc43eYb1lMSCl3+R4rgU+B6RHWeVZKOUNKOSM/Qn7z3mDUtj7xRDWytqEB7r478LpxffpF33eWbW9Mp6sruui3taksIAiO9G224Dky6+vh7LOVB1taqmqpDQqGYrS1KdV2OmP29M0BupGV0KfF49tg2Rb12zQ2RtjRIFGSVeK3c84qO4sxOSps2ta6DZtFGdDZ3YEMmnpTq93/f2+vMpbT02mJU2Zsbq7a9xllZ/DQVw/R5Gji9PFqOsyEBEjyBnoQ463xnNL6Kry0gPiOMlY4XwFgZNbIoGM1hG1KymkkeC0sGodKDYqQnvH8uqfBlc6cIZf4l0USfVAzmbU6W8Nmb4JAXfdoGSBDhkg4+XayZKmaJyExkdZWFQ9YrSrS7+jpIK+wG6s1IDb+8RUWC97kVGzOJHJyVH+V1eqL9GOojxSt2JqRTpmSbOHSS5UjZbPB2Bwl+kbaZmikb544BaBL+CLlTqW8CdYE0hLS1HgLCPP0IbroL61eSouzhR9O+GHYa0b+vxHp1/eoc7K6rdqvGe648EhfShk0iHNr61ZanC1cMe0KALw5AStgfeN6///mCVz2NbGI/gqgTAgxUgiRAFwMxJSFI4TIFkIk+v7PA2YBgyV7MVHrK+UyYkTk1y75VMIAACAASURBVMMifaMc7TbVfp4edosKtN7f8c37bRZ9CKRxdnerrJ6WFnjrLdWPMOiib7MNqMLm3oj+F9tV1NzYyD6L9Ef4rIjDiw6nOKM4SPTbfMKc5Qw0perqAv0T/t/Q5IE0W3w2gG9Y/7WHX4ujV+3n2jknk5hoqrsD/mZQdqYVNp/H70Z8zLrr1/H2JW8zJG1I0LEa0x007kjnZFnCwnEgx4RbO63OVt7f9QqsuYwh2YER09FE3+jg3NyymR07At7wwk0L+Yw/hk2gYuYfa+ZDcTmTW+9QHdq+/RtWUn6KunHbXCpXv8qxlhGZI4LE0p5ShMRCTo76bocPV5H+kLQh/rkTohHV03cFBPLqq9U9+aWX1Gd19Dr8NXiiefr+KY89SoW9HYHxEnkpeVTaKgEi2juFqYXUd9SH+eavb3ydlPgU5o6ZG7aNOdLPzYWqNnVTqWmr8Yt+rzXwmTKTMvFIj//cMtI2jbEhF026CIsnGXdWQPQ3NG9gdPZoCtMKD65IX0rpBm4E3gc2Aq9KKdcLIe4SQpwLIIQ4UgixE7gIeEYIYdzCJgDlQogKYAlwr5Ryv4q+EelHm49kaOgcGL6zbNXGJOLjI4+TMkR/8WLlrRr7METf8PUff1zVxHrhBZXdM3Giipj2cgpShVkxBlBhc49E32qlOz6dFXVDEUKJvnTsu0gf4OwyVYa5MK2Q1PhUFem7fFMlhoj+1KmB/4FAb2d6Oi2o5n9uluoPOGus6tAdmTWScYUlHHec74YQkstaWqoaTtdfr+YSPmvsWWHHOmGC6htZvx7OSTuCbbmwYlx4GYx/VfyLHm83lF8X1BhLTlb3mNCa+sYAty0tW7jxxsDI8SdWPMGqtHtJS4/cAfN0+dNc9/Z1ZDSdSvKWwCzwra2B0yU/VYm+0ZnbxDr/SFT/+slK1YwbxahR6ry1CEtYqYxNm5R9adCXp28I5PTpauzYP/4R/FkhuqdvXDN2dyNIQa89z7/v3OTcgOhHiPSL0otweVz+lEpQ9Y/e3PQmZ4w5I+K0qEbRNWM0rtGSqLYHIv1ugiN943OC0ojqaviidjkZiRlMLphMinMcPRnBkf6kgklMKZhycIk+gJRysZRyrJRytJTybt+yO6SUi3z/r5BSDpNSpkopc6WUk3zLv5RSTpFSTvM9/n3ffZTI1NYqYY6mh5mZ6uQKivSFYPU6KxMnRi6DapTF2b1bCb3RsTN8uLqQN21SEc8996i0e2NOdOMGMihpnZFEPwZ7J5KnD/1n8KxMPJYeTxyzZqkoraPLsk8ifaMW/3njVYKYEIIxOWOU6DtVSJzdoXLtjUGwM2aobSNF+i1e9T3lJKhlcZY4XvrhSzx3njKVn3kG/v1vwnJZf/ELFd3mBbQljJSUgGV3YemZFHXAGekL+XpnoFh9q7OVv5b/lTFJR8PuaWE/UWh/PCjvPN4Sz+bmzWzdqnLC3W5JRUMFHouDpNzwH+uh5Q9x/TvXc87Yczh+5yLqdwXKeJgjfSOFsbGrkRGlvThSNoWVzrAlFvqPDZSvX1kZODZzpH/TTXDFFYFt+8reMYRRCBXtl5eDpzE4bbOvjtzERGh2NpLgzsXZFfh8uSm52LrVlxgx0o+Qq//lji9p6GyIaO0A/qJru3dD7rBWv5j7I31LLz10RRX9MWOUy/h51XKOKj4Ki7CQ1DkeZ6q6+Hs9vWxp2cLEvIlMKZjChqYNeLye8APZB3zvR+Tu2KGsnQij4gG1PGiAli8UXr1aRPTzQTU7DbE0OnFB+axjxypRv+8+dbHdYxprY4j+oFg8gxTpZ2aqi6k/0V8mjgcCN7BGZ/o+ifTPKjuLTTds4vCiw/3LDNH3D+XvVB26zc2q3M2kSermHCnSb+7NJJM24p3t/v2dUHKCf/au0aN9k2OE2DtxcYGiX30xaZKK9AumHcuy5y1kJWVzyr9OYfHWxTzwxQOMfmw021q3MSfpFiD8vhxJ9OMscYzOGc2Wli3U1qr0xvJNDTQ5VGeRJS94jP9rG17j1x/8mosmXsTrP3qdEUOTgsaetLaG2ztNXU2klm4Gay/jc0Ii/XhlY5kj/cZGFW2HzmW8c6e6KRm1qNra1HcXGg+YRR/g0kuVdfTOy0NJiU9hc7PyRI3hH1JKv6cvpXpMS1M3qyRPQVBr2cjggeiePgSL/oJNC0iwJkRswYGyd1qcLTQ0QHKx8tcm5E2g1l5L0VAvJAWXcY4k+iR0sNm2lmOGHQNAgn083UnVOHudbGvdRq+3V0X6Q6bQ7e4ODELcxxwSoh/N2jEIGqDlcNCQVEpDQ2Q/38CweEIHz44frwaAPfqoOrHNN44xY9SJPuiivxeevhCx5ep/4TmKcRl1TFKDM5Xo74NIXwgRVr9nTM4YKm2VNDuayei1YO1U4Z8h8sXFITdu0wimFlcaubQEvqNohA5VjpGJE1Ufjnv0OEZV2lh2/QpGZo/krBfP4uaPbuaYYcdQMa+CUT3qbhkq+jk5kTOnxuaOZUPjZr+4fbTONOl7TrA4fFT5EdlJ2bz4wxeJt8ZTXKz2adzHzPaOOdKXecpSyHWHiH5cgf/YIJDBU12tIv3Grka/d93QoL46o+/MP8l8SJDV1t0WJMh5eWpCmxf+bWFMdpk/bdPhgN6MzWTdl4U9eRVSqpZlZ6cKthq7GkmRwaJv5OpD35G+OVf/611fM2PoDDISM9iyRWUTmS3/3JRcut3dNLQ4/TfZk0eeTK+3l9Qh9f4Km33ZOxSvwIuXo4epQUHWtvEgJFtbt/ozdybmT/Tba0YNoH3N9170a2ujd+IaBA3QcjhYbVXzokWL9KFv0W9qUk27P/4x+LX4eNUS2GeR/h5k70D/ou/1wheuGczK3uBPV2v05OyTSD8SY3LG0OvtZU3jGrLd8X5RN7J1iopCbtymEUwt3Snk0dy/6IcOVY6RSZNUJL59O5CRQVF6EZ9d+Rn/7+j/x4eXf8jiHy9mcsFk2tuVEIamWmZnR54nd1zuOCrbtoFQTf6va3yi77XgzgiO9Dc1b2JC/gTiLMryMGekSRls72QkZhBviafJ0URHylrwxGG1BZ/ErZY8/7FBcNqm0edSa6/F5YK2of+ByS/5LctotfTt3XayEoNfuOACleRQGD8uyN7ZmfUK7a526uOW+5d1dgYi/VRREFQGKkj0I3n6aSoBwYj0vdJLRUMF0wtVVPfUU6pu3ZNPBrYxBmg5ZAuezIDoAxRPquH2P/Ut+kOHghiujt8QfUuL+p43NW9ifdN6BILxeeOZmD8Rgdhvvv73WvS7u1WzNNZIX0qU6KNqlRizzkWiL9EHuO66yCXxJ04cJNFPTFQCNUB7J9TTh/5Ff/NmaPVkcVz6moDoU7BPIv1IGBk839Z/S7Y3wd+rZ9yohw6NHuk3dybHFumH2DuxYlh26wPZd2QnZ/PQ3IeYM2qOf5kxa1ZoBBzJ3gEV6fd4XZCpQujNbRWMyByBtbMEV0qw6G9s3siEvMCkO4bo79qlvgq3OyD6Qgj/AK0GuRZaxrGrNrjjyiay/ccGgfO4qio4V/8/334AF14MP7icj9etASLX3XF73XT0dITl0BvHmW8ZS5Wtih5PDw4H1CQtVPuy+EZiO4LtnQxLZHsndAIVg6ykLBKsCX7Rr7RV0tHT4S8XbaRl/vKXar4JMN1IkltxJm5naPpQxuepi3tHRzWz50YWfaOz2GKB+JFf8f/bO/Pwqspz7f/ezCMZCRASmQeDFBQEj9I61qqtoHU4KirOx9qearVqtWqrn60dbGutU7VqsdWi1Sq2xzqLtlqRSUDmKcwkhAQIZILk/f541rvX2itrD0l2pp11X1eunb32mod7Pe/9TLmHx5KXLieypWoUaMXqqtWs3L2SYXnDyEjOID05nZH5I33SjwVMX4toSL+hwXJC1dfzfsMJjBjhbbEYnH++JEG6Sf9rX4Prrw9dKLOsTCwmZxmb/fuD2p1GD8MYHZB3IDLp/9vq73FC+uJAmfhKirrU0gc40HSAXJ0aIHVD8gMHukjfaekfSOlUece0QIj0Ije19N0IRfpjCiyJq2Atw4fD9pbPmTBgAqpmJAdTbXmnur6ayoOVAUKCYNI3owhD4GCXYli/fzlq9/hW1TardR6Z6mCgTkz//vJ+dyZovb/pfb79wUWwuwzqCphdcw3NLc2epL+/Uc69m/SNAdHv0GiadTPr92ykPnkrFYmLAdiDFCIzRc/Ss5qoaaghJ7mI+nrbj2AStNwNVAyUUhKrb2Xlfr5LMqeNpV9ZKY3GRo+WJMpNm2xLn/Q91Kj1jMgbEZSnYCz6QMimJSuZ6Vprmgd9Sk7tcYH9OFSXQVbzkIClP67/uMBv4weM77JY/bgmfROuGY28A0Iaq3YX8k7tcVwZoWBkWZlViMvV6yQvDx5/PHTUR1mZ3KxrrSTEAwdE67/nnvDb84RhjH377I7bFlpabJ3ViVCkX1UVuhfAxx9D/5S9jNJrJa49u7lLLf3i7OJAyeY8ZWfs7NwpztbUVCH92lqL752a/r4kkXecXc694C5KFCUyMyWCx2npe8F0zXIjP1/22X3ujV8jedAappxQT13aGr40YALNVSPYn2hb+qurRFcJZembF4qx9EGcuRuqN7B532ZyGz1IvzmXfGzNSSk5xi1bRCpJSkjil5/8Ukh3zlxSPniI3SkLeHTBo55ds9wEaWBIP+2AHOuKXWthjKQAHVV0FLsPB1v6CflSwawoRR5oYzgZq9wrG9dgYNbAgKa/ZOcSElUi44qEdCsrZTQzd64YXyefDL/5qW3pVxzawIj8EYFOXeV7y1sdU2pSKmlJaYHpG2s20pxWRepum/QbGyG/ZQxfVH7Bmqo1gUg1kIbs66vXB3wlnYk+QfrRWPogD8nDm84mNaGJ667rnH1yR/C8+KL4AJ5+WobhbYKT9F2McuutEllU57qHQpG+1sGZxE78+98wrWA1qkGesqL8w11q6SeoBEbkiZ6Wl5ARZOmba2c+d+5EWFQpmpIyqD2QEL28k5YWOswrDMaNi87S9yJ9Z2K1E/0z+pPcnEPmkDXkjloBCS2MzJqArhpJvaoOhK+u2r0KIMjS79dPXkZOS99J+kWZRayqkuVKUo5qVWK55nAWebraNqWRulVbt9q9ExJUAtfkzoGa4Xwl/yJSNp/Jne/dyZ7DW0LW3XGTcl6e1ZyoWuofraxYC2PnUpQwmq+P+joVTRtBNQc0/aZcebMOyRCyNhKPkXe89HwDZ4P0zys+p6x/WcCQ2L1bXkCjRsFrr4mRuPBfcsKSC7dS1bgzcP+Z6CWvY3LW3/lsu9Rb0VunBn5vbIRCxrK8cjmHWg61In2NDirN0FmIK9KvrAw26IylW1ISfjlDGCtWwHO7z2RmyUde3e5iglGj5EY3JPHkk8I1FRXw9tttXJmT9B3m1YoVEj3U0BB8PrS2uc2JcLH6GzbI34nF6wJvkKLcpg5b+vffL41sTM3xSDAST25SVpAj1036O3YQ8PrtqRYCj8qRazVFbw/GjZMw3XAv7Uik75Z4lFKk7B9DQv+16AHixFUVE6FGyMckC62uWk1qYmpQMThnGLKnvJNh39xj8zws/aYssfQdFkNpqS2X3jntTmafM5uCvacDcNKJiqZXH0Nrze6TLqQxf3HQ+gKhti5STkgQ6Wh/RR79M/qzYMdnMPQDjs6YIc573QQ5WwOk35AtpD+in4xqAv10LXnHK3LHwFmKYcnOJRw9SKSdlhab9AFOPFGKwW1YLuv85ncWAvb9Z/IU9jbsbeVDcJL+/O3zSWxJ5+AmW8JpbISiBPvl7JZ3oGvKMcQN6ZeXS+bcnDn2tK1b5aaK9CwbwnjwQajT6Xy37N1O28/UVJFzVq6UZi6ffSZRPgUFMHt2G1fm1PQt0tcavvtd20fgdHiZ2ulelj54k76pCnrOyC8C4+kBOY0dsvTvuw/uvluO/Z13oltmVL5Yg3nJ/YSgm5vZsUMid3j8cQZb5aB27MAutmY1ZCpIOxidpd/O4ykrk3NrEpi80FbSB0lcasxaw/70pdCYxc6Vw6HaIv1qIf1VVasYXTCaxITg3siml6uXvGPCNrNSshhXMoSdO4OL1VU3ZArpG5kMMZwqKuQ4rz7mai790qVUVIh+P2ECsHcoN49+ipa8NTyfNYnpf5nOkp1LgNCWPsgzW1kpjus3N/8NEg9zXN6MwPUmfx0HD8p9XJu+gmG5w8jLEqI197aRd8JZ+gOzBlJVV8X2/dvZeWAnEweIE7faGtAY0jdIT04nLSmNxRVisbst/Zr6mkAtfQO3pT9QH0N1VTJay/PY3AwDk2zSd47ORuSNID0pvUucuXFD+kOGCHmbkuYgln4kaQfkWc/LE8I4MeU/TBhcFXmhDsBE8Dz1lFjdV10FF18smmLYapdueMg7f/sbvP8+nGpVinU8tyGjEiOR/uTJMGRAQ2AFRdl17bb0f/IT+NGP4PLL5T0VbalpY2nlpciD3VJ7kF27oDivDm64geI3JcM2YOlnZ7PHqldWkNkYvbzTDpjchXC6fjhNH1pf94YGaNg+hoNJW1l98BOoHM+SxQlQI6E0JpHHhGu6YUjfS94xpRiOKjqK4cOEApz+n+r6NE/S1zq4hPWuXXLvmGCGfuWXwEPlnJV2H//a8i8mPzWZO969I9CU3Iv0i4qE9McUjKFZN8PB/nwp/7jA9SZ/fcCRW5MsZQtM2GugCnpyBmlJaREtfY0OdGMzlr5p6OI1si9IL2BdtTiTR+QL6Q/NHUrD4QbWVq9tdTy5abnsa9zHoeZDLN65mGEpU2hokP00BtfgVDlZw3KHkZlijxISExIp61/mk35boJQ4YD74wE6yMNm40cBY+zcmP9bpWnVZGaxbJzV5LrhAHshZs2T499JLbVhRXp5YtXv2QE4OdXVw881Si+bmm2UWp6UfivRNVyA36W/dKtb4eedZCxl5J7OOKgppTmnbefrjH+Guu+CyyyQZZsYMedFF00w+QPpW+FvV1noOH4ZBVpJMdsV6MjODLX1D+oXZUZB+B+QdQ3rhdP1Ilr47Vn/LFmCPlChYUrGIzAMTWLQIOJRJfvIgNtRsoOFwA5v2bmJsQev2mib3ZM8eyVZ2Hpqx9McXjQ+UWHZKPDV1qeRRE3TzGOPJSDxAoC7NsGGyjU8/BRpz+O9Bd7Ppxk1cNfEqfvbxz7jxzRuB8KRvisyx5myyMxMZlD2ItMR0KFhHTQ20cIhqtYZx/ccFbI1AYxWlmDFmRiDL2gsmVv+N9dL3d8IAicc2fiy3pQ92BE9uWm7gf5OnsHTX0lbHk5Oaw96GvSyvXE5jcyNl/UTP37PHljELUgeQk5oTpOcbXPqlSzll6CkhjyFWiBvSBymfXFFhV7mMJhvXYMQI8eBPP/RKp0ellJXJUG//fgIO40mTZHqbJB7DGFu2QE4Ov/ud/PvwwzbBeJG+26BNTxer2036f/ubfAZIv6kJmpspyjiAJoE9TR4xiGHw0ENynM8+K36N884TC9fERofD1JKpXHzUxZyYJ8PyHRtFjyhOlCBrtW2rHbZpWfoBeSe3uVPlnays8BE8LS12nL4boeSdLVuAKjszuTR5QqApR0nmCDbUbAiUJA5l6Tc1iXGRnx/snzaa/vii8YHEq3VWm9b6emhoSmxt6Q8SvdBJ+sbST0yUcMdPpaAkublClE9Nf4o3LnmD/hn9yU7JJjul9f1iSD9AgqvPIT1dnPfDc0dC/nqxxvPX08whxvW3LX3nvT3n/DlSSjoETFbuOxveYWju0IDxYCz9cKRvpB2wy0vvrtvtaenvbdgbcOIePWAKEEz6qamKR896lDu/fGer7d103E3c8eU7Qh5DrBBXpH+ylEfngw9E8di/P3rS//3vYd57zSQ21XcJ6YPEeJ9wgvyvlFj7//mPyDMPPSROpWOPhZkz4d57rYbXThjGqKtDZ/fj6adlmRNPxPPBCBeK7hWr/8orEr88ahRBfXKLrLojlQdDdPLwwMqVsv+XX25FbACnny6E+fLLkZevqchi/m0vsK1CSmru2CJe0+IWi4W2OkjfZekX5LV0qrwDck1Dkb65BqHi9KE16W/eTCCqBaAs384UHNpPahF5hWsamLDN5cuDpR2AiQMncvmEyzn3yHMZPFgIb8EC+S0gB7lJ/9ozAdi62Y7o2bXLHiWOHWtLP87onTNHncnKb69kyf8saeV3ANn2wYNwYvFZ/HDY32HtNwK32qgCB+kXSYkCL3knGhjS39e4L5CUBeFJ3ziIA1ITwY10QpH+/O3zKcwopGzQUMBN+jDzSzM5vvT46Hc+xogr0h8+XLTHefOij9E3GDgQSvtbrNjJpD92rMhJt9wSbIFdeqlENJx6KnzvexLGl5cncfL33ivafxAcIRn/qT2Kdevgiivkuxfph6s04Cb9XbskVPObpnWoWai+nqIUIf2KWvs8VVYSsKy98Je/yLFdeKE9LS1NGsy89lrkcNXnnxdH6UP/FOt353Yhn0GN5TLDtm0UF2ub9C1NPzMT0vLSI8fpd0DeAdH116zxPg7zvvGy9FNSZB+95J2E5gxK+5WiUBw33K6PMyJvBDtqd7B452IUypZGHDCkv3FjcOQOiJNy9jmzKelXglISRTXfKgwaRPrm5tGanM8/JJv9bHvpY0AIt7bW9gc5kxTdIZv9UvsFNHE3DNlW70lkXPI3ABV4/EYXjoK8DVRUNkORXbbALe9EA2cvBJOUBba841VcLz+ttaWfm5Yb8B14kX5TcxMfln/IlMFTKCyUh7uqKpj0uxtxRfpG1583z7KUiN7SB2zToZM1/bQ0GSZffXXw9OJiqcH/059K8tbSpRLGWV4Od94p34OsG8fTPHv1VDIyLCmG9pG+SUcHIWKt7fUFWfpJwgyV++w7+NxzxT/hBa3hhRfglFNskjA4/3x58P71L+9lDV6U5lW8+kkR1eTZ2bj7rSy3hgaKc+ul3kztgUD0TkEBol11orwDYuk3NnpH8IQjffDOyt28We6Hsv5ljC4YzfgxdueU0f2FhP5v3f8xNHco6cmt99uQvtatLX03pk61y4Gb/cijxrb0q6qgqYmSpF1sW1wJTz8duFe8SD+KxPAAAmU9KoPaUwMwKn8kJDWxdf826L+CganDyUjOaJeln5aURl6aPC9uS7+goHWSJdiWvvuFZcJjvUgfYNPeTUwdPDXwInFb+t2NuCJ9EF2/stKOeW8X6XdBpmmoHKAbboA77rAkFQemThU/wKJFjokW6deTxpylR3LeebaEYLorRaPpQ2tL/5VXZB+OMqXWDSHW1TlIX2q2NDaKPPDRR94JXgsWCBlecknr3844Q1YdLopn7VoJb501CxqbEniemeyoSJRs3Ao77KQ4rZr6ethbmxiw9AsLEbbtZHnHFOfzenm1h/RNocCHz3yYOefPCSrhPW6gyA1fVH4RFPbnxMCB9j0WDemDXCdPS98S8kvL+rG13zi4/noq3pRwTKe8YxCufIkbTtI396ct78hDsKtpHRStYHi2hEl5GTTRwEg8Tku/stJb2gFvTR9siScU6QNMGTwlcN590u9kGF3/L38R7XjQoDYs3IWk31aYB9MMw4EA6c9lBvsbUoKaWZgHwxmyGUnT379fTsG//y1+kfPOc7ycHPJOnq4mkcNU7pbbZ/lyicBpaZFuYm688ILc7AGpyIHMTDjrLHEaOxJAg2Cs/Pvvh0lHNfI0V7Njd5JEXO3YEah5UZwgb60dB3MCmn5BAcK2tbWhN2BOTgcs/QkThPiefbb1b5FI36u88ubNEoY8umA0EwdO5Igj5BwmJEDZIJuEvPR8kGoShszc8o4bxx4r1/nTT0No+pZWWjIkkW0Zo2HAAHY9Ixfa3VdCKW/fRSiEs/SNll6duBLy1zE6V0jfXKb2kH5BegEl/exszXCkP6ZgDOlJ6a0ibYwzNxzpH1t8LMnJcs190u9kDB0qFtLu3TI89hq2hUQPJv2iIgmN8yL92cyitH994IUHctwpKW2TdwBef11IeORIO+wTsM9JXR0JDXX0V1UBJ9hCSVokO1uWd6K5WUj7rLNCD/vPO0+ya4OOzYGXXoJp08Rfc/VlTSxlIh+tLhLS37498EYsPixW/w4GsVsVUV7uIH3TiSMUOijvmG5QH39sR48ZRGPpOzX9lpbW4caJiXJNsrKgICM/IFWEsvTBlngiWfo5OfLCmj8/BOlbln7JyDR2VSRwqGwCFVXilDWWflaWjKpzckI3bfeCF+mbAVdxdjGqOY36kjcg8TBlhUL6CQlBEcRR49pjruWHX/5hUELV7t3eMfoA08dMZ8ctOwJ5DQah5B2j9Y/IGxGQhgoLfdLvdBhdH6J34gbgHl/2MDgdbgCkpbEjdRhvczqXnbmn1cOWmdl20p85Ux6C995zPQwOS5+6OooSq4NIv6BAln3rreDsznnzRDbyknYMzjpLLNPXXmv928qV8MUX8N//Ld8vvjSRNOrZW5/GoAEt4oiYOBGSkxl8UPT9v3IBE397BTU14hwPsG04iaeD8g5I/kFiYmtrv63yzq5dMnIaMiR4vjFjbCva6Mxe4ZoG0ZI+2PdWdbUcQ1Z6S7C8k5RE6dhMSdDKGMmufXKunFby2LFt0/NBHrWsLJv009Ptl0aCSiDt4EgY9j4A4weOC1qurZb+xeMv5nv/9b2gaeEsfaWUZ25BJEt/aoldb6egoJc6cpVSZyil1iil1iulfuDx+1eUUouVUoeVUue7fpullFpn/c1yL9sZOOkk+WyTng9d5shtL6ZOFQvQmRX5fMqVtJDI5RfUt5o/FOmH0vRBrOn337cJIwCHI5f6eoqSa4JIf/JkSbY6eDA47v7xx4Wovu7dlQ4Qojj5ZHj11eDuRSCjBKXs5uC5g9I5H4nxLM45KGZxSQmUljJorxQRe4rryEpvYf58a7uRSF/rDss7IOfw61+XXAtnFE9buqPVHQAAIABJREFUSd8EIbiNlrvvtht9GJ05lLwD9jWMJO+A3FtVVeIzys8HlZ0VbOkXF1NyhNDFtqShVBzMoqAguCjpHXdIxnVbUVQk725nf1yDjMaRkHgIWhKYMNge1WRmtt3Sd+PQIXnJhSL9UJh2xDROGXYKk4snB00vyiwiKSGJaaXTAtMKCnqhpa+USgQeBc4EyoCLlVLudLItwBXAC65l84EfAVOBKcCPlFJR3IIdQ4dJvwdb+mBb+1rDU42XcTwfM2Zia8Jyk344TX/8eCmPMG9eawszaKG6OrH0U/YGnG9ffCGkf/LJYrUZieef/xQH7fe/H5lPzzlHEoScTeO1FtI/8URH1I9SXJ0mt1lJuhWIP3gwlJaSsXMDpx+3n6t4mkW//tBughOJ9I1DIgYv+6uuEkv9zTftaWazobTu/Hw5rYYYTEkE93WYOFFerABnjjyT04afFpARvNBWSx/gww+t+TMzgzX90tJA4cJtqpRdTfkMHBj8hj75ZBnttRUmQctY+k7kHLYiGmpGUJBjWyvue7s9MCHGbSX9AVkDeO/y9wKOYYOCjAKWXr+Uaydda0/rjaSPkPV6rfVGrXUTMAeY4ZxBa12utV4GuD1lXwPe0VpXa61rgHeAM2Kw32ExdKhYRNdeG3HWYPRw0j/6aLGsDOl/8AGsaxrK9TzhOa7Oyope3klMlMYvJkOzFZzyTn09Ren7qayUMNLmZiH91FRpIvP668IXN9wgQ/7bb498bNOny6dT4lm4UPRxI+0YnJjzOS+e+iSXTLCyoYqL5Q2/dStv/fxznuYasooc19Ccm1Cx+u3smuWFs84SEnnmGXtaba2sOlSpfneCVihL34lZE2fxzmXhq9W1hfTHj5dL3Nhoze+8ebZtg5KSgBG19fAgKhjAgLwo6mdEASfpux+93BZx5qqqcUHnrz3yjhsm0iyWFXXL+pcF2lZC79X0BwNbHd+3WdOiQUeW7RBuuKF12GNE9HDST0sTa8+Q/hNPQH7yfs7nldbNVwkt77TrxnM4cqmrY0B6LQcOSJgmCOmDkPeOHSLHlJdLpnM02xs8GKZMsUlfa0lQKyyEiy4KnldlZXLhgA/J2WuxoyH97dttYs+y49ojWvrt7JrlheRkyTr++9/tbM9QdXcM3KS/ZYuEPUbR8jgszjgDrrxSCD0SkpKkREZgf7IseUfrAOn36yeTtzUUsouBDMxpLSm2B4b06z2S4QuUkH7qvnFB06OVdy6/HL71Le/fwmXjxgoFBXL9zaCpt5B+p0MpdZ1SaqFSauHuUJ08ugI93JELMgxfsED47dVX4YqRH5Oek+IZMuEcoUOH+oS0tvQz5W3yz39KBIexKs86S3blrbck+ewrX4l+E+ecIwXetm+XDNyPP4YHHvCI+zZW6I4dMkQpKhLSb26G9VYrQaeWEon029kUPRSuvFI0/eeeszfbFtI34ZodxaBBMuKI9rCMxBMk71RXy0uxtBSlrLr6B3LF0s+s7fhOIpdv927ZnPvRG5w4AQ72J7vq1KDp0cg7FRVyH3n5iqDrSB+s5j70HtLfDjjV8RJrWjSIalmt9ZNa68la68n9O6t7STTo4Y5ckAfz4EHRyQ8fhutuyYbbbvOc10vTb/ehuaN3+ol1/O9/i5VvXiSFhfDlL8uQ+Re/aNsmzjlHPv/8Z+n8deyxHqUnwCakHTvsil9GezClLsOR/nPPSSKHQQzlHZDs3OOPl25oWkcmfWd55Z07JXLKWN1diSDSNy9WU2HNEvRLSmD1zn4cJIuBaXu9V9RGFBXJ+3r7dg9LP6MAfllJYe3JQdOjkXdeeklcNRUVwcEPBuEqbMYKbtJPSQk9b1chGtJfAIxSSg1TSqUAFwGvR1jG4C3gdKVUnuXAPd2a1jPhDhTugTAP5pw54jgbc/U0qdHgAS95p92kn5wsGkBdnVj6FukfPmxLOwYvvCASVDRashNjx0q1xh/+UJyhjzwSIubbSA/bt9s1sQ3pr1plz2NgXgD790vXliuugF/9yv49hvKOwTXXiFP6k0+it/Srq6WhzqFDIS9pp+I4q51rgPQPHLCLWDlIf9UmeT4GJO6JyXYN6W7e7BG9Y313q5fRyDsvvGDfBiaXxInKSrEX2pJB3FaYXtnbLVO3V1j6WuvDwHcQsl4FvKS1XqGUuk8pNR1AKXWsUmobcAHwe6XUCmvZauD/IS+OBcB91rSeCXegcA/EyJE2mV5/ffh5Y0r6IAsbS9/hxHOTfnFxGIdwGCgl1n5zs0hDU6aEmNEp7xhdyXg9jaXvJP2kJGGPFSskYUDr4BjJGMs7IHWIsrPhD3+InvQXLJDGOtddJ6W+uxqlpbL9K67AHk25LP3SUmhpkWHdQFXhvaI2wpB+Q0No0ndeTjM9nKW/caNkGN98szzOQeVLLFRWyoi0Mx93Y+mbkUZPIP2o8lW11m8Ab7im3eP4fwEi3Xgt+wzwjNdvPQ5enqQeBqVEOliwwJZDQsGL9Ds0iMnICFj6/fPsQPRYShHXXiuhmw88EGYmQ0j79tlOg9xcmV5TI0+WO1SmXz8Z72dlSYiRM8stxvIOyGYuvhj+9Cch/3DOVGNpPvaY7Prdd8dsN9qMa66x/nHKO4mJgZhZZ7/pAYejVXnDw2T1QuwsfaPeXXWVlPgIRfqdKe1AMOknJUHCzu3SSeirXw2fsdiJ6LkmbXfAK2asB+L3v5d46kj6YFaWhIqZfrkdzj9yWPqZOUlkZoqh3ab6RhEwcqQ8pGFdO1lZEmRdU2PLO8bLCN4B8SZs8+mnRcfYuzf4xEDMfTnXXCOnq7IyfD2apCR5JzU3S8SSuxJptyArS54HU+7TaoLgJP2BTVtCLNw2OInXfQkM2bstfUP6Xg5arcWBO22aOMQnTRLSd8/rbIjeWTCkv3s3pCYeEofPH/8oSTFeO98F8EnfCa/skB6I4mKCqi6GgrsaYUzknf37RchPT6ekxPYxdCmcYUnO1GFD+m6GACnkf//98mn0sb2WI7IT5B0Q2etL0vMlYvhlXp7s1q23xnQX2g9z86xdG8T05hQrWig8uDkmmyoosAMB2iLvaG1fOieWLRPXjkkUmzRJnLnbXQMTI+8EYe5ciYuOpodnFMjIsAeQqY375aa46y6JMluyJCbbaCt80neil1j60cJdabPDpJ+RYVfkysjglVekNWOXw8kAxtKH8Jb+ffeJhxhs0jfH0gnyDgiRGbkkEunfdZeUb2hr7ZpOgznHq1cHkb75t3/yXpKqK2OyqcRE2+HZFnkHvCWeF16Q0ZMp3WF8Tm6Jx1Peee89yTh0vyE6gMICsehTMxLh3XfhpptkB9vUEDt28EnfiTglfael3yFeS08n0IMwPZ1x4zxq9HQFIpG+l6XvhJv0O0neASn4NmKEbfGHwjXXSBexHgNzDl09R3OkajUDMmrteyEGMOQbraUfrqb+q6/CaafZL5IJE1o7cxsaJFO6FembLjhbtxIrFGRLOm5qRpJYAgUFsoMvvdQtEo9P+k70AkduW+B+MDqs6Wdk2A96d54np9nnJe9EKujuDIyHTpN3QGSb9et7GKFHA+c5dlj6xnUyKPtAl5C+2Q23pe9MEHeipkYCAZxJgRkZIqU7ST9kjH5nkH6qPICpGQ66vfBC2LTJ28PcyfBJ34leoulHi07R9B2WfrfBmH1pacFB1u219DtJ3unVcJ7DkuDAvMceg5989UM5f+Ea07QBsbL0DYcee2zw9EmTJFbfGNYmGzdI029pESIGO1Q1BihIFOMiNdMRUXbOORJh1g0Sj0/6TsSZvONumRgT0jc1g3uCpV9cHFxTwsTqR2vpd4G802sRhvRPOgkmj7fCwiI1nI8SkUg/lKXvJv0FC+TTHUY8aZIQvZHqPUsw7Npl3wsxtPQLW2RjqVmOCPm8PDj99G6ReHzSdyLOSD/mmr7z3PQES9/tUIjW0jejA6eln+Jdv6jPwsmyXjXKnV2/Y4BQpD9ypFR/Pfts791zyzsLF4oPxd1DwO3M9ZR3nF3tYynvNEhmVmqqq+jVhRdKSOxnn8VsW9HAv8ud8DX98HAu3J3nyZC604kLcsDTp0vxn3BIShKPpJP0fWknGOYcJyR4Jw7EmPRNgpb7/kxIkJB2t/YeSt5ZsKC1tAOtnbmelr4h/REjYivvHJDQ1lbZuNOni7FhmkB3EdrSQTb+EaeW/oEDEnbc3BwDR65Bd1r6TnnHjblzo1tHfn6wvONLO8EwpD9okHejaRMaE2PSjzRIM/By5FZUiIHuLgti5i8rk0zd5mZJyE5NdW1v40aRC084IbgLTgdRUL0O8EimzM2V7PCXX4YHH+yykaZv6Ru0tMRA9O5ZcFpDMQlQ6WmWfkfiRZ3dyOPsuscE5uYp8ayuYlv6pv1UB/G1r0njo5D1llzwsvRNUTUvSx+kJENdHfz85xKOP3q0q8z4xo0iZY0YIUMB0/mkI9i3j8K6EJY+SDLB1q1dKvH4pG9gHDhxaOl3Cul3J0kecYQUrXcLvW2B09L35Z3WMM9BqJ6jMZZ3UlOl8ZFV7SEivBy5CxcKiR99tPcy3/ueOHIbG8Vn+8knrhk2boThw+1jjkWC1qZNFCDnyJP0p0+XKJ6//rXj24oSPukb9PCuWe1BUpIMKQ8etN9pMXPkdud5SkqS7iCjR7d/Hb68Ex4JCaK5hDrHOTkyTwxj9dsCc/vVOvq4LFgARx4ZOXgrMVEOrZWUZEjfjG5i4cyNRPq5uRLF8/LLXRbF45O+QS/omtUemGKJcWXpxwJuS7+3H09n4NNP4Y47vH9LSLC7fncDEhMly/nPfxbLXWux9L30/KhQVyedTpyWfluduS0tos07RwiRSB+kDveWLXa8aSfDJ32DOLT0wS6vHBPS7ymO3FjAkL6p2uXLO60xdGh4z2pBQcw0/fbgF78Q4/yRR4SfKypC6/kRUV4unx2x9P/zH6mY9+ij9rRNm8jpJy+pkKQ/Y0aXSjw+6Rv0glaJ7UFMSd8snJra+2Pa8/MljKO21pd32otutPRBnL9nnindxv75T5kW1tJfvlwaL3vBhGsOHy4vutzctpP+a6/J57vvBq1XDR/GTTeFKcWRmyv19f/61y6ReHr5kxtDxLGlf+BAjDR9Q4zxcI6cWbm+vNM+dDPpg3S9PHAAbrlFXD0TJoSZ+bbb4Jvf9C4d4SR9sDrAt0He0dom/YULbelw0yYYNowHH5SXVEicf74kann1dYwxfNI3iGPSj7m8Ew8E6SZ9X95pOwoLu530jzxS2oYeOABHHRXh1ty4UUIxvcIjN24UC9/kH5SWts3SX7VKKutdeqm8AD74QD7Ly6PrHTpjhry1ukDi8UnfIE4duZ0i78TDOXJW2vTlnfbBaPrd1AHK4Mc/lrSLadPCzKS1OEsB/v731r+byB0TuF9S0jbSN0mB998v4UPvvCNOhvp6e/QQDvn5Um7Z6FSdiKhIXyl1hlJqjVJqvVLqBx6/pyqlXrR+n6+UGmpNH6qUqldKfW79PRHb3Y8hfE0/MuLZ0o+HY+pqFBRI6Ey4ZrVdgMJCWLlSkq5CoqLC1jjDkb5Baam80MwykTB3rniRhwyRinTvvmtX7IzG0gfpg9oFSVoRSV8plQg8CpwJlAEXK6XKXLNdDdRorUcCvwGcp3+D1nqi9Xd9jPY79ohTeceEbPqavgumIpcv77QfMU7Q6ggGDoxwW5ronJNPFoeu+Q4yCvAifYhO19+xQ+o6zJgh3087DTZsgPffl+/Rkv4RR3SJ8RGNpT8FWK+13qi1bgLmADNc88wAZlv/vwycqpRylZTr4YhT0u8UeScerGJD+lVV0NQUH8fU1Yhx/Z1OxWarn+///q98Oq19LxnGhG1GQ/pmXYb0v/pV+fzDH+Rz6NB27XJnIRrSHww4xa1t1jTPebTWh4F9gGUGMEwptUQp9aFSKkL5w26Er+lHhjk38XCO0tPlb8cO+7uPtiHG9Xc6FcayP+00GDMmmPTdkTtgW/rR6Ppz50q9nnHj5PvYsVIMsLxchiA97N7qbEfuTuAIrfXRwM3AC0qpVi2ilVLXKaUWKqUW7jaFrrsacazpNzba6eoxkXfi5Rzl59vZk76803b0IHknIjZvluudnS01m+bNk/6/4E360SZo1dZK9bYZM2wnsFLycnGvs4cgGtLfDjirLpVY0zznUUolATnAHq11o9Z6D4DWehGwAWhVzENr/aTWerLWenL/oP5lXYi6uvhIOnLBFF3bsycGfULMCuKJ9H1Lv/3oTaRfXm7LLGefLbXG335bSP3PfxaiHjLEnj8jQ44vkryzcKHIg6efHjzdkH60en4XIhoKWACMUkoNU0qlABcBr7vmeR2YZf1/PvC+1lorpfpbjmCUUsOBUcBGuhP33Qdz5rSeHme19A2cpN9hXlNKVhIv58lp6fuk33aYCKjeRvrHHy8+ndtvh1GjxOF6772tR3vRhG0uXSqfEycGTz/tNHleRo6Mxd7HFBFJ39LovwO8BawCXtJar1BK3aeUmm7N9jRQoJRaj8g4JqzzK8AypdTniIP3eq11dawPok34zW+ks7MbcUr6pnRKVVWMeO2ii2wrprcjP19q7IIv77QHyclSbTOSpn/4sJ2h2hk4dEhKFD/yiPfvWou8Yyz5pCQ491x5EcycCevWwd13t14umgStZcuk/ZbpAmMwaJDE6hvHcQ9CVJ2ztNZvAG+4pt3j+L8BuMBjuVeAVzq4j7HDvn2wdy8sWSKp2E6tI85aJRoYSz9mpG8iEuIB+fl2Sr5v6bcP0ZRi+NnPpPrkpk2tm9dGgtYSu56XJ85Sr4L7jz0mjtl33xUydzfXqaoSo84ZRfO730ki1aBBobddWipF1MJh2TIp9+mFU08Nv2w3Ib4E7EgwYVsHDkgcrRNxauk7Sd83Zl0w8gT4pN9eREP6c+aIwfXcc8HTKyoknXbtWu/lFiyQNNvjjpOIm+xsaa319tv2PJWV0kR36lQZUfz4x63XY557t2YfjvBB5J09e0Innx0+DCtWRCj40/PQN0kfYPHi4N82bWo9RIsDxNzSjyc4Sd9/I7YPY8fCv/5lR8C4sWGDEGNCAjzxRHDJhttvFy39yCPhkkskwWnePHjySfk+ZYrUs3n0UWmac/318vI4+2z4xz9kHXfcIaQ8e7a03nrmGamD44QJ12xrvPxRR8mnSbJyY906yXoMZen3VGite9TfpEmTdKfh4Ye1Bq2V0vr22+3p1dUy7b77Om/b3YQlS+SQQesTTujuvelheOIJ++QsWtTde9M7sXmz1tnZWp90ktbNza1//9Wv5Pzec498zpsn01et0johQetrrtH6ttu0zsy0rwVonZGh9Q9+oPW+fcHrq67WevJkrZOTtf7xj2XeW2+V33bv1rpfP61nzAhe5sEHZb6amrYdW1OT1sXFWp9xhvfvc+bIepcsadt6OwnAQh0Fx/Y9Sz89XYZjS5bY0z/+WG61r3yl+/atk2AsffAt/Vbw5Z2O44gjpL7xvHlSO8aN114TS/j226Vu/BNW+a1775Vz/tOfStGczZtF/nn7bbHMa2vhgQegnyutJy9PHKTHHCNSzqBBthO2sFC2M3ducN388nJxOOfmtu3YkpPhf/4H3nxTrHo3li0Tp/CRR7Ztvd2MvkX65eWi6x1zjMg7Zqj50UcSgz5lSrfuXmfASfq+guGCL+/EBtdcI6UHbr3VLjIGoil+/LEkLmVkwKxZ8Mor4nCdMwduvBFMXk5BAVx2maxnyJDwCSW5ufJyuOIKePbZ4Ka4N90kL4Kf/MSe5gzXbCuuu07I3yvib9kykbdCtsTqmeh7pD90qJB+VZUdo/3RR0L4cWjtObvdxeHhdQy+pR8bKCVRXQkJQsSHDsn0f/xDoqNMTZrrr5ffzj1XLO/vf7/92+zXTwjf3ZkkI0P24e23xckLweGabcXAgdLg5NlnpZ6JE0uX9j49n75G+ubiH320fF+8WCJ5Fi2KS2kHfHknLHzSjx2OOEKs4Y8+Eoeq6SRVUiJGFohVfNJJdqurtoZvRouZM6UV5osv2o1MOlL07NvfFgfy88/b02pqJIa/F5J+VHH6vRK7donGl2Qd4sGDYt0PHSqavlKi62dkSOhVnJK+acjc2OjzWiv48k5scemlsHq1SCtHHCHW9lVX2TVpAO66S4j4xhs7bz/GjZNn/IUXZJ9qaztG+scfLxm3jzwC114rx7N8ufzWC0k//iz9hgbphTl4MPz61/Z0Z6xuZqbE/S5ZIpZJQoJc2DiFsfZ9XnMhK0uMAqXEp+Oj47jvPrjgArjnHkl4nOGqwn7qqeL0dTtoY41LLoFPP5ViaNB+eQfk/vjOd4ToX35Zpi1bJp+9LEYf4o30Fy2CSZPgl78U8/aDD+zf3LG6xpn70Ufyv9MZFGcwpO9b+i4oJdZ+enqwNeqj/UhIkJj5KVOkPMGJJ3bPflx8sVzTBx6Q7x2taT9rlnDLDTeIr2DpUnE+R0rw6oGIH9Jfs0ay8vbtkz6TM2dK+raJ0HFn5R19tGhyn3wSt9KOgU/6YZCf7w+BYo30dDGmli7tvhFUaak81yYJsyOWPsiIcPZsKcd8ww22E7cXGgvxQ/pjxkjm3vLlcMYZYmlUV0tGH4iln5Ii3niwnUuHDvmk35dhLH0fsUVqqv2sdRdmzpTPrKxg/017MW6cyFevvCIllXuhng/xRPogiRQmImDqVPk0jYbLy8W5ZOJ/naVQp03rsl3sDpiwTd+g9UBenk/68YrzzpMY+yFDYmeR33KLcIvWvVLPh3iO3hk3Tkzc+fPljb95c7Cul58v3zMz7WYQcQrf0g+DK6+MriWej96H/HyJEoplIUUj83zrW722xHj8kn5iojhe5s+X7+Xl8I1vBM/z61/3CfPXJ/0wOO+87t4DH52JX/4y9uscMyZ0EbZegPglfZBh2G9/K87diorWHvxzz+2W3epq+KTvw4cPg/jS9N2YOlX6V/797/K9ox78Xgo/Tt+HDx8G8U36poDaiy/KZ0djdXspfEvfhw8fBvFN+iUlkjzx1lvyvY9a+iZ6xyd9Hz58xDfpKyUSz6FD4nUvLu7uPeoW+Ja+Dx8+DKIifaXUGUqpNUqp9UqpH3j8nqqUetH6fb5Saqjjtzus6WuUUl9zL9vpMBJPSYldfK2Pwdf0ffjwYRCR9JVSicCjwJlAGXCxUqrMNdvVQI3WeiTwG+Dn1rJlwEXAOOAM4DFrfV0Hk6TVR/V8kNyz00+X3DQfPnz0bURj6U8B1mutN2qtm4A5gKt0HjOA2db/LwOnKqWUNX2O1rpRa70JWG+tr+swebLIPH1UzwfJU3vrLV/e8eHDR3Rx+oMBZ8riNmBqqHm01oeVUvuAAmv6p65lB7s3oJS6DrgO4IhYm6P9+kkS1nHHxXa9Pnz48NEL0SNEbq31k8CTAJMnT9Yx38BNN8V8lT58+PDRGxGNvLMdKHV8L7Gmec6jlEoCcoA9US7rw4cPHz66CNGQ/gJglFJqmFIqBXHMvu6a53VglvX/+cD7WmttTb/Iiu4ZBowCPovNrvvw4cOHj7YiorxjafTfAd4CEoFntNYrlFL3AQu11q8DTwN/UkqtB6qRFwPWfC8BK4HDwLe11s2ddCw+fPjw4SMClNaxl9A7gsmTJ+uFCxd292748OHDR6+CUmqR1npypPniOyPXhw8fPnwEwSd9Hz58+OhD8Enfhw8fPvoQfNL34cOHjz6EHufIVUrtBjZ3YBWFQFWMdqe3oC8eM/TN4+6Lxwx987jbesxDtNb9I83U40i/o1BKLYzGgx1P6IvHDH3zuPviMUPfPO7OOmZf3vHhw4ePPgSf9H348OGjDyEeSf/J7t6BbkBfPGbom8fdF48Z+uZxd8oxx52m78OHDx8+QiMeLX0fPnz48BECcUP6kfr4xguUUqVKqQ+UUiuVUiuUUjda0/OVUu8opdZZn3ndva+xhlIqUSm1RCn1D+v7MKsn83qrR3NKd+9jrKGUylVKvayUWq2UWqWU+q94v9ZKqe9Z9/YXSqm/KKXS4vFaK6WeUUpVKqW+cEzzvLZK8LB1/MuUUse0d7txQfpR9vGNFxwGbtFalwHHAd+2jvUHwHta61HAe9b3eMONwCrH958Dv7F6M9cgvZrjDb8F3tRajwUmIMcft9daKTUY+C4wWWt9FFLZ9yLi81r/Eekd7kSoa3smUpp+FNJl8PH2bjQuSJ/o+vjGBbTWO7XWi63/axESGExwn+LZwDnds4edA6VUCfB14A/WdwWcgvRkhvg85hzgK0jpcrTWTVrrvcT5tUZKvqdbDZkygJ3E4bXWWn+ElKJ3ItS1nQE8pwWfArlKqUHt2W68kL5XH99WvXjjDUqpocDRwHxggNZ6p/XTLmBAN+1WZ+Eh4DagxfpeAOzVWh+2vsfjNR8G7AaetWStPyilMonja6213g48CGxByH4fsIj4v9YGoa5tzDguXki/z0EplQW8Atyktd7v/M3qWhY3YVlKqW8AlVrrRd29L12MJOAY4HGt9dHAQVxSThxe6zzEqh0GFAOZtJZA+gQ669rGC+n3qV68SqlkhPCf11r/zZpcYYZ71mdld+1fJ+AEYLpSqhyR7k5BtO5cSwKA+Lzm24BtWuv51veXkZdAPF/r04BNWuvdWutDwN+Q6x/v19og1LWNGcfFC+lH08c3LmBp2U8Dq7TWv3b85OxTPAuY29X71lnQWt+htS7RWg9Fru37WuuZwAdIT2aIs2MG0FrvArYqpcZYk05FWo/G7bVGZJ3jlFIZ1r1ujjmur7UDoa7t68DlVhTPccA+hwzUNmit4+IPOAtYC2wAftjd+9OJxzkNGfItAz63/s5CNO73gHXAu0B+d+9rJx3/ScA/rP+HA58B64G/AqndvX+dcLwTgYXW9X4NyIv3aw3cC6wGvgD+BKTG47UG/oL4LQ4ho7qrQ11bQCERihuA5Uhfo8WGAAAAXElEQVR0U7u262fk+vDhw0cfQrzIOz58+PDhIwr4pO/Dhw8ffQg+6fvw4cNHH4JP+j58+PDRh+CTvg8fPnz0Ifik78OHDx99CD7p+/Dhw0cfgk/6Pnz48NGH8P8Bccl9dRbnepkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mob_01_f1 = pd.read_csv(main_path + 'f1_0.01.csv')\n",
    "mob_001_f1 = pd.read_csv(main_path + 'f1_0.001.csv')\n",
    "mob_0001_f1 = pd.read_csv(main_path + 'f1_0.0001.csv')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(mob_01_f1['epoch'], mob_01_f1['f1 score'], color='r')\n",
    "ax.plot(mob_001_f1['epoch'], mob_001_f1['f1 score'], color='b')\n",
    "ax.plot(mob_0001_f1['epoch'], mob_0001_f1['f1 score'], color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING MODEL WITH FACTOR: 1.5\n",
      "Epoch 1/80\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 684s 684ms/step - loss: 9.4477\n",
      "Epoch 2/80\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 616s 616ms/step - loss: 4.7836\n",
      "Epoch 3/80\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 567s 567ms/step - loss: 4.6395\n",
      "Epoch 4/80\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 563s 563ms/step - loss: 4.4467\n",
      "Epoch 5/80\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 566s 566ms/step - loss: 4.3176\n",
      "Epoch 6/80\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 565s 565ms/step - loss: 4.6294\n",
      "Epoch 7/80\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 567s 567ms/step - loss: 4.4301\n",
      "Epoch 8/80\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 564s 564ms/step - loss: 4.2265\n",
      "Epoch 9/80\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 567s 567ms/step - loss: 4.1728\n",
      "Epoch 10/80\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 657s 657ms/step - loss: 4.1465\n",
      "Epoch 11/80\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 584s 584ms/step - loss: 4.1126\n",
      "Epoch 12/80\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 586s 586ms/step - loss: 4.0839\n",
      "Epoch 13/80\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 589s 589ms/step - loss: 4.0174\n",
      "Epoch 14/80\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 585s 585ms/step - loss: 3.9874\n",
      "Epoch 15/80\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 584s 584ms/step - loss: 3.9465\n",
      "Epoch 16/80\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 586s 586ms/step - loss: 3.9021\n",
      "Epoch 17/80\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 601s 601ms/step - loss: 3.8636\n",
      "Epoch 18/80\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 565s 565ms/step - loss: 4.0825\n",
      "Epoch 19/80\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 566s 566ms/step - loss: 3.8706\n",
      "Epoch 20/80\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 568s 568ms/step - loss: 3.8851\n",
      "Epoch 21/80\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 564s 564ms/step - loss: 3.8183\n",
      "Epoch 22/80\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 563s 563ms/step - loss: 4.0379\n",
      "Epoch 23/80\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 565s 565ms/step - loss: 3.8375\n",
      "Epoch 24/80\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 565s 565ms/step - loss: 4.2264\n",
      "Epoch 25/80\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 567s 567ms/step - loss: 3.9756\n",
      "Epoch 26/80\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 565s 565ms/step - loss: 3.8268\n",
      "Epoch 27/80\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 568s 568ms/step - loss: 3.7982\n",
      "Epoch 28/80\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 566s 566ms/step - loss: 3.7533\n",
      "Epoch 29/80\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 565s 565ms/step - loss: 4.0588\n",
      "Epoch 30/80\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 565s 565ms/step - loss: 5.7362\n",
      "Epoch 31/80\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 568s 568ms/step - loss: 4.8354\n",
      "Epoch 32/80\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 564s 564ms/step - loss: 4.6027\n",
      "Epoch 33/80\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 565s 565ms/step - loss: 4.4871\n",
      "Epoch 34/80\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 566s 566ms/step - loss: 4.2494\n",
      "Epoch 35/80\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 567s 567ms/step - loss: 3.9999\n",
      "Epoch 36/80\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 567s 567ms/step - loss: 4.2109\n",
      "Epoch 37/80\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 569s 569ms/step - loss: 4.0252\n",
      "Epoch 38/80\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 567s 567ms/step - loss: 3.9202\n",
      "Epoch 39/80\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 567s 567ms/step - loss: 3.8632\n",
      "Epoch 40/80\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 569s 569ms/step - loss: 3.8893\n",
      "Epoch 41/80\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 566s 566ms/step - loss: 3.7982\n",
      "Epoch 42/80\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 570s 570ms/step - loss: 3.7409\n",
      "Epoch 43/80\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 566s 566ms/step - loss: 3.7118\n",
      "Epoch 44/80\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 564s 564ms/step - loss: 3.6978\n",
      "Epoch 45/80\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 567s 567ms/step - loss: 3.7007\n",
      "Epoch 46/80\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 567s 567ms/step - loss: 3.6509\n",
      "Epoch 47/80\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 564s 564ms/step - loss: 3.6282\n",
      "Epoch 48/80\n",
      "\n",
      "Epoch 00048: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 569s 569ms/step - loss: 3.6144\n",
      "Epoch 49/80\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 570s 570ms/step - loss: 3.5843\n",
      "Epoch 50/80\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 568s 568ms/step - loss: 3.5623\n",
      "Epoch 51/80\n",
      "\n",
      "Epoch 00051: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 569s 569ms/step - loss: 3.5708\n",
      "Epoch 52/80\n",
      "\n",
      "Epoch 00052: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 567s 567ms/step - loss: 3.5420\n",
      "Epoch 53/80\n",
      "\n",
      "Epoch 00053: LearningRateScheduler setting learning rate to 0.001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 569s 569ms/step - loss: 3.5440\n",
      "Epoch 54/80\n",
      "\n",
      "Epoch 00054: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 567s 567ms/step - loss: 3.5247\n",
      "Epoch 55/80\n",
      "\n",
      "Epoch 00055: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 563s 563ms/step - loss: 3.5045\n",
      "Epoch 56/80\n",
      "\n",
      "Epoch 00056: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 566s 566ms/step - loss: 3.4892\n",
      "Epoch 57/80\n",
      "\n",
      "Epoch 00057: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 566s 566ms/step - loss: 3.9126\n",
      "Epoch 58/80\n",
      "\n",
      "Epoch 00058: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 565s 565ms/step - loss: 3.5021\n",
      "Epoch 59/80\n",
      "\n",
      "Epoch 00059: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 568s 568ms/step - loss: 3.4650\n",
      "Epoch 60/80\n",
      "\n",
      "Epoch 00060: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 564s 564ms/step - loss: 3.5286\n",
      "Epoch 61/80\n",
      "\n",
      "Epoch 00061: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 565s 565ms/step - loss: 3.3878\n",
      "Epoch 62/80\n",
      "\n",
      "Epoch 00062: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 568s 568ms/step - loss: 3.3449\n",
      "Epoch 63/80\n",
      "\n",
      "Epoch 00063: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 565s 565ms/step - loss: 3.3348\n",
      "Epoch 64/80\n",
      "\n",
      "Epoch 00064: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 566s 566ms/step - loss: 3.3228\n",
      "Epoch 65/80\n",
      "\n",
      "Epoch 00065: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 563s 563ms/step - loss: 3.3028\n",
      "Epoch 66/80\n",
      "\n",
      "Epoch 00066: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 566s 566ms/step - loss: 3.3031\n",
      "Epoch 67/80\n",
      "\n",
      "Epoch 00067: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 565s 565ms/step - loss: 3.2924\n",
      "Epoch 68/80\n",
      "\n",
      "Epoch 00068: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 564s 564ms/step - loss: 3.2902\n",
      "Epoch 69/80\n",
      "\n",
      "Epoch 00069: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 566s 566ms/step - loss: 3.2757\n",
      "Epoch 70/80\n",
      "\n",
      "Epoch 00070: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 563s 563ms/step - loss: 3.2812\n",
      "Epoch 71/80\n",
      "\n",
      "Epoch 00071: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 566s 566ms/step - loss: 3.2756\n",
      "Epoch 72/80\n",
      "\n",
      "Epoch 00072: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 567s 567ms/step - loss: 3.2710\n",
      "Epoch 73/80\n",
      "\n",
      "Epoch 00073: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 565s 565ms/step - loss: 3.2815\n",
      "Epoch 74/80\n",
      "\n",
      "Epoch 00074: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 562s 562ms/step - loss: 3.2615\n",
      "Epoch 75/80\n",
      "\n",
      "Epoch 00075: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 565s 565ms/step - loss: 3.2728\n",
      "Epoch 76/80\n",
      "\n",
      "Epoch 00076: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 564s 564ms/step - loss: 3.2619\n",
      "Epoch 77/80\n",
      "\n",
      "Epoch 00077: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 565s 565ms/step - loss: 3.2702\n",
      "Epoch 78/80\n",
      "\n",
      "Epoch 00078: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 563s 563ms/step - loss: 3.2627\n",
      "Epoch 79/80\n",
      "\n",
      "Epoch 00079: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 569s 569ms/step - loss: 3.2757\n",
      "Epoch 80/80\n",
      "\n",
      "Epoch 00080: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 564s 564ms/step - loss: 3.2617\n",
      "TRAINING MODEL WITH FACTOR: 1.0\n",
      "Epoch 1/80\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 573s 573ms/step - loss: 7.2535\n",
      "Epoch 2/80\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 564s 564ms/step - loss: 4.8311\n",
      "Epoch 3/80\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 563s 563ms/step - loss: 4.6294\n",
      "Epoch 4/80\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 562s 562ms/step - loss: 4.5125\n",
      "Epoch 5/80\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 563s 563ms/step - loss: 4.3777\n",
      "Epoch 6/80\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 562s 562ms/step - loss: 4.3668\n",
      "Epoch 7/80\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 562s 562ms/step - loss: 4.2986\n",
      "Epoch 8/80\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 561s 561ms/step - loss: 5.7972\n",
      "Epoch 9/80\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 564s 564ms/step - loss: 4.8279\n",
      "Epoch 10/80\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 561s 561ms/step - loss: 4.6684\n",
      "Epoch 11/80\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 562s 562ms/step - loss: 4.3838\n",
      "Epoch 12/80\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 564s 564ms/step - loss: 4.7398\n",
      "Epoch 13/80\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 562s 562ms/step - loss: 4.3885\n",
      "Epoch 14/80\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 561s 561ms/step - loss: 4.3653\n",
      "Epoch 15/80\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 559s 559ms/step - loss: 4.2476\n",
      "Epoch 16/80\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 565s 565ms/step - loss: 4.2144\n",
      "Epoch 17/80\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 560s 560ms/step - loss: 4.2260\n",
      "Epoch 18/80\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 561s 561ms/step - loss: 4.5168\n",
      "Epoch 19/80\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 562s 562ms/step - loss: 4.1895\n",
      "Epoch 20/80\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 562s 562ms/step - loss: 4.1245\n",
      "Epoch 21/80\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 560s 560ms/step - loss: 4.1056\n",
      "Epoch 22/80\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 560s 560ms/step - loss: 4.0620\n",
      "Epoch 23/80\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 561s 561ms/step - loss: 4.0790\n",
      "Epoch 24/80\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 559s 559ms/step - loss: 4.0762\n",
      "Epoch 25/80\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 0.001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 564s 564ms/step - loss: 4.0232\n",
      "Epoch 26/80\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 560s 560ms/step - loss: 4.0178\n",
      "Epoch 27/80\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 562s 562ms/step - loss: 3.9650\n",
      "Epoch 28/80\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 560s 560ms/step - loss: 3.9498\n",
      "Epoch 29/80\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 562s 562ms/step - loss: 3.9963\n",
      "Epoch 30/80\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 562s 562ms/step - loss: 3.9185\n",
      "Epoch 31/80\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 565s 565ms/step - loss: 3.9125\n",
      "Epoch 32/80\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 562s 562ms/step - loss: 3.8816\n",
      "Epoch 33/80\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 561s 561ms/step - loss: 3.8930\n",
      "Epoch 34/80\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 563s 563ms/step - loss: 3.8534\n",
      "Epoch 35/80\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 565s 565ms/step - loss: 3.8426\n",
      "Epoch 36/80\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 564s 564ms/step - loss: 3.8184\n",
      "Epoch 37/80\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 560s 560ms/step - loss: 3.7952\n",
      "Epoch 38/80\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 562s 562ms/step - loss: 4.0534\n",
      "Epoch 39/80\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 561s 561ms/step - loss: 3.8121\n",
      "Epoch 40/80\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 560s 560ms/step - loss: 3.8003\n",
      "Epoch 41/80\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 561s 561ms/step - loss: 3.7731\n",
      "Epoch 42/80\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 567s 567ms/step - loss: 3.7809\n",
      "Epoch 43/80\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 559s 559ms/step - loss: 3.7405\n",
      "Epoch 44/80\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 563s 563ms/step - loss: 3.7682\n",
      "Epoch 45/80\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 562s 562ms/step - loss: 3.7331\n",
      "Epoch 46/80\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 566s 566ms/step - loss: 3.7196\n",
      "Epoch 47/80\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 562s 562ms/step - loss: 3.7059\n",
      "Epoch 48/80\n",
      "\n",
      "Epoch 00048: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 560s 560ms/step - loss: 3.6804\n",
      "Epoch 49/80\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 561s 561ms/step - loss: 3.6733\n",
      "Epoch 50/80\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 561s 561ms/step - loss: 3.6861\n",
      "Epoch 51/80\n",
      "\n",
      "Epoch 00051: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 563s 563ms/step - loss: 3.6565\n",
      "Epoch 52/80\n",
      "\n",
      "Epoch 00052: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 615s 615ms/step - loss: 3.7251\n",
      "Epoch 53/80\n",
      "\n",
      "Epoch 00053: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 633s 633ms/step - loss: 3.7072\n",
      "Epoch 54/80\n",
      "\n",
      "Epoch 00054: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 570s 570ms/step - loss: 3.6297\n",
      "Epoch 55/80\n",
      "\n",
      "Epoch 00055: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 572s 572ms/step - loss: 3.6316\n",
      "Epoch 56/80\n",
      "\n",
      "Epoch 00056: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 570s 570ms/step - loss: 3.6136\n",
      "Epoch 57/80\n",
      "\n",
      "Epoch 00057: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 574s 574ms/step - loss: 3.6138\n",
      "Epoch 58/80\n",
      "\n",
      "Epoch 00058: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 567s 567ms/step - loss: 3.6038\n",
      "Epoch 59/80\n",
      "\n",
      "Epoch 00059: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 566s 566ms/step - loss: 3.5880\n",
      "Epoch 60/80\n",
      "\n",
      "Epoch 00060: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 569s 569ms/step - loss: 3.5837\n",
      "Epoch 61/80\n",
      "\n",
      "Epoch 00061: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 568s 568ms/step - loss: 3.4917\n",
      "Epoch 62/80\n",
      "\n",
      "Epoch 00062: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 619s 619ms/step - loss: 3.4596\n",
      "Epoch 63/80\n",
      "\n",
      "Epoch 00063: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 567s 567ms/step - loss: 3.4598\n",
      "Epoch 64/80\n",
      "\n",
      "Epoch 00064: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 564s 564ms/step - loss: 3.4344\n",
      "Epoch 65/80\n",
      "\n",
      "Epoch 00065: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 566s 566ms/step - loss: 3.4357\n",
      "Epoch 66/80\n",
      "\n",
      "Epoch 00066: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 567s 567ms/step - loss: 3.4390\n",
      "Epoch 67/80\n",
      "\n",
      "Epoch 00067: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 566s 566ms/step - loss: 3.4294\n",
      "Epoch 68/80\n",
      "\n",
      "Epoch 00068: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 564s 564ms/step - loss: 3.4180\n",
      "Epoch 69/80\n",
      "\n",
      "Epoch 00069: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 565s 565ms/step - loss: 3.4208\n",
      "Epoch 70/80\n",
      "\n",
      "Epoch 00070: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 566s 566ms/step - loss: 3.4193\n",
      "Epoch 71/80\n",
      "\n",
      "Epoch 00071: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 561s 561ms/step - loss: 3.4113\n",
      "Epoch 72/80\n",
      "\n",
      "Epoch 00072: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 561s 561ms/step - loss: 3.4148\n",
      "Epoch 73/80\n",
      "\n",
      "Epoch 00073: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 559s 559ms/step - loss: 3.4052\n",
      "Epoch 74/80\n",
      "\n",
      "Epoch 00074: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 563s 563ms/step - loss: 3.3963\n",
      "Epoch 75/80\n",
      "\n",
      "Epoch 00075: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 561s 561ms/step - loss: 3.4005\n",
      "Epoch 76/80\n",
      "\n",
      "Epoch 00076: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 560s 560ms/step - loss: 3.3953\n",
      "Epoch 77/80\n",
      "\n",
      "Epoch 00077: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 622s 622ms/step - loss: 3.4019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/80\n",
      "\n",
      "Epoch 00078: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 626s 626ms/step - loss: 3.4098\n",
      "Epoch 79/80\n",
      "\n",
      "Epoch 00079: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 568s 568ms/step - loss: 3.4002\n",
      "Epoch 80/80\n",
      "\n",
      "Epoch 00080: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 563s 563ms/step - loss: 3.3959\n",
      "TRAINING MODEL WITH FACTOR: 0.5\n",
      "Epoch 1/80\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 570s 570ms/step - loss: 6.5526\n",
      "Epoch 2/80\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 562s 562ms/step - loss: 4.8939\n",
      "Epoch 3/80\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 561s 561ms/step - loss: 4.6782\n",
      "Epoch 4/80\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 563s 563ms/step - loss: 4.6344\n",
      "Epoch 5/80\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 561s 561ms/step - loss: 4.4824\n",
      "Epoch 6/80\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 565s 565ms/step - loss: 4.4178\n",
      "Epoch 7/80\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 564s 564ms/step - loss: 4.3726\n",
      "Epoch 8/80\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 564s 564ms/step - loss: 4.3413\n",
      "Epoch 9/80\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 592s 592ms/step - loss: 4.3179\n",
      "Epoch 10/80\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 558s 558ms/step - loss: 4.2438\n",
      "Epoch 11/80\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 558s 558ms/step - loss: 4.2313\n",
      "Epoch 12/80\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 559s 559ms/step - loss: 4.2040\n",
      "Epoch 13/80\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 559s 559ms/step - loss: 4.1804\n",
      "Epoch 14/80\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 563s 563ms/step - loss: 4.2940\n",
      "Epoch 15/80\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 557s 557ms/step - loss: 4.1453\n",
      "Epoch 16/80\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 561s 561ms/step - loss: 4.0993\n",
      "Epoch 17/80\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 560s 560ms/step - loss: 4.0995\n",
      "Epoch 18/80\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 560s 560ms/step - loss: 4.0671\n",
      "Epoch 19/80\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 564s 564ms/step - loss: 4.0608\n",
      "Epoch 20/80\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 557s 557ms/step - loss: 4.0409\n",
      "Epoch 21/80\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 558s 558ms/step - loss: 4.1603\n",
      "Epoch 22/80\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 560s 560ms/step - loss: 4.0386\n",
      "Epoch 23/80\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 557s 557ms/step - loss: 4.0065\n",
      "Epoch 24/80\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 559s 559ms/step - loss: 3.9914\n",
      "Epoch 25/80\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 560s 560ms/step - loss: 3.9657\n",
      "Epoch 26/80\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 560s 560ms/step - loss: 4.0034\n",
      "Epoch 27/80\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 556s 556ms/step - loss: 3.9397\n",
      "Epoch 28/80\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 559s 559ms/step - loss: 3.9476\n",
      "Epoch 29/80\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 561s 561ms/step - loss: 4.0308\n",
      "Epoch 30/80\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 560s 560ms/step - loss: 3.9214\n",
      "Epoch 31/80\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 561s 561ms/step - loss: 3.9263\n",
      "Epoch 32/80\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 561s 561ms/step - loss: 3.9098\n",
      "Epoch 33/80\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 559s 559ms/step - loss: 3.8877\n",
      "Epoch 34/80\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 561s 561ms/step - loss: 3.8968\n",
      "Epoch 35/80\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 557s 557ms/step - loss: 3.8932\n",
      "Epoch 36/80\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 561s 561ms/step - loss: 3.8491\n",
      "Epoch 37/80\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 561s 561ms/step - loss: 3.8512\n",
      "Epoch 38/80\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 559s 559ms/step - loss: 3.8380\n",
      "Epoch 39/80\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 560s 560ms/step - loss: 3.8271\n",
      "Epoch 40/80\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 558s 558ms/step - loss: 3.8252\n",
      "Epoch 41/80\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 562s 562ms/step - loss: 3.8372\n",
      "Epoch 42/80\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 562s 562ms/step - loss: 3.8026\n",
      "Epoch 43/80\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 561s 561ms/step - loss: 3.7952\n",
      "Epoch 44/80\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 560s 560ms/step - loss: 3.7928\n",
      "Epoch 45/80\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 561s 561ms/step - loss: 3.8244\n",
      "Epoch 46/80\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 558s 558ms/step - loss: 3.7870\n",
      "Epoch 47/80\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 561s 561ms/step - loss: 3.7742\n",
      "Epoch 48/80\n",
      "\n",
      "Epoch 00048: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 560s 560ms/step - loss: 3.7444\n",
      "Epoch 49/80\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 560s 560ms/step - loss: 3.7486\n",
      "Epoch 50/80\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 0.001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 557s 557ms/step - loss: 4.0065\n",
      "Epoch 51/80\n",
      "\n",
      "Epoch 00051: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 558s 558ms/step - loss: 4.1612\n",
      "Epoch 52/80\n",
      "\n",
      "Epoch 00052: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 557s 557ms/step - loss: 3.9884\n",
      "Epoch 53/80\n",
      "\n",
      "Epoch 00053: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 557s 557ms/step - loss: 3.8877\n",
      "Epoch 54/80\n",
      "\n",
      "Epoch 00054: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 557s 557ms/step - loss: 3.8104\n",
      "Epoch 55/80\n",
      "\n",
      "Epoch 00055: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 558s 558ms/step - loss: 3.7651\n",
      "Epoch 56/80\n",
      "\n",
      "Epoch 00056: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 560s 560ms/step - loss: 3.7391\n",
      "Epoch 57/80\n",
      "\n",
      "Epoch 00057: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 560s 560ms/step - loss: 3.7283\n",
      "Epoch 58/80\n",
      "\n",
      "Epoch 00058: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 561s 561ms/step - loss: 3.8099\n",
      "Epoch 59/80\n",
      "\n",
      "Epoch 00059: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 558s 558ms/step - loss: 3.8433\n",
      "Epoch 60/80\n",
      "\n",
      "Epoch 00060: LearningRateScheduler setting learning rate to 0.001.\n",
      "1000/1000 [==============================] - 559s 559ms/step - loss: 3.7462\n",
      "Epoch 61/80\n",
      "\n",
      "Epoch 00061: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 560s 560ms/step - loss: 3.6741\n",
      "Epoch 62/80\n",
      "\n",
      "Epoch 00062: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 558s 558ms/step - loss: 3.6383\n",
      "Epoch 63/80\n",
      "\n",
      "Epoch 00063: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 560s 560ms/step - loss: 3.6210\n",
      "Epoch 64/80\n",
      "\n",
      "Epoch 00064: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 557s 557ms/step - loss: 3.6130\n",
      "Epoch 65/80\n",
      "\n",
      "Epoch 00065: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 560s 560ms/step - loss: 3.6084\n",
      "Epoch 66/80\n",
      "\n",
      "Epoch 00066: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 560s 560ms/step - loss: 3.5962\n",
      "Epoch 67/80\n",
      "\n",
      "Epoch 00067: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 556s 556ms/step - loss: 3.5954\n",
      "Epoch 68/80\n",
      "\n",
      "Epoch 00068: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 558s 558ms/step - loss: 3.5896\n",
      "Epoch 69/80\n",
      "\n",
      "Epoch 00069: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 557s 557ms/step - loss: 3.5798\n",
      "Epoch 70/80\n",
      "\n",
      "Epoch 00070: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 558s 558ms/step - loss: 3.5753\n",
      "Epoch 71/80\n",
      "\n",
      "Epoch 00071: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 559s 559ms/step - loss: 3.5724\n",
      "Epoch 72/80\n",
      "\n",
      "Epoch 00072: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 557s 557ms/step - loss: 3.5748\n",
      "Epoch 73/80\n",
      "\n",
      "Epoch 00073: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 560s 560ms/step - loss: 3.5669\n",
      "Epoch 74/80\n",
      "\n",
      "Epoch 00074: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 561s 561ms/step - loss: 3.5801\n",
      "Epoch 75/80\n",
      "\n",
      "Epoch 00075: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 557s 557ms/step - loss: 3.5839\n",
      "Epoch 76/80\n",
      "\n",
      "Epoch 00076: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 558s 558ms/step - loss: 3.5677\n",
      "Epoch 77/80\n",
      "\n",
      "Epoch 00077: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 559s 559ms/step - loss: 3.5891\n",
      "Epoch 78/80\n",
      "\n",
      "Epoch 00078: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 558s 558ms/step - loss: 3.5747\n",
      "Epoch 79/80\n",
      "\n",
      "Epoch 00079: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 558s 558ms/step - loss: 3.5766\n",
      "Epoch 80/80\n",
      "\n",
      "Epoch 00080: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 560s 560ms/step - loss: 3.5702\n"
     ]
    }
   ],
   "source": [
    "scale_factors = [1.5, 1.0, 0.5]\n",
    "\n",
    "for factor in scale_factors:\n",
    "    # 1: Build the Keras model.\n",
    "    K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "    print('TRAINING MODEL WITH FACTOR:', factor)\n",
    "    \n",
    "    model = ssd_300(image_size=(img_height, img_width, img_channels),\n",
    "                n_classes=n_classes,\n",
    "                mode='training',\n",
    "                scale_factor=factor,\n",
    "                scales=scales,\n",
    "                aspect_ratios_per_layer=aspect_ratios,\n",
    "                two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                steps=steps,\n",
    "                offsets=offsets,\n",
    "                clip_boxes=clip_boxes,\n",
    "                variances=variances,\n",
    "                normalize_coords=normalize_coords,\n",
    "                subtract_mean=mean_color,\n",
    "                divide_by_stddev=divide_by_stddev,\n",
    "                swap_channels=swap_channels)\n",
    "\n",
    "    adam = Adam(lr=0.001)\n",
    "    ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "    model.compile(optimizer=adam, loss=ssd_loss.compute_loss)\n",
    "    \n",
    "    # Define model callbacks.\n",
    "    main_path = '/home/aldo/Documents/'\n",
    "    # TODO: Set the filepath under which you want to save the model.\n",
    "\n",
    "    csv_logger = CSVLogger(filename=main_path + 'data-cic/history/light_models/PASCAL/shufflenet_v1_factor_' + \n",
    "                           str(factor) + '.csv',\n",
    "                           separator=',',\n",
    "                           append=True)\n",
    "\n",
    "    learning_rate_scheduler = LearningRateScheduler(schedule=lr_schedule, verbose=1)\n",
    "\n",
    "\n",
    "    callbacks = [csv_logger,\n",
    "                 learning_rate_scheduler]\n",
    "    \n",
    "    initial_epoch   = 0\n",
    "    final_epoch     = 80\n",
    "    steps_per_epoch = 1000\n",
    "\n",
    "    history = model.fit_generator(generator=train_generator,\n",
    "                                  steps_per_epoch=steps_per_epoch,\n",
    "                                  epochs=final_epoch,\n",
    "                                  callbacks=callbacks,\n",
    "                                  initial_epoch=initial_epoch)\n",
    "    \n",
    "    model.save(main_path + 'weights/light_models/PASCAL/shufflenet_v1_factor_' + str(factor) + '.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test2]",
   "language": "python",
   "name": "conda-env-test2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
