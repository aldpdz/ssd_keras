{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "sys.path.append(os.path.abspath('../../'))\n",
    "sys.path.append(os.path.abspath('../../extra_files'))\n",
    "import helper as hp\n",
    "from imageio import imwrite, imread\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "data_path = '/home/aldo/Documents/data-cic/'\n",
    "preprocess_path = data_path + 'preprocess_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training SSD300 trained with mobilenet backbone trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TerminateOnNaN, CSVLogger, EarlyStopping, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from light_models.keras_ssd300_mobilenetv2 import ssd_300\n",
    "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
    "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
    "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
    "from keras_layers.keras_layer_L2Normalization import L2Normalization\n",
    "\n",
    "from ssd_encoder_decoder.ssd_input_encoder import SSDInputEncoder\n",
    "from ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast\n",
    "\n",
    "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
    "from data_generator.object_detection_2d_geometric_ops import Resize\n",
    "from data_generator.object_detection_2d_photometric_ops import ConvertTo3Channels\n",
    "from data_generator.data_augmentation_chain_original_ssd import SSDDataAugmentation\n",
    "from data_generator.object_detection_2d_misc_utils import apply_inverse_transforms\n",
    "\n",
    "from extra_files.f1_callback import F1_callback as f1_call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters (original SSD300 architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameteres needed for ssd_300() and SSDInputEncoder()\n",
    "\n",
    "img_height = 300 # Height of the model input images\n",
    "img_width = 300 # Width of the model input images\n",
    "img_channels = 3 # Number of color channels of the model input images\n",
    "mean_color = [1., 1., 1.] # The per-channel mean of the images in the dataset. Do not change this value if you're using any of the pre-trained weights.\n",
    "divide_by_stddev = [127.5, 127.5, 127.5]\n",
    "swap_channels = False # The color channel order in the original SSD is BGR, so we'll have the model reverse the color channel order of the input images.\n",
    "n_classes = 1 # Number of positive classes, e.g. 20 for Pascal VOC, 80 for MS COCO\n",
    "scales_pascal = [0.1, 0.2, 0.37, 0.54, 0.71, 0.88, 1.05] # The anchor box scaling factors used in the original SSD300 for the Pascal VOC datasets\n",
    "scales = scales_pascal\n",
    "#scales = [0.07, 0.15, 0.33, 0.51, 0.69, 0.87, 1.05]\n",
    "aspect_ratios = [[1.0, 2.0, 0.5],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                 [1.0, 2.0, 0.5],\n",
    "                 [1.0, 2.0, 0.5]] # The anchor box aspect ratios used in the original SSD300; the order matters\n",
    "two_boxes_for_ar1 = True\n",
    "steps = [16, 30, 60, 100, 150, 300] # The space between two adjacent anchor box center points for each predictor layer.\n",
    "offsets = [0.5, 0.5, 0.5, 0.5, 0.5, 0.5] # The offsets of the first anchor box center points from the top and left borders of the image as a fraction of the step size for each predictor layer.\n",
    "clip_boxes = False # Whether or not to clip the anchor boxes to lie entirely within the image boundaries\n",
    "variances = [0.1, 0.1, 0.2, 0.2] # The variances by which the encoded target coordinates are divided as in the original implementation\n",
    "normalize_coords = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new model with SSD weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Build the Keras model.\n",
    "\n",
    "K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "model = ssd_300(image_size=(img_height, img_width, img_channels),\n",
    "                n_classes=n_classes,\n",
    "                mode='training',\n",
    "                alpha=1.0,\n",
    "                scales=scales,\n",
    "                aspect_ratios_per_layer=aspect_ratios,\n",
    "                two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                steps=steps,\n",
    "                offsets=offsets,\n",
    "                clip_boxes=clip_boxes,\n",
    "                variances=variances,\n",
    "                normalize_coords=normalize_coords,\n",
    "                subtract_mean=mean_color,\n",
    "                divide_by_stddev=divide_by_stddev,\n",
    "                swap_channels=swap_channels)\n",
    "\n",
    "# 2: Load some weights into the model.\n",
    "\n",
    "# TODO: Set the path to the weights you want to load.\n",
    "\n",
    "# 3: Instantiate an optimizer and the SSD loss function and compile the model.\n",
    "#    If you want to follow the original Caffe implementation, use the preset SGD\n",
    "#    optimizer, otherwise I'd recommend the commented-out Adam optimizer.\n",
    "\n",
    "adam = Adam(lr=0.001)\n",
    "#sgd = SGD(lr=0.001, momentum=0.9, decay=0.0, nesterov=False)\n",
    "\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "model.compile(optimizer=adam, loss=ssd_loss.compute_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 300, 300, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "identity_layer (Lambda)         (None, 300, 300, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_stddev_normalization (Lam (None, 300, 300, 3)  0           identity_layer[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "input_mean_normalization (Lambd (None, 300, 300, 3)  0           input_stddev_normalization[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 multiple             558656      input_mean_normalization[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "mobl13_conv_expand (Conv2D)     (None, 18, 18, 576)  55296       model_1[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn13_conv_bn_expand (BatchNorma (None, 18, 18, 576)  2304        mobl13_conv_expand[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv_13_relu (Activation)       (None, 18, 18, 576)  0           bn13_conv_bn_expand[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "mobl13_conv_depthwise (Depthwis (None, 18, 18, 576)  5184        conv_13_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn13_conv_depthwise (BatchNorma (None, 18, 18, 576)  2304        mobl13_conv_depthwise[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_13_relu (Activation)    (None, 18, 18, 576)  0           bn13_conv_depthwise[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "mobl13_conv_project (Conv2D)    (None, 18, 18, 160)  92160       conv_dw_13_relu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn13_conv_bn_project (BatchNorm (None, 18, 18, 160)  640         mobl13_conv_project[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "mobl14_conv_expand (Conv2D)     (None, 18, 18, 960)  153600      bn13_conv_bn_project[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn14_conv_bn_expand (BatchNorma (None, 18, 18, 960)  3840        mobl14_conv_expand[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv_14_relu (Activation)       (None, 18, 18, 960)  0           bn14_conv_bn_expand[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "mobl14_conv_depthwise (Depthwis (None, 18, 18, 960)  8640        conv_14_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn14_conv_depthwise (BatchNorma (None, 18, 18, 960)  3840        mobl14_conv_depthwise[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_14_relu (Activation)    (None, 18, 18, 960)  0           bn14_conv_depthwise[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "mobl14_conv_project (Conv2D)    (None, 18, 18, 160)  153600      conv_dw_14_relu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn14_conv_bn_project (BatchNorm (None, 18, 18, 160)  640         mobl14_conv_project[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res_connect_14 (Add)            (None, 18, 18, 160)  0           bn13_conv_bn_project[0][0]       \n",
      "                                                                 bn14_conv_bn_project[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "mobl15_conv_expand (Conv2D)     (None, 18, 18, 960)  153600      res_connect_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn15_conv_bn_expand (BatchNorma (None, 18, 18, 960)  3840        mobl15_conv_expand[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv_15_relu (Activation)       (None, 18, 18, 960)  0           bn15_conv_bn_expand[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "mobl15_conv_depthwise (Depthwis (None, 18, 18, 960)  8640        conv_15_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn15_conv_depthwise (BatchNorma (None, 18, 18, 960)  3840        mobl15_conv_depthwise[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_15_relu (Activation)    (None, 18, 18, 960)  0           bn15_conv_depthwise[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "mobl15_conv_project (Conv2D)    (None, 18, 18, 160)  153600      conv_dw_15_relu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn15_conv_bn_project (BatchNorm (None, 18, 18, 160)  640         mobl15_conv_project[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res_connect_15 (Add)            (None, 18, 18, 160)  0           res_connect_14[0][0]             \n",
      "                                                                 bn15_conv_bn_project[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "mobl16_conv_expand (Conv2D)     (None, 18, 18, 960)  153600      res_connect_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn16_conv_bn_expand (BatchNorma (None, 18, 18, 960)  3840        mobl16_conv_expand[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv_16_relu (Activation)       (None, 18, 18, 960)  0           bn16_conv_bn_expand[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "mobl16_conv_depthwise (Depthwis (None, 18, 18, 960)  8640        conv_16_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn16_conv_depthwise (BatchNorma (None, 18, 18, 960)  3840        mobl16_conv_depthwise[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_16_relu (Activation)    (None, 18, 18, 960)  0           bn16_conv_depthwise[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "mobl16_conv_project (Conv2D)    (None, 18, 18, 320)  307200      conv_dw_16_relu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn16_conv_bn_project (BatchNorm (None, 18, 18, 320)  1280        mobl16_conv_project[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1 (Conv2D)                 (None, 9, 9, 1280)   409600      bn16_conv_bn_project[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1_bn (BatchNormalization)  (None, 9, 9, 1280)   5120        Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1_relu (Activation)        (None, 9, 9, 1280)   0           Conv_1_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_18_1 (ZeroPadding2D)   (None, 11, 11, 1280) 0           Conv_1_relu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv__18_1 (Conv2D)             (None, 11, 11, 256)  327680      conv_pad_18_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_18_bn_1 (BatchNormalizatio (None, 11, 11, 256)  1024        conv__18_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_18_relu_1 (Activation)     (None, 11, 11, 256)  0           conv_18_bn_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv__18_2 (Conv2D)             (None, 5, 5, 512)    1179648     conv_18_relu_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_18_bn_2 (BatchNormalizatio (None, 5, 5, 512)    2048        conv__18_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_18_relu_2 (Activation)     (None, 5, 5, 512)    0           conv_18_bn_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_19_1 (ZeroPadding2D)   (None, 7, 7, 512)    0           conv_18_relu_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv__19_1 (Conv2D)             (None, 7, 7, 128)    65536       conv_pad_19_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_19_bn_1 (BatchNormalizatio (None, 7, 7, 128)    512         conv__19_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_19_relu_1 (Activation)     (None, 7, 7, 128)    0           conv_19_bn_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv__19_2 (Conv2D)             (None, 3, 3, 256)    294912      conv_19_relu_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_19_bn_2 (BatchNormalizatio (None, 3, 3, 256)    1024        conv__19_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_19_relu_2 (Activation)     (None, 3, 3, 256)    0           conv_19_bn_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_20_1 (ZeroPadding2D)   (None, 5, 5, 256)    0           conv_19_relu_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv__20_1 (Conv2D)             (None, 5, 5, 128)    32768       conv_pad_20_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_20_bn_1 (BatchNormalizatio (None, 5, 5, 128)    512         conv__20_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_20_relu_1 (Activation)     (None, 5, 5, 128)    0           conv_20_bn_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv__20_2 (Conv2D)             (None, 2, 2, 256)    294912      conv_20_relu_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_20_bn_2 (BatchNormalizatio (None, 2, 2, 256)    1024        conv__20_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_20_relu_2 (Activation)     (None, 2, 2, 256)    0           conv_20_bn_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_21_1 (ZeroPadding2D)   (None, 4, 4, 256)    0           conv_20_relu_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv__21_1 (Conv2D)             (None, 4, 4, 64)     16384       conv_pad_21_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_21_bn_1 (BatchNormalizatio (None, 4, 4, 64)     256         conv__21_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_21_relu_1 (Activation)     (None, 4, 4, 64)     0           conv_21_bn_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv__21_2 (Conv2D)             (None, 1, 1, 128)    73728       conv_21_relu_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv13_mbox_conf (Conv2D)       (None, 18, 18, 8)    41480       mobl13_conv_expand[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv17_mbox_conf (Conv2D)       (None, 9, 9, 12)     138252      Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv18_2_mbox_conf (Conv2D)     (None, 5, 5, 12)     55308       conv__18_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv19_2_mbox_conf (Conv2D)     (None, 3, 3, 12)     27660       conv__19_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv20_2_mbox_conf (Conv2D)     (None, 2, 2, 8)      18440       conv__20_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv21_2_mbox_conf (Conv2D)     (None, 1, 1, 8)      9224        conv__21_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv13_mbox_loc (Conv2D)        (None, 18, 18, 16)   82960       mobl13_conv_expand[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv17_mbox_loc (Conv2D)        (None, 9, 9, 24)     276504      Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv18_2_mbox_loc (Conv2D)      (None, 5, 5, 24)     110616      conv__18_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv19_2_mbox_loc (Conv2D)      (None, 3, 3, 24)     55320       conv__19_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv20_2_mbox_loc (Conv2D)      (None, 2, 2, 16)     36880       conv__20_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv21_2_mbox_loc (Conv2D)      (None, 1, 1, 16)     18448       conv__21_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv11_mbox_conf_reshape (Resha (None, 1296, 2)      0           conv13_mbox_conf[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv13_mbox_conf_reshape (Resha (None, 486, 2)       0           conv17_mbox_conf[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv14_2_mbox_conf_reshape (Res (None, 150, 2)       0           conv18_2_mbox_conf[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv15_2_mbox_conf_reshape (Res (None, 54, 2)        0           conv19_2_mbox_conf[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv16_2_mbox_conf_reshape (Res (None, 16, 2)        0           conv20_2_mbox_conf[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv17_2_mbox_conf_reshape (Res (None, 4, 2)         0           conv21_2_mbox_conf[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv13_mbox_priorbox (AnchorBox (None, 18, 18, 4, 8) 0           conv13_mbox_loc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv17_mbox_priorbox (AnchorBox (None, 9, 9, 6, 8)   0           conv17_mbox_loc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv18_2_mbox_priorbox (AnchorB (None, 5, 5, 6, 8)   0           conv18_2_mbox_loc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv19_2_mbox_priorbox (AnchorB (None, 3, 3, 6, 8)   0           conv19_2_mbox_loc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv20_2_mbox_priorbox (AnchorB (None, 2, 2, 4, 8)   0           conv20_2_mbox_loc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv21_2_mbox_priorbox (AnchorB (None, 1, 1, 4, 8)   0           conv21_2_mbox_loc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "mbox_conf (Concatenate)         (None, 2006, 2)      0           conv11_mbox_conf_reshape[0][0]   \n",
      "                                                                 conv13_mbox_conf_reshape[0][0]   \n",
      "                                                                 conv14_2_mbox_conf_reshape[0][0] \n",
      "                                                                 conv15_2_mbox_conf_reshape[0][0] \n",
      "                                                                 conv16_2_mbox_conf_reshape[0][0] \n",
      "                                                                 conv17_2_mbox_conf_reshape[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv11_mbox_loc_reshape (Reshap (None, 1296, 4)      0           conv13_mbox_loc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv13_mbox_loc_reshape (Reshap (None, 486, 4)       0           conv17_mbox_loc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv14_2_mbox_loc_reshape (Resh (None, 150, 4)       0           conv18_2_mbox_loc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv15_2_mbox_loc_reshape (Resh (None, 54, 4)        0           conv19_2_mbox_loc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv16_2_mbox_loc_reshape (Resh (None, 16, 4)        0           conv20_2_mbox_loc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv17_2_mbox_loc_reshape (Resh (None, 4, 4)         0           conv21_2_mbox_loc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv13_mbox_priorbox_reshape (R (None, 1296, 8)      0           conv13_mbox_priorbox[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv17_mbox_priorbox_reshape (R (None, 486, 8)       0           conv17_mbox_priorbox[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv18_2_mbox_priorbox_reshape  (None, 150, 8)       0           conv18_2_mbox_priorbox[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv19_2_mbox_priorbox_reshape  (None, 54, 8)        0           conv19_2_mbox_priorbox[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv20_2_mbox_priorbox_reshape  (None, 16, 8)        0           conv20_2_mbox_priorbox[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv21_2_mbox_priorbox_reshape  (None, 4, 8)         0           conv21_2_mbox_priorbox[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mbox_conf_softmax (Activation)  (None, 2006, 2)      0           mbox_conf[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "mbox_loc (Concatenate)          (None, 2006, 4)      0           conv11_mbox_loc_reshape[0][0]    \n",
      "                                                                 conv13_mbox_loc_reshape[0][0]    \n",
      "                                                                 conv14_2_mbox_loc_reshape[0][0]  \n",
      "                                                                 conv15_2_mbox_loc_reshape[0][0]  \n",
      "                                                                 conv16_2_mbox_loc_reshape[0][0]  \n",
      "                                                                 conv17_2_mbox_loc_reshape[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mbox_priorbox (Concatenate)     (None, 2006, 8)      0           conv13_mbox_priorbox_reshape[0][0\n",
      "                                                                 conv17_mbox_priorbox_reshape[0][0\n",
      "                                                                 conv18_2_mbox_priorbox_reshape[0]\n",
      "                                                                 conv19_2_mbox_priorbox_reshape[0]\n",
      "                                                                 conv20_2_mbox_priorbox_reshape[0]\n",
      "                                                                 conv21_2_mbox_priorbox_reshape[0]\n",
      "__________________________________________________________________________________________________\n",
      "predictions (Concatenate)       (None, 2006, 14)     0           mbox_conf_softmax[0][0]          \n",
      "                                                                 mbox_loc[0][0]                   \n",
      "                                                                 mbox_priorbox[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 5,421,044\n",
      "Trainable params: 5,383,732\n",
      "Non-trainable params: 37,312\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generator for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images into memory: 100%|██████████| 6469/6469 [00:27<00:00, 232.21it/s]\n",
      "Loading images into memory: 100%|██████████| 1025/1025 [00:04<00:00, 247.81it/s]\n",
      "Number of images in the training dataset:\t  6469\n",
      "Number of images in the validation dataset:\t  1025\n"
     ]
    }
   ],
   "source": [
    "# 1: Instantiate two `DataGenerator` objects: One for training, one for validation.\n",
    "\n",
    "# Optional: If you have enough memory, consider loading the images into memory for the reasons explained above.\n",
    "\n",
    "train_dataset = DataGenerator(load_images_into_memory=True, hdf5_dataset_path=None)\n",
    "val_dataset = DataGenerator(load_images_into_memory=True, hdf5_dataset_path=None)\n",
    "\n",
    "# 2: Parse the image and label lists for the training and validation datasets.\n",
    "\n",
    "# TODO: Set the paths to your dataset here.\n",
    "\n",
    "# Images\n",
    "images_dir = data_path + 'PASCAL'\n",
    "#images_dir = data_path + 'COCO'\n",
    "\n",
    "# Ground truth\n",
    "#train_labels_filename = preprocess_path + '/PASCAL_train.csv'\n",
    "train_labels_filename = preprocess_path + '/PASCAL_train_val.csv'\n",
    "val_labels_filename   = preprocess_path + '/PASCAL_val.csv'\n",
    "\n",
    "train_dataset.parse_csv(images_dir=images_dir,\n",
    "                        labels_filename=train_labels_filename,\n",
    "                        input_format=['image_name', 'xmin', 'xmax', 'ymin', 'ymax', 'class_id'], # This is the order of the first six columns in the CSV file that contains the labels for your dataset. If your labels are in XML format, maybe the XML parser will be helpful, check the documentation.\n",
    "                        include_classes='all')\n",
    "\n",
    "val_dataset.parse_csv(#images_dir=images_dir,\n",
    "                      data_path + 'PASCAL',\n",
    "                      labels_filename=val_labels_filename,\n",
    "                      input_format=['image_name', 'xmin', 'xmax', 'ymin', 'ymax', 'class_id'],\n",
    "                      include_classes='all')\n",
    "\n",
    "# Get the number of samples in the training and validations datasets.\n",
    "train_dataset_size = train_dataset.get_dataset_size()\n",
    "val_dataset_size   = val_dataset.get_dataset_size()\n",
    "\n",
    "print(\"Number of images in the training dataset:\\t{:>6}\".format(train_dataset_size))\n",
    "print(\"Number of images in the validation dataset:\\t{:>6}\".format(val_dataset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the training dataset:\t  6469\n",
      "Number of images in the validation dataset:\t  1025\n"
     ]
    }
   ],
   "source": [
    "# 3: Set the batch size.\n",
    "batch_size = 32 # Change the batch size if you like, or if you run into GPU memory issues.\n",
    "\n",
    "# 4: Set the image transformations for pre-processing and data augmentation options.\n",
    "# For the training generator:\n",
    "ssd_data_augmentation = SSDDataAugmentation(img_height=img_height,\n",
    "                                            img_width=img_width,\n",
    "                                            background=mean_color)\n",
    "\n",
    "# For the validation generator:\n",
    "convert_to_3_channels = ConvertTo3Channels()\n",
    "resize = Resize(height=img_height, width=img_width)\n",
    "\n",
    "# 5: Instantiate an encoder that can encode ground truth labels into the format needed by the SSD loss function.\n",
    "# The encoder constructor needs the spatial dimensions of the model's predictor layers to create the anchor boxes.\n",
    "predictor_sizes = [model.get_layer('conv13_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv17_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv18_2_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv19_2_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv20_2_mbox_conf').output_shape[1:3],\n",
    "                   model.get_layer('conv21_2_mbox_conf').output_shape[1:3]]\n",
    "\n",
    "ssd_input_encoder = SSDInputEncoder(img_height=img_height,\n",
    "                                    img_width=img_width,\n",
    "                                    n_classes=n_classes,\n",
    "                                    predictor_sizes=predictor_sizes,\n",
    "                                    scales=scales,\n",
    "                                    aspect_ratios_per_layer=aspect_ratios,\n",
    "                                    two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                                    steps=steps,\n",
    "                                    offsets=offsets,\n",
    "                                    clip_boxes=clip_boxes,\n",
    "                                    variances=variances,\n",
    "                                    matching_type='multi',\n",
    "                                    pos_iou_threshold=0.5,\n",
    "                                    neg_iou_limit=0.5,\n",
    "                                    normalize_coords=normalize_coords)\n",
    "\n",
    "# 6: Create the generator handles that will be passed to Keras' `fit_generator()` function.\n",
    "train_generator = train_dataset.generate(batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         transformations=[ssd_data_augmentation],\n",
    "                                         label_encoder=ssd_input_encoder,\n",
    "                                         returns={'processed_images',\n",
    "                                                  'encoded_labels'},\n",
    "                                         keep_images_without_gt=False)\n",
    "\n",
    "val_generator = val_dataset.generate(batch_size=batch_size,\n",
    "                                     shuffle=False,\n",
    "                                     transformations=[convert_to_3_channels,\n",
    "                                                      resize],\n",
    "                                     label_encoder=ssd_input_encoder,\n",
    "                                     returns={'processed_images',\n",
    "                                              'encoded_labels'},\n",
    "                                     keep_images_without_gt=False)\n",
    "\n",
    "# Get the number of samples in the training and validations datasets.\n",
    "train_dataset_size = train_dataset.get_dataset_size()\n",
    "val_dataset_size   = val_dataset.get_dataset_size()\n",
    "\n",
    "print(\"Number of images in the training dataset:\\t{:>6}\".format(train_dataset_size))\n",
    "print(\"Number of images in the validation dataset:\\t{:>6}\".format(val_dataset_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remaining training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a learning rate schedule.\n",
    "def lr_schedule(epoch):\n",
    "    if epoch < 60:\n",
    "        return 0.0001\n",
    "    elif epoch < 70:\n",
    "        return 0.00001\n",
    "    else:\n",
    "        return 0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING MODEL WITH LEARNING RATE: 0.01\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 120s 599ms/step - loss: 121.0878 - val_loss: 147.1752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aldo/Documents/ssd/bounding_box_utils/bounding_box_utils.py:383: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return intersection_areas / union_areas\n",
      "/home/aldo/Documents/ssd/ssd_encoder_decoder/ssd_output_decoder.py:91: RuntimeWarning: invalid value encountered in less_equal\n",
      "  boxes_left = boxes_left[similarities <= iou_threshold] # ...so that we can remove the ones that overlap too much with the maximum box\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 1025\n",
      "Presicion: 0.014\n",
      "Recall: 0.2036\n",
      "F1 score: 0.0261\n",
      "F1 score: 0.026141397828356353\n",
      "Improve F1 score from -inf to 0.026141397828356353\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 108s 540ms/step - loss: 106.5339 - val_loss: 104.7687\n",
      "Number of images: 1025\n",
      "Presicion: 0.0167\n",
      "Recall: 0.1795\n",
      "F1 score: 0.0305\n",
      "F1 score: 0.030530054100235793\n",
      "Improve F1 score from 0.026141397828356353 to 0.030530054100235793\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 109s 545ms/step - loss: 107.0733 - val_loss: 106.8845\n",
      "Number of images: 1025\n",
      "Presicion: 0.0466\n",
      "Recall: 0.3763\n",
      "F1 score: 0.0829\n",
      "F1 score: 0.082854360386477\n",
      "Improve F1 score from 0.030530054100235793 to 0.082854360386477\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 110s 550ms/step - loss: 106.4365 - val_loss: 105.2696\n",
      "Number of images: 1025\n",
      "Presicion: 0.0512\n",
      "Recall: 0.3688\n",
      "F1 score: 0.0899\n",
      "F1 score: 0.08993633157572349\n",
      "Improve F1 score from 0.082854360386477 to 0.08993633157572349\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 114s 572ms/step - loss: 106.5339 - val_loss: 88.6387\n",
      "Number of images: 1025\n",
      "Presicion: 0.0403\n",
      "Recall: 0.3672\n",
      "F1 score: 0.0726\n",
      "F1 score: 0.0726354729050802\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 109s 545ms/step - loss: 106.3970 - val_loss: 57.3507\n",
      "Number of images: 1025\n",
      "Presicion: 0.0399\n",
      "Recall: 0.3885\n",
      "F1 score: 0.0723\n",
      "F1 score: 0.07231125545657657\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 106s 530ms/step - loss: 166.1980 - val_loss: 12045.7456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aldo/Documents/ssd/ssd_encoder_decoder/ssd_output_decoder.py:175: RuntimeWarning: overflow encountered in exp\n",
      "  y_pred_decoded_raw[:,:,[-2,-1]] = np.exp(y_pred_decoded_raw[:,:,[-2,-1]] * y_pred[:,:,[-2,-1]]) # exp(ln(w(pred)/w(anchor)) / w_variance * w_variance) == w(pred) / w(anchor), exp(ln(h(pred)/h(anchor)) / h_variance * h_variance) == h(pred) / h(anchor)\n",
      "/home/aldo/Documents/ssd/ssd_encoder_decoder/ssd_output_decoder.py:198: RuntimeWarning: overflow encountered in multiply\n",
      "  y_pred_decoded_raw[:,:,[-3,-1]] *= img_height # Convert ymin, ymax back to absolute coordinates\n",
      "/home/aldo/Documents/ssd/bounding_box_utils/bounding_box_utils.py:280: RuntimeWarning: overflow encountered in multiply\n",
      "  return side_lengths[:,0] * side_lengths[:,1]\n",
      "/home/aldo/Documents/ssd/bounding_box_utils/bounding_box_utils.py:280: RuntimeWarning: invalid value encountered in multiply\n",
      "  return side_lengths[:,0] * side_lengths[:,1]\n",
      "/home/aldo/Documents/ssd/bounding_box_utils/bounding_box_utils.py:378: RuntimeWarning: overflow encountered in multiply\n",
      "  boxes1_areas = (boxes1[:,xmax] - boxes1[:,xmin] + d) * (boxes1[:,ymax] - boxes1[:,ymin] + d)\n",
      "/home/aldo/Documents/ssd/bounding_box_utils/bounding_box_utils.py:378: RuntimeWarning: invalid value encountered in multiply\n",
      "  boxes1_areas = (boxes1[:,xmax] - boxes1[:,xmin] + d) * (boxes1[:,ymax] - boxes1[:,ymin] + d)\n",
      "/home/aldo/Documents/ssd/bounding_box_utils/bounding_box_utils.py:381: RuntimeWarning: invalid value encountered in subtract\n",
      "  union_areas = boxes1_areas + boxes2_areas - intersection_areas\n",
      "/home/aldo/Documents/ssd/bounding_box_utils/bounding_box_utils.py:379: RuntimeWarning: overflow encountered in multiply\n",
      "  boxes2_areas = (boxes2[:,xmax] - boxes2[:,xmin] + d) * (boxes2[:,ymax] - boxes2[:,ymin] + d)\n",
      "/home/aldo/Documents/ssd/extra_files/helper.py:230: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  yB = min(boxA[3] + boxA[1], boxB[3] + boxB[1])\n",
      "/home/aldo/Documents/ssd/extra_files/helper.py:237: RuntimeWarning: overflow encountered in double_scalars\n",
      "  boxAArea = boxA[2] * boxA[3]\n",
      "/home/aldo/Documents/ssd/extra_files/helper.py:238: RuntimeWarning: overflow encountered in double_scalars\n",
      "  boxBArea = boxB[2] * boxB[3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 1025\n",
      "Presicion: 0.0781\n",
      "Recall: 0.3326\n",
      "F1 score: 0.1265\n",
      "F1 score: 0.12649012658491174\n",
      "Improve F1 score from 0.08993633157572349 to 0.12649012658491174\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 107s 535ms/step - loss: 141.9374 - val_loss: 674.0578\n",
      "Number of images: 1025\n",
      "Presicion: 0.0025\n",
      "Recall: 0.05\n",
      "F1 score: 0.0047\n",
      "F1 score: 0.004684521543988075\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 106s 528ms/step - loss: 107.0604 - val_loss: 355.3525\n",
      "Number of images: 1025\n",
      "Presicion: 0.0\n",
      "Recall: 0.0\n",
      "F1 score: 0.0\n",
      "F1 score: 3.3329545607589186e-20\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 107s 536ms/step - loss: 110.8243 - val_loss: 247.0752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aldo/Documents/ssd/ssd_encoder_decoder/ssd_output_decoder.py:197: RuntimeWarning: overflow encountered in multiply\n",
      "  y_pred_decoded_raw[:,:,[-4,-2]] *= img_width # Convert xmin, xmax back to absolute coordinates\n",
      "/home/aldo/Documents/ssd/bounding_box_utils/bounding_box_utils.py:378: RuntimeWarning: overflow encountered in subtract\n",
      "  boxes1_areas = (boxes1[:,xmax] - boxes1[:,xmin] + d) * (boxes1[:,ymax] - boxes1[:,ymin] + d)\n",
      "/home/aldo/Documents/ssd/bounding_box_utils/bounding_box_utils.py:278: RuntimeWarning: overflow encountered in subtract\n",
      "  side_lengths = np.maximum(0, max_xy - min_xy + d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 1025\n",
      "Presicion: 0.0176\n",
      "Recall: 0.1507\n",
      "F1 score: 0.0316\n",
      "F1 score: 0.031560911419670365\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 107s 534ms/step - loss: 107.3175 - val_loss: 131.6135\n",
      "Number of images: 1025\n",
      "Presicion: 0.0202\n",
      "Recall: 0.2503\n",
      "F1 score: 0.0373\n",
      "F1 score: 0.03732554693540373\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 105s 525ms/step - loss: 107.5767 - val_loss: 114.5521\n",
      "Number of images: 1025\n",
      "Presicion: 0.0279\n",
      "Recall: 0.2783\n",
      "F1 score: 0.0507\n",
      "F1 score: 0.050691611586901664\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 106s 529ms/step - loss: 106.9012 - val_loss: 109.4707\n",
      "Number of images: 1025\n",
      "Presicion: 0.007\n",
      "Recall: 0.1264\n",
      "F1 score: 0.0133\n",
      "F1 score: 0.013250548746538663\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 107s 534ms/step - loss: 106.7656 - val_loss: 107.2442\n",
      "Number of images: 1025\n",
      "Presicion: 0.0219\n",
      "Recall: 0.1835\n",
      "F1 score: 0.0392\n",
      "F1 score: 0.039181950563293766\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 105s 523ms/step - loss: 106.6557 - val_loss: 106.8679\n",
      "Number of images: 1025\n",
      "Presicion: 0.0286\n",
      "Recall: 0.2828\n",
      "F1 score: 0.0519\n",
      "F1 score: 0.05192340411795214\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 106s 529ms/step - loss: 107.1647 - val_loss: 106.7828\n",
      "Number of images: 1025\n",
      "Presicion: 0.0183\n",
      "Recall: 0.1741\n",
      "F1 score: 0.0331\n",
      "F1 score: 0.033072262892873946\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 106s 531ms/step - loss: 106.6076 - val_loss: 106.6167\n",
      "Number of images: 1025\n",
      "Presicion: 0.0178\n",
      "Recall: 0.1857\n",
      "F1 score: 0.0325\n",
      "F1 score: 0.03247220960656465\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 105s 524ms/step - loss: 106.6856 - val_loss: 106.6291\n",
      "Number of images: 1025\n",
      "Presicion: 0.0193\n",
      "Recall: 0.1932\n",
      "F1 score: 0.035\n",
      "F1 score: 0.03502283163239992\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 106s 528ms/step - loss: 106.6916 - val_loss: 106.7277\n",
      "Number of images: 1025\n",
      "Presicion: 0.0211\n",
      "Recall: 0.1619\n",
      "F1 score: 0.0373\n",
      "F1 score: 0.03734827832609886\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 106s 530ms/step - loss: 106.6287 - val_loss: 106.4874\n",
      "Number of images: 1025\n",
      "Presicion: 0.0205\n",
      "Recall: 0.1739\n",
      "F1 score: 0.0367\n",
      "F1 score: 0.03667655707130535\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 105s 524ms/step - loss: 106.6305 - val_loss: 106.5955\n",
      "Number of images: 1025\n",
      "Presicion: 0.0225\n",
      "Recall: 0.1823\n",
      "F1 score: 0.04\n",
      "F1 score: 0.04001530308072007\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 105s 527ms/step - loss: 106.6324 - val_loss: 106.4743\n",
      "Number of images: 1025\n",
      "Presicion: 0.0185\n",
      "Recall: 0.2068\n",
      "F1 score: 0.0339\n",
      "F1 score: 0.03392555139496932\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 106s 529ms/step - loss: 106.5541 - val_loss: 106.4608\n",
      "Number of images: 1025\n",
      "Presicion: 0.0202\n",
      "Recall: 0.2071\n",
      "F1 score: 0.0367\n",
      "F1 score: 0.03673530613758481\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 106s 531ms/step - loss: 106.5938 - val_loss: 107.0350\n",
      "Number of images: 1025\n",
      "Presicion: 0.0206\n",
      "Recall: 0.2392\n",
      "F1 score: 0.038\n",
      "F1 score: 0.03798526674716787\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 105s 523ms/step - loss: 106.7075 - val_loss: 106.8063\n",
      "Number of images: 1025\n",
      "Presicion: 0.0164\n",
      "Recall: 0.1709\n",
      "F1 score: 0.0299\n",
      "F1 score: 0.02994842140006858\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 106s 532ms/step - loss: 106.7341 - val_loss: 90.9214\n",
      "Number of images: 1025\n",
      "Presicion: 0.0097\n",
      "Recall: 0.1265\n",
      "F1 score: 0.0181\n",
      "F1 score: 0.018071289617824282\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 106s 528ms/step - loss: 106.7302 - val_loss: 87.6900\n",
      "Number of images: 1025\n",
      "Presicion: 0.0186\n",
      "Recall: 0.2212\n",
      "F1 score: 0.0343\n",
      "F1 score: 0.034281356993979294\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 105s 525ms/step - loss: 106.7444 - val_loss: 106.3630\n",
      "Number of images: 1025\n",
      "Presicion: 0.0104\n",
      "Recall: 0.1145\n",
      "F1 score: 0.0191\n",
      "F1 score: 0.019128496054608306\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 107s 535ms/step - loss: 107.1460 - val_loss: 108.6356\n",
      "Number of images: 1025\n",
      "Presicion: 0.0141\n",
      "Recall: 0.1822\n",
      "F1 score: 0.0261\n",
      "F1 score: 0.026091489242416794\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 105s 527ms/step - loss: 107.7912 - val_loss: 106.5539\n",
      "Number of images: 1025\n",
      "Presicion: 0.0219\n",
      "Recall: 0.2136\n",
      "F1 score: 0.0397\n",
      "F1 score: 0.039655172578581865\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 104s 521ms/step - loss: 106.5932 - val_loss: 106.5039\n",
      "Number of images: 1025\n",
      "Presicion: 0.0234\n",
      "Recall: 0.2155\n",
      "F1 score: 0.0422\n",
      "F1 score: 0.04215540849189587\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 106.6387 - val_loss: 84.0935\n",
      "Number of images: 1025\n",
      "Presicion: 0.0201\n",
      "Recall: 0.2215\n",
      "F1 score: 0.0369\n",
      "F1 score: 0.036884613616418954\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 105s 526ms/step - loss: 106.5809 - val_loss: 103.6473\n",
      "Number of images: 1025\n",
      "Presicion: 0.0207\n",
      "Recall: 0.1843\n",
      "F1 score: 0.0372\n",
      "F1 score: 0.037207916756567115\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 107s 536ms/step - loss: 106.5992 - val_loss: 84.5691\n",
      "Number of images: 1025\n",
      "Presicion: 0.0262\n",
      "Recall: 0.2887\n",
      "F1 score: 0.048\n",
      "F1 score: 0.047972326128172565\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 105s 526ms/step - loss: 117.3264 - val_loss: 112.4819\n",
      "Number of images: 1025\n",
      "Presicion: 0.0351\n",
      "Recall: 0.2869\n",
      "F1 score: 0.0626\n",
      "F1 score: 0.06256142642388782\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 105s 527ms/step - loss: 113.5310 - val_loss: 115.9896\n",
      "Number of images: 1025\n",
      "Presicion: 0.0324\n",
      "Recall: 0.2904\n",
      "F1 score: 0.0582\n",
      "F1 score: 0.05824176425548532\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 106s 531ms/step - loss: 106.9413 - val_loss: 109.4434\n",
      "Number of images: 1025\n",
      "Presicion: 0.0679\n",
      "Recall: 0.4096\n",
      "F1 score: 0.1165\n",
      "F1 score: 0.11651072427066976\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 106s 529ms/step - loss: 106.6151 - val_loss: 108.6600\n",
      "Number of images: 1025\n",
      "Presicion: 0.0575\n",
      "Recall: 0.4078\n",
      "F1 score: 0.1007\n",
      "F1 score: 0.10073568789490225\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 105s 524ms/step - loss: 106.8360 - val_loss: 106.4862\n",
      "Number of images: 1025\n",
      "Presicion: 0.0218\n",
      "Recall: 0.2069\n",
      "F1 score: 0.0395\n",
      "F1 score: 0.03946026438122315\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 104s 520ms/step - loss: 106.5561 - val_loss: 106.4481\n",
      "Number of images: 1025\n",
      "Presicion: 0.028\n",
      "Recall: 0.2566\n",
      "F1 score: 0.0504\n",
      "F1 score: 0.05043900524476918\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 105s 524ms/step - loss: 106.5091 - val_loss: 106.4393\n",
      "Number of images: 1025\n",
      "Presicion: 0.0219\n",
      "Recall: 0.1976\n",
      "F1 score: 0.0395\n",
      "F1 score: 0.03945295858122983\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 105s 526ms/step - loss: 113.4393 - val_loss: 108.0171\n",
      "Number of images: 1025\n",
      "Presicion: 0.0258\n",
      "Recall: 0.2451\n",
      "F1 score: 0.0466\n",
      "F1 score: 0.04662762221564293\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 105s 526ms/step - loss: 106.8272 - val_loss: 92.7842\n",
      "Number of images: 1025\n",
      "Presicion: 0.081\n",
      "Recall: 0.4329\n",
      "F1 score: 0.1364\n",
      "F1 score: 0.13640804133801832\n",
      "Improve F1 score from 0.12649012658491174 to 0.13640804133801832\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 106s 528ms/step - loss: 106.6630 - val_loss: 107.4975\n",
      "Number of images: 1025\n",
      "Presicion: 0.0437\n",
      "Recall: 0.3367\n",
      "F1 score: 0.0774\n",
      "F1 score: 0.07741155034632144\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 106s 531ms/step - loss: 106.6503 - val_loss: 96.4372\n",
      "Number of images: 1025\n",
      "Presicion: 0.0724\n",
      "Recall: 0.431\n",
      "F1 score: 0.124\n",
      "F1 score: 0.12398440965927734\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 106s 529ms/step - loss: 106.7212 - val_loss: 106.7196\n",
      "Number of images: 1025\n",
      "Presicion: 0.0516\n",
      "Recall: 0.3369\n",
      "F1 score: 0.0895\n",
      "F1 score: 0.0895425567259963\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 106s 531ms/step - loss: 106.6431 - val_loss: 106.5510\n",
      "Number of images: 1025\n",
      "Presicion: 0.0408\n",
      "Recall: 0.3052\n",
      "F1 score: 0.072\n",
      "F1 score: 0.07201701671539304\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 106s 532ms/step - loss: 109.1030 - val_loss: 109.1640\n",
      "Number of images: 1025\n",
      "Presicion: 0.0439\n",
      "Recall: 0.3344\n",
      "F1 score: 0.0776\n",
      "F1 score: 0.07759942977632019\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 107s 534ms/step - loss: 110.0127 - val_loss: 114.9576\n",
      "Number of images: 1025\n",
      "Presicion: 0.0038\n",
      "Recall: 0.131\n",
      "F1 score: 0.0074\n",
      "F1 score: 0.00738637660510511\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 107s 536ms/step - loss: 107.3207 - val_loss: 107.5272\n",
      "Number of images: 1025\n",
      "Presicion: 0.0189\n",
      "Recall: 0.1696\n",
      "F1 score: 0.0339\n",
      "F1 score: 0.03393428674870412\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 105s 525ms/step - loss: 107.2101 - val_loss: 107.4421\n",
      "Number of images: 1025\n",
      "Presicion: 0.0211\n",
      "Recall: 0.1825\n",
      "F1 score: 0.0378\n",
      "F1 score: 0.03784822597473549\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 106s 531ms/step - loss: 106.6956 - val_loss: 106.7352\n",
      "Number of images: 1025\n",
      "Presicion: 0.0187\n",
      "Recall: 0.1459\n",
      "F1 score: 0.0331\n",
      "F1 score: 0.03310846216996071\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 106s 528ms/step - loss: 106.6061 - val_loss: 106.6400\n",
      "Number of images: 1025\n",
      "Presicion: 0.0188\n",
      "Recall: 0.1823\n",
      "F1 score: 0.0341\n",
      "F1 score: 0.034083739685782266\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 106s 528ms/step - loss: 106.6117 - val_loss: 106.5364\n",
      "Number of images: 1025\n",
      "Presicion: 0.0201\n",
      "Recall: 0.1974\n",
      "F1 score: 0.0365\n",
      "F1 score: 0.03649988805091492\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 105s 526ms/step - loss: 106.6193 - val_loss: 106.5180\n",
      "Number of images: 1025\n",
      "Presicion: 0.0167\n",
      "Recall: 0.178\n",
      "F1 score: 0.0305\n",
      "F1 score: 0.03049409814171486\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 106.5655 - val_loss: 106.5326\n",
      "Number of images: 1025\n",
      "Presicion: 0.0175\n",
      "Recall: 0.1892\n",
      "F1 score: 0.032\n",
      "F1 score: 0.032013273833184516\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 105s 527ms/step - loss: 106.6317 - val_loss: 106.5479\n",
      "Number of images: 1025\n",
      "Presicion: 0.018\n",
      "Recall: 0.2018\n",
      "F1 score: 0.0331\n",
      "F1 score: 0.033125684287952\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 105s 525ms/step - loss: 106.5732 - val_loss: 106.4696\n",
      "Number of images: 1025\n",
      "Presicion: 0.0188\n",
      "Recall: 0.1916\n",
      "F1 score: 0.0342\n",
      "F1 score: 0.03422566898450337\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 105s 524ms/step - loss: 106.5109 - val_loss: 106.5887\n",
      "Number of images: 1025\n",
      "Presicion: 0.0175\n",
      "Recall: 0.1898\n",
      "F1 score: 0.032\n",
      "F1 score: 0.03199775150655848\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 106s 528ms/step - loss: 106.5448 - val_loss: 106.5395\n",
      "Number of images: 1025\n",
      "Presicion: 0.017\n",
      "Recall: 0.1857\n",
      "F1 score: 0.0312\n",
      "F1 score: 0.031218608751610758\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 106s 528ms/step - loss: 106.5094 - val_loss: 106.4454\n",
      "Number of images: 1025\n",
      "Presicion: 0.0364\n",
      "Recall: 0.3138\n",
      "F1 score: 0.0652\n",
      "F1 score: 0.0651872252233663\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 106.5364 - val_loss: 106.4658\n",
      "Number of images: 1025\n",
      "Presicion: 0.0256\n",
      "Recall: 0.2303\n",
      "F1 score: 0.046\n",
      "F1 score: 0.046040398627645994\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 106s 531ms/step - loss: 106.4964 - val_loss: 106.5093\n",
      "Number of images: 1025\n",
      "Presicion: 0.026\n",
      "Recall: 0.2105\n",
      "F1 score: 0.0462\n",
      "F1 score: 0.04620880583086277\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 106s 529ms/step - loss: 106.5172 - val_loss: 106.4585\n",
      "Number of images: 1025\n",
      "Presicion: 0.0233\n",
      "Recall: 0.2125\n",
      "F1 score: 0.042\n",
      "F1 score: 0.041974818166019355\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 105s 527ms/step - loss: 106.5258 - val_loss: 106.5208\n",
      "Number of images: 1025\n",
      "Presicion: 0.0189\n",
      "Recall: 0.2033\n",
      "F1 score: 0.0345\n",
      "F1 score: 0.03451193988870248\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 105s 526ms/step - loss: 106.5042 - val_loss: 106.5501\n",
      "Number of images: 1025\n",
      "Presicion: 0.0496\n",
      "Recall: 0.3646\n",
      "F1 score: 0.0873\n",
      "F1 score: 0.08728277292696156\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 107s 536ms/step - loss: 106.5777 - val_loss: 105.3043\n",
      "Number of images: 1025\n",
      "Presicion: 0.0185\n",
      "Recall: 0.1969\n",
      "F1 score: 0.0338\n",
      "F1 score: 0.033760438416441156\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 106s 530ms/step - loss: 106.4893 - val_loss: 106.5587\n",
      "Number of images: 1025\n",
      "Presicion: 0.0464\n",
      "Recall: 0.3401\n",
      "F1 score: 0.0817\n",
      "F1 score: 0.08168902563872568\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 105s 526ms/step - loss: 106.4892 - val_loss: 106.4873\n",
      "Number of images: 1025\n",
      "Presicion: 0.0194\n",
      "Recall: 0.1991\n",
      "F1 score: 0.0353\n",
      "F1 score: 0.03532618656162644\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 106s 531ms/step - loss: 128.3015 - val_loss: 168.3115\n",
      "Number of images: 1025\n",
      "Presicion: 0.013\n",
      "Recall: 0.1848\n",
      "F1 score: 0.0242\n",
      "F1 score: 0.024217748178477813\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 107s 537ms/step - loss: 108.0330 - val_loss: 108.3734\n",
      "Number of images: 1025\n",
      "Presicion: 0.0295\n",
      "Recall: 0.2302\n",
      "F1 score: 0.0523\n",
      "F1 score: 0.052315231683188995\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 106s 532ms/step - loss: 106.6683 - val_loss: 106.9215\n",
      "Number of images: 1025\n",
      "Presicion: 0.0223\n",
      "Recall: 0.2145\n",
      "F1 score: 0.0403\n",
      "F1 score: 0.04032063765802194\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 107s 535ms/step - loss: 106.5704 - val_loss: 106.6179\n",
      "Number of images: 1025\n",
      "Presicion: 0.0213\n",
      "Recall: 0.2029\n",
      "F1 score: 0.0386\n",
      "F1 score: 0.038630978387041603\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 105s 527ms/step - loss: 106.6388 - val_loss: 106.6100\n",
      "Number of images: 1025\n",
      "Presicion: 0.02\n",
      "Recall: 0.2097\n",
      "F1 score: 0.0365\n",
      "F1 score: 0.036510217841068\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 107s 537ms/step - loss: 106.6076 - val_loss: 106.5424\n",
      "Number of images: 1025\n",
      "Presicion: 0.0219\n",
      "Recall: 0.1956\n",
      "F1 score: 0.0395\n",
      "F1 score: 0.03945381947170381\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 105s 524ms/step - loss: 106.5365 - val_loss: 106.5088\n",
      "Number of images: 1025\n",
      "Presicion: 0.0208\n",
      "Recall: 0.1949\n",
      "F1 score: 0.0375\n",
      "F1 score: 0.037510285527198955\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 106s 530ms/step - loss: 145.8105 - val_loss: 153.8487\n",
      "Number of images: 1025\n",
      "Presicion: 0.0043\n",
      "Recall: 0.0982\n",
      "F1 score: 0.0083\n",
      "F1 score: 0.00825974818777484\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 108s 538ms/step - loss: 108.6234 - val_loss: 122.4307\n",
      "Number of images: 1025\n",
      "Presicion: 0.0033\n",
      "Recall: 0.0727\n",
      "F1 score: 0.0064\n",
      "F1 score: 0.006366917927611111\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 107.1743 - val_loss: 112.9813\n",
      "Number of images: 1025\n",
      "Presicion: 0.032\n",
      "Recall: 0.1715\n",
      "F1 score: 0.0539\n",
      "F1 score: 0.05389096622158019\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 106s 530ms/step - loss: 112.3816 - val_loss: 123.2347\n",
      "Number of images: 1025\n",
      "Presicion: 0.0003\n",
      "Recall: 0.0178\n",
      "F1 score: 0.0007\n",
      "F1 score: 0.0006521954284239415\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 105s 527ms/step - loss: 109.1950 - val_loss: 110.3362\n",
      "Number of images: 1025\n",
      "Presicion: 0.013\n",
      "Recall: 0.1799\n",
      "F1 score: 0.0242\n",
      "F1 score: 0.024206796994460426\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 105s 527ms/step - loss: 107.5022 - val_loss: 110.3221\n",
      "Number of images: 1025\n",
      "Presicion: 0.0074\n",
      "Recall: 0.1052\n",
      "F1 score: 0.0139\n",
      "F1 score: 0.013890273032578204\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 105s 525ms/step - loss: 110.0441 - val_loss: 131.0798\n",
      "Number of images: 1025\n",
      "Presicion: 0.0059\n",
      "Recall: 0.1315\n",
      "F1 score: 0.0113\n",
      "F1 score: 0.011266250651559184\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 105s 525ms/step - loss: 111.9339 - val_loss: 111.0980\n",
      "Number of images: 1025\n",
      "Presicion: 0.0252\n",
      "Recall: 0.1867\n",
      "F1 score: 0.0444\n",
      "F1 score: 0.04442968891391953\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 106s 529ms/step - loss: 111.5870 - val_loss: 110.0556\n",
      "Number of images: 1025\n",
      "Presicion: 0.0134\n",
      "Recall: 0.1741\n",
      "F1 score: 0.025\n",
      "F1 score: 0.02496685212623968\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 107s 534ms/step - loss: 106.9786 - val_loss: 108.6682\n",
      "Number of images: 1025\n",
      "Presicion: 0.0109\n",
      "Recall: 0.1526\n",
      "F1 score: 0.0203\n",
      "F1 score: 0.02027392719626661\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 106s 530ms/step - loss: 106.7320 - val_loss: 107.3009\n",
      "Number of images: 1025\n",
      "Presicion: 0.0162\n",
      "Recall: 0.1607\n",
      "F1 score: 0.0294\n",
      "F1 score: 0.02938648400520795\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 106s 530ms/step - loss: 106.6794 - val_loss: 107.6199\n",
      "Number of images: 1025\n",
      "Presicion: 0.0089\n",
      "Recall: 0.0987\n",
      "F1 score: 0.0164\n",
      "F1 score: 0.016402103176928452\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 106s 532ms/step - loss: 106.8647 - val_loss: 107.3695\n",
      "Number of images: 1025\n",
      "Presicion: 0.0234\n",
      "Recall: 0.2504\n",
      "F1 score: 0.0428\n",
      "F1 score: 0.04279071541376841\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 106s 532ms/step - loss: 106.8628 - val_loss: 106.8980\n",
      "Number of images: 1025\n",
      "Presicion: 0.0185\n",
      "Recall: 0.2078\n",
      "F1 score: 0.034\n",
      "F1 score: 0.034004291422040325\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 106s 528ms/step - loss: 106.6832 - val_loss: 106.6519\n",
      "Number of images: 1025\n",
      "Presicion: 0.0221\n",
      "Recall: 0.2185\n",
      "F1 score: 0.0402\n",
      "F1 score: 0.04022115204243692\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 105s 527ms/step - loss: 106.7872 - val_loss: 106.7853\n",
      "Number of images: 1025\n",
      "Presicion: 0.024\n",
      "Recall: 0.2337\n",
      "F1 score: 0.0435\n",
      "F1 score: 0.043498185469240586\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 105s 525ms/step - loss: 108.3742 - val_loss: 107.0073\n",
      "Number of images: 1025\n",
      "Presicion: 0.0136\n",
      "Recall: 0.1171\n",
      "F1 score: 0.0244\n",
      "F1 score: 0.024368250320528185\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 105s 527ms/step - loss: 106.9790 - val_loss: 106.7428\n",
      "Number of images: 1025\n",
      "Presicion: 0.0167\n",
      "Recall: 0.1572\n",
      "F1 score: 0.0302\n",
      "F1 score: 0.03024788255392955\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 105s 527ms/step - loss: 106.6418 - val_loss: 106.6383\n",
      "Number of images: 1025\n",
      "Presicion: 0.0191\n",
      "Recall: 0.1863\n",
      "F1 score: 0.0347\n",
      "F1 score: 0.03465788586836585\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 106s 529ms/step - loss: 106.6277 - val_loss: 106.7138\n",
      "Number of images: 1025\n",
      "Presicion: 0.0212\n",
      "Recall: 0.2212\n",
      "F1 score: 0.0387\n",
      "F1 score: 0.038699448721694785\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 105s 526ms/step - loss: 106.6420 - val_loss: 106.6533\n",
      "Number of images: 1025\n",
      "Presicion: 0.0256\n",
      "Recall: 0.2201\n",
      "F1 score: 0.0459\n",
      "F1 score: 0.04594139299735664\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 105s 525ms/step - loss: 106.6526 - val_loss: 106.9144\n",
      "Number of images: 1025\n",
      "Presicion: 0.0187\n",
      "Recall: 0.1724\n",
      "F1 score: 0.0337\n",
      "F1 score: 0.03374733639713386\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 105s 525ms/step - loss: 108.7902 - val_loss: 113.1923\n",
      "Number of images: 1025\n",
      "Presicion: 0.0055\n",
      "Recall: 0.0776\n",
      "F1 score: 0.0103\n",
      "F1 score: 0.01026655078110333\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 105s 524ms/step - loss: 115.8722 - val_loss: 124.3238\n",
      "Number of images: 1025\n",
      "Presicion: 0.0219\n",
      "Recall: 0.2076\n",
      "F1 score: 0.0396\n",
      "F1 score: 0.03961271227949859\n",
      "TRAINING MODEL WITH LEARNING RATE: 0.001\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 117s 584ms/step - loss: 8.6574 - val_loss: 9.2346\n",
      "Number of images: 1025\n",
      "Presicion: 0.0412\n",
      "Recall: 0.3417\n",
      "F1 score: 0.0735\n",
      "F1 score: 0.07352379692603851\n",
      "Improve F1 score from -inf to 0.07352379692603851\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 105s 525ms/step - loss: 5.3459 - val_loss: 6.3538\n",
      "Number of images: 1025\n",
      "Presicion: 0.0387\n",
      "Recall: 0.3985\n",
      "F1 score: 0.0705\n",
      "F1 score: 0.07052593227195689\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 105s 527ms/step - loss: 5.2252 - val_loss: 7.1801\n",
      "Number of images: 1025\n",
      "Presicion: 0.0833\n",
      "Recall: 0.3835\n",
      "F1 score: 0.1368\n",
      "F1 score: 0.13684385281638078\n",
      "Improve F1 score from 0.07352379692603851 to 0.13684385281638078\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 106s 528ms/step - loss: 8.8152 - val_loss: 143.8035\n",
      "Number of images: 1025\n",
      "Presicion: 0.0008\n",
      "Recall: 0.0346\n",
      "F1 score: 0.0017\n",
      "F1 score: 0.0016519318821957246\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 103s 517ms/step - loss: 11.7245 - val_loss: 137.5173\n",
      "Number of images: 1025\n",
      "Presicion: 0.0089\n",
      "Recall: 0.1319\n",
      "F1 score: 0.0167\n",
      "F1 score: 0.0167374534084017\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 106s 528ms/step - loss: 12.0303 - val_loss: 132.5609\n",
      "Number of images: 1025\n",
      "Presicion: 0.0368\n",
      "Recall: 0.318\n",
      "F1 score: 0.066\n",
      "F1 score: 0.06595844361329642\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 106s 531ms/step - loss: 5.9562 - val_loss: 19.8602\n",
      "Number of images: 1025\n",
      "Presicion: 0.1419\n",
      "Recall: 0.311\n",
      "F1 score: 0.1949\n",
      "F1 score: 0.19487767418894653\n",
      "Improve F1 score from 0.13684385281638078 to 0.19487767418894653\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 5.1770 - val_loss: 9.8611\n",
      "Number of images: 1025\n",
      "Presicion: 0.1355\n",
      "Recall: 0.3362\n",
      "F1 score: 0.1932\n",
      "F1 score: 0.19319399442678714\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 106s 530ms/step - loss: 5.6662 - val_loss: 7.9375\n",
      "Number of images: 1025\n",
      "Presicion: 0.1442\n",
      "Recall: 0.3349\n",
      "F1 score: 0.2016\n",
      "F1 score: 0.20160411785125967\n",
      "Improve F1 score from 0.19487767418894653 to 0.20160411785125967\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 103s 516ms/step - loss: 5.0887 - val_loss: 6.4893\n",
      "Number of images: 1025\n",
      "Presicion: 0.1248\n",
      "Recall: 0.3571\n",
      "F1 score: 0.1849\n",
      "F1 score: 0.18492700782714336\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 104s 518ms/step - loss: 4.9487 - val_loss: 7.3848\n",
      "Number of images: 1025\n",
      "Presicion: 0.0767\n",
      "Recall: 0.4353\n",
      "F1 score: 0.1304\n",
      "F1 score: 0.13035932035202616\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 105s 527ms/step - loss: 4.8838 - val_loss: 5.6187\n",
      "Number of images: 1025\n",
      "Presicion: 0.0529\n",
      "Recall: 0.4705\n",
      "F1 score: 0.0951\n",
      "F1 score: 0.09510945706588239\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 106s 532ms/step - loss: 4.7394 - val_loss: 5.1935\n",
      "Number of images: 1025\n",
      "Presicion: 0.0608\n",
      "Recall: 0.4863\n",
      "F1 score: 0.1082\n",
      "F1 score: 0.10815004882415565\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 107s 534ms/step - loss: 4.7826 - val_loss: 4.9875\n",
      "Number of images: 1025\n",
      "Presicion: 0.0425\n",
      "Recall: 0.4739\n",
      "F1 score: 0.078\n",
      "F1 score: 0.07799502152014369\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 106s 530ms/step - loss: 4.6465 - val_loss: 4.8845\n",
      "Number of images: 1025\n",
      "Presicion: 0.0581\n",
      "Recall: 0.4677\n",
      "F1 score: 0.1033\n",
      "F1 score: 0.10334355370097213\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 104s 519ms/step - loss: 4.6656 - val_loss: 4.7478\n",
      "Number of images: 1025\n",
      "Presicion: 0.0412\n",
      "Recall: 0.4894\n",
      "F1 score: 0.0759\n",
      "F1 score: 0.07592072944521196\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 103s 516ms/step - loss: 4.6208 - val_loss: 4.6974\n",
      "Number of images: 1025\n",
      "Presicion: 0.0538\n",
      "Recall: 0.481\n",
      "F1 score: 0.0968\n",
      "F1 score: 0.09678752089457804\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 106s 529ms/step - loss: 4.5254 - val_loss: 4.8006\n",
      "Number of images: 1025\n",
      "Presicion: 0.047\n",
      "Recall: 0.5016\n",
      "F1 score: 0.0859\n",
      "F1 score: 0.08591532550345411\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 105s 523ms/step - loss: 4.5505 - val_loss: 4.7949\n",
      "Number of images: 1025\n",
      "Presicion: 0.047\n",
      "Recall: 0.4979\n",
      "F1 score: 0.0859\n",
      "F1 score: 0.08594114324298946\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 105s 526ms/step - loss: 4.5096 - val_loss: 4.7786\n",
      "Number of images: 1025\n",
      "Presicion: 0.0574\n",
      "Recall: 0.4822\n",
      "F1 score: 0.1027\n",
      "F1 score: 0.10266660757904997\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 103s 516ms/step - loss: 4.4778 - val_loss: 4.7879\n",
      "Number of images: 1025\n",
      "Presicion: 0.0389\n",
      "Recall: 0.5047\n",
      "F1 score: 0.0723\n",
      "F1 score: 0.07231271133863579\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 103s 513ms/step - loss: 4.4612 - val_loss: 4.6756\n",
      "Number of images: 1025\n",
      "Presicion: 0.0459\n",
      "Recall: 0.5145\n",
      "F1 score: 0.0842\n",
      "F1 score: 0.08423203916113127\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 105s 525ms/step - loss: 4.3995 - val_loss: 4.7087\n",
      "Number of images: 1025\n",
      "Presicion: 0.0404\n",
      "Recall: 0.498\n",
      "F1 score: 0.0748\n",
      "F1 score: 0.07480539041589081\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 4.3859 - val_loss: 4.7754\n",
      "Number of images: 1025\n",
      "Presicion: 0.0483\n",
      "Recall: 0.5195\n",
      "F1 score: 0.0884\n",
      "F1 score: 0.08842318320320819\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 103s 517ms/step - loss: 4.3863 - val_loss: 5.1755\n",
      "Number of images: 1025\n",
      "Presicion: 0.0445\n",
      "Recall: 0.415\n",
      "F1 score: 0.0804\n",
      "F1 score: 0.08041418500525255\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 106s 531ms/step - loss: 4.3345 - val_loss: 5.1377\n",
      "Number of images: 1025\n",
      "Presicion: 0.0538\n",
      "Recall: 0.5267\n",
      "F1 score: 0.0976\n",
      "F1 score: 0.09757579263602506\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 123s 615ms/step - loss: 4.3833 - val_loss: 4.6787\n",
      "Number of images: 1025\n",
      "Presicion: 0.0534\n",
      "Recall: 0.5034\n",
      "F1 score: 0.0966\n",
      "F1 score: 0.09662546083699186\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 113s 565ms/step - loss: 4.2961 - val_loss: 5.0407\n",
      "Number of images: 1025\n",
      "Presicion: 0.0457\n",
      "Recall: 0.4865\n",
      "F1 score: 0.0836\n",
      "F1 score: 0.08355357714342539\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 107s 534ms/step - loss: 4.2923 - val_loss: 5.4725\n",
      "Number of images: 1025\n",
      "Presicion: 0.0441\n",
      "Recall: 0.5051\n",
      "F1 score: 0.0811\n",
      "F1 score: 0.0810952926340034\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 106s 531ms/step - loss: 4.3035 - val_loss: 4.8378\n",
      "Number of images: 1025\n",
      "Presicion: 0.0392\n",
      "Recall: 0.5063\n",
      "F1 score: 0.0727\n",
      "F1 score: 0.07269727246632944\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 105s 525ms/step - loss: 4.2626 - val_loss: 5.8587\n",
      "Number of images: 1025\n",
      "Presicion: 0.0909\n",
      "Recall: 0.3621\n",
      "F1 score: 0.1453\n",
      "F1 score: 0.14527751920087936\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 105s 527ms/step - loss: 4.2801 - val_loss: 6.4470\n",
      "Number of images: 1025\n",
      "Presicion: 0.0338\n",
      "Recall: 0.3277\n",
      "F1 score: 0.0613\n",
      "F1 score: 0.06129428443060295\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 104s 520ms/step - loss: 4.3091 - val_loss: 5.3756\n",
      "Number of images: 1025\n",
      "Presicion: 0.042\n",
      "Recall: 0.5045\n",
      "F1 score: 0.0776\n",
      "F1 score: 0.07762739099600477\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 107s 535ms/step - loss: 8.6518 - val_loss: 217.7914\n",
      "Number of images: 1025\n",
      "Presicion: 0.0057\n",
      "Recall: 0.1389\n",
      "F1 score: 0.0109\n",
      "F1 score: 0.010894449409244535\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 104s 518ms/step - loss: 17.0235 - val_loss: 190.8530\n",
      "Number of images: 1025\n",
      "Presicion: 0.0773\n",
      "Recall: 0.0363\n",
      "F1 score: 0.0494\n",
      "F1 score: 0.04940424181283848\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 106s 529ms/step - loss: 13.6400 - val_loss: 104.4052\n",
      "Number of images: 1025\n",
      "Presicion: 0.0\n",
      "Recall: 0.0\n",
      "F1 score: 0.0\n",
      "F1 score: 0.0\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 108s 539ms/step - loss: 15.4017 - val_loss: 97.5492\n",
      "Number of images: 1025\n",
      "Presicion: 0.0585\n",
      "Recall: 0.1788\n",
      "F1 score: 0.0882\n",
      "F1 score: 0.08818305130439136\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 12.7041 - val_loss: 21.8275\n",
      "Number of images: 1025\n",
      "Presicion: 0.0259\n",
      "Recall: 0.1822\n",
      "F1 score: 0.0453\n",
      "F1 score: 0.045293988962039074\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 106s 531ms/step - loss: 12.0946 - val_loss: 14.6407\n",
      "Number of images: 1025\n",
      "Presicion: 0.0114\n",
      "Recall: 0.09\n",
      "F1 score: 0.0202\n",
      "F1 score: 0.020211550439952403\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 12.3538 - val_loss: 13.4944\n",
      "Number of images: 1025\n",
      "Presicion: 0.2753\n",
      "Recall: 0.1447\n",
      "F1 score: 0.1897\n",
      "F1 score: 0.18970036417080086\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 103s 515ms/step - loss: 11.9132 - val_loss: 12.9634\n",
      "Number of images: 1025\n",
      "Presicion: 0.2538\n",
      "Recall: 0.1642\n",
      "F1 score: 0.1994\n",
      "F1 score: 0.19936728089032954\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 106s 529ms/step - loss: 12.0582 - val_loss: 12.6960\n",
      "Number of images: 1025\n",
      "Presicion: 0.1167\n",
      "Recall: 0.1557\n",
      "F1 score: 0.1334\n",
      "F1 score: 0.13339348890900649\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 103s 517ms/step - loss: 11.2183 - val_loss: 10.4437\n",
      "Number of images: 1025\n",
      "Presicion: 0.1496\n",
      "Recall: 0.3021\n",
      "F1 score: 0.2001\n",
      "F1 score: 0.20010160219835021\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 5.5360 - val_loss: 5.7911\n",
      "Number of images: 1025\n",
      "Presicion: 0.0791\n",
      "Recall: 0.4411\n",
      "F1 score: 0.1342\n",
      "F1 score: 0.13417529319076882\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 106s 531ms/step - loss: 4.7815 - val_loss: 5.5764\n",
      "Number of images: 1025\n",
      "Presicion: 0.1022\n",
      "Recall: 0.371\n",
      "F1 score: 0.1602\n",
      "F1 score: 0.16021693903525588\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 104s 518ms/step - loss: 4.7014 - val_loss: 5.3894\n",
      "Number of images: 1025\n",
      "Presicion: 0.0773\n",
      "Recall: 0.3909\n",
      "F1 score: 0.1291\n",
      "F1 score: 0.12909681612395196\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 107s 536ms/step - loss: 4.6542 - val_loss: 5.2343\n",
      "Number of images: 1025\n",
      "Presicion: 0.075\n",
      "Recall: 0.3789\n",
      "F1 score: 0.1252\n",
      "F1 score: 0.1251639450967933\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 108s 538ms/step - loss: 4.6380 - val_loss: 5.0789\n",
      "Number of images: 1025\n",
      "Presicion: 0.07\n",
      "Recall: 0.3862\n",
      "F1 score: 0.1185\n",
      "F1 score: 0.11847161014798302\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 107s 536ms/step - loss: 4.5843 - val_loss: 5.4827\n",
      "Number of images: 1025\n",
      "Presicion: 0.0622\n",
      "Recall: 0.3689\n",
      "F1 score: 0.1064\n",
      "F1 score: 0.10643359411229669\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 108s 538ms/step - loss: 4.5337 - val_loss: 5.2064\n",
      "Number of images: 1025\n",
      "Presicion: 0.0363\n",
      "Recall: 0.4555\n",
      "F1 score: 0.0672\n",
      "F1 score: 0.06721575073201436\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 107s 534ms/step - loss: 4.4694 - val_loss: 5.2905\n",
      "Number of images: 1025\n",
      "Presicion: 0.0562\n",
      "Recall: 0.4603\n",
      "F1 score: 0.1001\n",
      "F1 score: 0.1001144422400501\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 106s 529ms/step - loss: 4.4454 - val_loss: 4.8685\n",
      "Number of images: 1025\n",
      "Presicion: 0.0722\n",
      "Recall: 0.4837\n",
      "F1 score: 0.1256\n",
      "F1 score: 0.12563935316434038\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 106s 528ms/step - loss: 4.4642 - val_loss: 5.5822\n",
      "Number of images: 1025\n",
      "Presicion: 0.0688\n",
      "Recall: 0.4321\n",
      "F1 score: 0.1187\n",
      "F1 score: 0.11871340352613687\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 4.4662 - val_loss: 4.8704\n",
      "Number of images: 1025\n",
      "Presicion: 0.1068\n",
      "Recall: 0.4422\n",
      "F1 score: 0.172\n",
      "F1 score: 0.1719923768973333\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 4.3442 - val_loss: 4.6273\n",
      "Number of images: 1025\n",
      "Presicion: 0.0998\n",
      "Recall: 0.3943\n",
      "F1 score: 0.1592\n",
      "F1 score: 0.15924093568830094\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 104s 520ms/step - loss: 5.2484 - val_loss: 7.3272\n",
      "Number of images: 1025\n",
      "Presicion: 0.0351\n",
      "Recall: 0.4145\n",
      "F1 score: 0.0647\n",
      "F1 score: 0.0647191055199348\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 104s 521ms/step - loss: 4.5809 - val_loss: 5.6593\n",
      "Number of images: 1025\n",
      "Presicion: 0.0296\n",
      "Recall: 0.3529\n",
      "F1 score: 0.0546\n",
      "F1 score: 0.0546039370560314\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 117s 585ms/step - loss: 6.0998 - val_loss: 12.0147\n",
      "Number of images: 1025\n",
      "Presicion: 0.0195\n",
      "Recall: 0.2867\n",
      "F1 score: 0.0365\n",
      "F1 score: 0.03647350475041511\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 107s 535ms/step - loss: 8.2382 - val_loss: 7.3178\n",
      "Number of images: 1025\n",
      "Presicion: 0.0476\n",
      "Recall: 0.3236\n",
      "F1 score: 0.083\n",
      "F1 score: 0.08300084863427193\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 105s 523ms/step - loss: 5.3657 - val_loss: 9.5037\n",
      "Number of images: 1025\n",
      "Presicion: 0.0338\n",
      "Recall: 0.2307\n",
      "F1 score: 0.0589\n",
      "F1 score: 0.05888846962525594\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 108s 538ms/step - loss: 4.4888 - val_loss: 5.2167\n",
      "Number of images: 1025\n",
      "Presicion: 0.0619\n",
      "Recall: 0.4602\n",
      "F1 score: 0.1092\n",
      "F1 score: 0.10919080322765044\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 105s 527ms/step - loss: 4.4216 - val_loss: 4.7935\n",
      "Number of images: 1025\n",
      "Presicion: 0.0234\n",
      "Recall: 0.4144\n",
      "F1 score: 0.0443\n",
      "F1 score: 0.04434451166292467\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 107s 536ms/step - loss: 4.9095 - val_loss: 6.0827\n",
      "Number of images: 1025\n",
      "Presicion: 0.0441\n",
      "Recall: 0.3515\n",
      "F1 score: 0.0784\n",
      "F1 score: 0.07835462934479628\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 105s 523ms/step - loss: 4.3227 - val_loss: 4.9071\n",
      "Number of images: 1025\n",
      "Presicion: 0.024\n",
      "Recall: 0.3997\n",
      "F1 score: 0.0453\n",
      "F1 score: 0.045263137021986546\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 104s 520ms/step - loss: 4.3112 - val_loss: 4.8446\n",
      "Number of images: 1025\n",
      "Presicion: 0.0287\n",
      "Recall: 0.4706\n",
      "F1 score: 0.0542\n",
      "F1 score: 0.05415020505412794\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 104s 520ms/step - loss: 4.2621 - val_loss: 4.8454\n",
      "Number of images: 1025\n",
      "Presicion: 0.0267\n",
      "Recall: 0.4627\n",
      "F1 score: 0.0505\n",
      "F1 score: 0.0505071305425953\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 107s 534ms/step - loss: 4.4406 - val_loss: 4.7407\n",
      "Number of images: 1025\n",
      "Presicion: 0.0486\n",
      "Recall: 0.5008\n",
      "F1 score: 0.0887\n",
      "F1 score: 0.08866003297281778\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 106s 531ms/step - loss: 4.2452 - val_loss: 4.7135\n",
      "Number of images: 1025\n",
      "Presicion: 0.0487\n",
      "Recall: 0.3821\n",
      "F1 score: 0.0864\n",
      "F1 score: 0.08638491401361509\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 106s 530ms/step - loss: 4.1673 - val_loss: 5.3637\n",
      "Number of images: 1025\n",
      "Presicion: 0.0431\n",
      "Recall: 0.3947\n",
      "F1 score: 0.0777\n",
      "F1 score: 0.07766314107536398\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 107s 535ms/step - loss: 4.1933 - val_loss: 4.6680\n",
      "Number of images: 1025\n",
      "Presicion: 0.0573\n",
      "Recall: 0.487\n",
      "F1 score: 0.1025\n",
      "F1 score: 0.10249634096860775\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 104s 521ms/step - loss: 4.2562 - val_loss: 5.7881\n",
      "Number of images: 1025\n",
      "Presicion: 0.0375\n",
      "Recall: 0.4359\n",
      "F1 score: 0.069\n",
      "F1 score: 0.06898225805339657\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 108s 538ms/step - loss: 4.2089 - val_loss: 5.2962\n",
      "Number of images: 1025\n",
      "Presicion: 0.0408\n",
      "Recall: 0.4959\n",
      "F1 score: 0.0754\n",
      "F1 score: 0.07542707906578108\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 105s 523ms/step - loss: 4.1662 - val_loss: 4.5241\n",
      "Number of images: 1025\n",
      "Presicion: 0.0495\n",
      "Recall: 0.5236\n",
      "F1 score: 0.0905\n",
      "F1 score: 0.09051366073733143\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 104s 521ms/step - loss: 4.1236 - val_loss: 4.3395\n",
      "Number of images: 1025\n",
      "Presicion: 0.0698\n",
      "Recall: 0.5329\n",
      "F1 score: 0.1234\n",
      "F1 score: 0.12337123023220184\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 106s 532ms/step - loss: 4.0966 - val_loss: 4.4489\n",
      "Number of images: 1025\n",
      "Presicion: 0.0509\n",
      "Recall: 0.5443\n",
      "F1 score: 0.0932\n",
      "F1 score: 0.09315462961894895\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 105s 523ms/step - loss: 4.1180 - val_loss: 4.4944\n",
      "Number of images: 1025\n",
      "Presicion: 0.0342\n",
      "Recall: 0.5253\n",
      "F1 score: 0.0643\n",
      "F1 score: 0.0642794136558434\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 104s 520ms/step - loss: 4.0917 - val_loss: 4.7929\n",
      "Number of images: 1025\n",
      "Presicion: 0.0408\n",
      "Recall: 0.5163\n",
      "F1 score: 0.0757\n",
      "F1 score: 0.07568627202811143\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 107s 537ms/step - loss: 4.0815 - val_loss: 4.4926\n",
      "Number of images: 1025\n",
      "Presicion: 0.0319\n",
      "Recall: 0.5185\n",
      "F1 score: 0.0601\n",
      "F1 score: 0.060098300747191524\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 108s 539ms/step - loss: 4.1218 - val_loss: 4.5630\n",
      "Number of images: 1025\n",
      "Presicion: 0.0482\n",
      "Recall: 0.534\n",
      "F1 score: 0.0884\n",
      "F1 score: 0.08844203615061946\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 107s 535ms/step - loss: 4.1460 - val_loss: 4.4757\n",
      "Number of images: 1025\n",
      "Presicion: 0.0409\n",
      "Recall: 0.5451\n",
      "F1 score: 0.076\n",
      "F1 score: 0.07604191777597312\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 103s 517ms/step - loss: 4.1091 - val_loss: 4.2552\n",
      "Number of images: 1025\n",
      "Presicion: 0.0518\n",
      "Recall: 0.5558\n",
      "F1 score: 0.0948\n",
      "F1 score: 0.09477594664326738\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 105s 527ms/step - loss: 4.2887 - val_loss: 4.7394\n",
      "Number of images: 1025\n",
      "Presicion: 0.0726\n",
      "Recall: 0.479\n",
      "F1 score: 0.1262\n",
      "F1 score: 0.12616051612400075\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 103s 514ms/step - loss: 4.1036 - val_loss: 4.4451\n",
      "Number of images: 1025\n",
      "Presicion: 0.0761\n",
      "Recall: 0.5325\n",
      "F1 score: 0.1332\n",
      "F1 score: 0.13317776814458776\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 107s 535ms/step - loss: 4.0670 - val_loss: 5.0075\n",
      "Number of images: 1025\n",
      "Presicion: 0.0436\n",
      "Recall: 0.4845\n",
      "F1 score: 0.08\n",
      "F1 score: 0.08004727020925895\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 105s 523ms/step - loss: 4.1310 - val_loss: 4.6135\n",
      "Number of images: 1025\n",
      "Presicion: 0.0499\n",
      "Recall: 0.5026\n",
      "F1 score: 0.0908\n",
      "F1 score: 0.09082784870020236\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 105s 527ms/step - loss: 4.0350 - val_loss: 4.4765\n",
      "Number of images: 1025\n",
      "Presicion: 0.0389\n",
      "Recall: 0.4951\n",
      "F1 score: 0.0721\n",
      "F1 score: 0.07213708729990813\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 103s 517ms/step - loss: 4.0434 - val_loss: 4.5737\n",
      "Number of images: 1025\n",
      "Presicion: 0.0342\n",
      "Recall: 0.4961\n",
      "F1 score: 0.0639\n",
      "F1 score: 0.06393109349878374\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 107s 534ms/step - loss: 4.0287 - val_loss: 4.8092\n",
      "Number of images: 1025\n",
      "Presicion: 0.0548\n",
      "Recall: 0.4466\n",
      "F1 score: 0.0977\n",
      "F1 score: 0.09766629215871628\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 104s 521ms/step - loss: 4.0251 - val_loss: 4.8230\n",
      "Number of images: 1025\n",
      "Presicion: 0.0451\n",
      "Recall: 0.4526\n",
      "F1 score: 0.082\n",
      "F1 score: 0.0819509126557233\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 106s 530ms/step - loss: 4.0261 - val_loss: 4.6178\n",
      "Number of images: 1025\n",
      "Presicion: 0.0329\n",
      "Recall: 0.4977\n",
      "F1 score: 0.0617\n",
      "F1 score: 0.06170956783130146\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 104s 518ms/step - loss: 3.9950 - val_loss: 4.3966\n",
      "Number of images: 1025\n",
      "Presicion: 0.0339\n",
      "Recall: 0.5349\n",
      "F1 score: 0.0637\n",
      "F1 score: 0.06372774884312053\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 105s 524ms/step - loss: 4.0107 - val_loss: 4.3380\n",
      "Number of images: 1025\n",
      "Presicion: 0.094\n",
      "Recall: 0.5283\n",
      "F1 score: 0.1596\n",
      "F1 score: 0.1596034453303907\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 102s 510ms/step - loss: 3.9762 - val_loss: 4.2286\n",
      "Number of images: 1025\n",
      "Presicion: 0.0499\n",
      "Recall: 0.5522\n",
      "F1 score: 0.0915\n",
      "F1 score: 0.09145475877296567\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 107s 537ms/step - loss: 4.0055 - val_loss: 5.7674\n",
      "Number of images: 1025\n",
      "Presicion: 0.0376\n",
      "Recall: 0.5214\n",
      "F1 score: 0.0701\n",
      "F1 score: 0.07005727813058342\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 106s 530ms/step - loss: 3.9833 - val_loss: 5.8628\n",
      "Number of images: 1025\n",
      "Presicion: 0.0603\n",
      "Recall: 0.5539\n",
      "F1 score: 0.1087\n",
      "F1 score: 0.10873662825679901\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 107s 536ms/step - loss: 3.9582 - val_loss: 5.1056\n",
      "Number of images: 1025\n",
      "Presicion: 0.0602\n",
      "Recall: 0.5146\n",
      "F1 score: 0.1077\n",
      "F1 score: 0.10773802206912944\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 106s 531ms/step - loss: 4.5713 - val_loss: 20.6745\n",
      "Number of images: 1025\n",
      "Presicion: 0.1135\n",
      "Recall: 0.3995\n",
      "F1 score: 0.1767\n",
      "F1 score: 0.1767264076672964\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 107s 536ms/step - loss: 5.6447 - val_loss: 7.6406\n",
      "Number of images: 1025\n",
      "Presicion: 0.0823\n",
      "Recall: 0.3193\n",
      "F1 score: 0.1309\n",
      "F1 score: 0.130889326645809\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 104s 520ms/step - loss: 5.3040 - val_loss: 5.6867\n",
      "Number of images: 1025\n",
      "Presicion: 0.0928\n",
      "Recall: 0.1161\n",
      "F1 score: 0.1032\n",
      "F1 score: 0.10318457207513033\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 106s 532ms/step - loss: 4.5651 - val_loss: 5.7086\n",
      "Number of images: 1025\n",
      "Presicion: 0.1113\n",
      "Recall: 0.2063\n",
      "F1 score: 0.1446\n",
      "F1 score: 0.14461571368118364\n",
      "TRAINING MODEL WITH LEARNING RATE: 0.0001\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 115s 575ms/step - loss: 9.8834 - val_loss: 7.4347\n",
      "Number of images: 1025\n",
      "Presicion: 0.0343\n",
      "Recall: 0.4117\n",
      "F1 score: 0.0633\n",
      "F1 score: 0.0633127823469095\n",
      "Improve F1 score from -inf to 0.0633127823469095\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 108s 539ms/step - loss: 6.3426 - val_loss: 6.6813\n",
      "Number of images: 1025\n",
      "Presicion: 0.0354\n",
      "Recall: 0.4049\n",
      "F1 score: 0.0651\n",
      "F1 score: 0.06510028277563927\n",
      "Improve F1 score from 0.0633127823469095 to 0.06510028277563927\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 106s 528ms/step - loss: 5.8685 - val_loss: 6.9677\n",
      "Number of images: 1025\n",
      "Presicion: 0.0443\n",
      "Recall: 0.3975\n",
      "F1 score: 0.0797\n",
      "F1 score: 0.07974811843807493\n",
      "Improve F1 score from 0.06510028277563927 to 0.07974811843807493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "200/200 [==============================] - 106s 529ms/step - loss: 5.4428 - val_loss: 6.6102\n",
      "Number of images: 1025\n",
      "Presicion: 0.0509\n",
      "Recall: 0.399\n",
      "F1 score: 0.0902\n",
      "F1 score: 0.09023404077567851\n",
      "Improve F1 score from 0.07974811843807493 to 0.09023404077567851\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 106s 531ms/step - loss: 5.3199 - val_loss: 6.5248\n",
      "Number of images: 1025\n",
      "Presicion: 0.0535\n",
      "Recall: 0.4098\n",
      "F1 score: 0.0947\n",
      "F1 score: 0.09472152702012492\n",
      "Improve F1 score from 0.09023404077567851 to 0.09472152702012492\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 5.2171 - val_loss: 6.0504\n",
      "Number of images: 1025\n",
      "Presicion: 0.0539\n",
      "Recall: 0.4326\n",
      "F1 score: 0.0958\n",
      "F1 score: 0.09581827522585497\n",
      "Improve F1 score from 0.09472152702012492 to 0.09581827522585497\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 107s 536ms/step - loss: 5.1156 - val_loss: 5.5107\n",
      "Number of images: 1025\n",
      "Presicion: 0.0529\n",
      "Recall: 0.4475\n",
      "F1 score: 0.0946\n",
      "F1 score: 0.0945645309350415\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 106s 529ms/step - loss: 5.0584 - val_loss: 5.7352\n",
      "Number of images: 1025\n",
      "Presicion: 0.0503\n",
      "Recall: 0.4479\n",
      "F1 score: 0.0904\n",
      "F1 score: 0.09043403903682677\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 107s 536ms/step - loss: 5.0509 - val_loss: 5.4750\n",
      "Number of images: 1025\n",
      "Presicion: 0.0569\n",
      "Recall: 0.4677\n",
      "F1 score: 0.1015\n",
      "F1 score: 0.1015140222568277\n",
      "Improve F1 score from 0.09581827522585497 to 0.1015140222568277\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 106s 532ms/step - loss: 4.9584 - val_loss: 5.1704\n",
      "Number of images: 1025\n",
      "Presicion: 0.0479\n",
      "Recall: 0.463\n",
      "F1 score: 0.0868\n",
      "F1 score: 0.08683275133701898\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 106s 531ms/step - loss: 4.9021 - val_loss: 5.1609\n",
      "Number of images: 1025\n",
      "Presicion: 0.0504\n",
      "Recall: 0.462\n",
      "F1 score: 0.0909\n",
      "F1 score: 0.09090717597837596\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 107s 536ms/step - loss: 4.9073 - val_loss: 4.9938\n",
      "Number of images: 1025\n",
      "Presicion: 0.054\n",
      "Recall: 0.4764\n",
      "F1 score: 0.097\n",
      "F1 score: 0.0970214544472777\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 4.8805 - val_loss: 5.0071\n",
      "Number of images: 1025\n",
      "Presicion: 0.0603\n",
      "Recall: 0.4837\n",
      "F1 score: 0.1073\n",
      "F1 score: 0.10726049928513331\n",
      "Improve F1 score from 0.1015140222568277 to 0.10726049928513331\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 103s 516ms/step - loss: 4.8402 - val_loss: 4.9506\n",
      "Number of images: 1025\n",
      "Presicion: 0.0631\n",
      "Recall: 0.4901\n",
      "F1 score: 0.1118\n",
      "F1 score: 0.11181178332486612\n",
      "Improve F1 score from 0.10726049928513331 to 0.11181178332486612\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 107s 534ms/step - loss: 4.8268 - val_loss: 4.9144\n",
      "Number of images: 1025\n",
      "Presicion: 0.0578\n",
      "Recall: 0.4858\n",
      "F1 score: 0.1033\n",
      "F1 score: 0.10334463015576452\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 106s 530ms/step - loss: 4.7789 - val_loss: 5.1052\n",
      "Number of images: 1025\n",
      "Presicion: 0.0644\n",
      "Recall: 0.4731\n",
      "F1 score: 0.1133\n",
      "F1 score: 0.11330996117982971\n",
      "Improve F1 score from 0.11181178332486612 to 0.11330996117982971\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 107s 534ms/step - loss: 4.7599 - val_loss: 4.8348\n",
      "Number of images: 1025\n",
      "Presicion: 0.0581\n",
      "Recall: 0.4933\n",
      "F1 score: 0.1039\n",
      "F1 score: 0.10394211436070126\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 109s 543ms/step - loss: 4.7366 - val_loss: 4.8665\n",
      "Number of images: 1025\n",
      "Presicion: 0.0544\n",
      "Recall: 0.4823\n",
      "F1 score: 0.0978\n",
      "F1 score: 0.09777822322609979\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 108s 539ms/step - loss: 4.7104 - val_loss: 4.9634\n",
      "Number of images: 1025\n",
      "Presicion: 0.0477\n",
      "Recall: 0.4811\n",
      "F1 score: 0.0868\n",
      "F1 score: 0.08683342782084956\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 108s 539ms/step - loss: 4.6990 - val_loss: 4.9122\n",
      "Number of images: 1025\n",
      "Presicion: 0.0711\n",
      "Recall: 0.4779\n",
      "F1 score: 0.1238\n",
      "F1 score: 0.12376586668063719\n",
      "Improve F1 score from 0.11330996117982971 to 0.12376586668063719\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 4.7505 - val_loss: 4.7643\n",
      "Number of images: 1025\n",
      "Presicion: 0.0649\n",
      "Recall: 0.4999\n",
      "F1 score: 0.1149\n",
      "F1 score: 0.1148826267275139\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 105s 527ms/step - loss: 4.5807 - val_loss: 4.8286\n",
      "Number of images: 1025\n",
      "Presicion: 0.0463\n",
      "Recall: 0.4959\n",
      "F1 score: 0.0846\n",
      "F1 score: 0.08464880173378626\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 107s 534ms/step - loss: 4.6379 - val_loss: 4.8329\n",
      "Number of images: 1025\n",
      "Presicion: 0.0637\n",
      "Recall: 0.5009\n",
      "F1 score: 0.113\n",
      "F1 score: 0.11300799136352624\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 105s 525ms/step - loss: 4.6280 - val_loss: 4.9764\n",
      "Number of images: 1025\n",
      "Presicion: 0.0722\n",
      "Recall: 0.4715\n",
      "F1 score: 0.1253\n",
      "F1 score: 0.12530000233643773\n",
      "Improve F1 score from 0.12376586668063719 to 0.12530000233643773\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 106s 529ms/step - loss: 4.5748 - val_loss: 4.7794\n",
      "Number of images: 1025\n",
      "Presicion: 0.0558\n",
      "Recall: 0.4993\n",
      "F1 score: 0.1004\n",
      "F1 score: 0.10043834467164653\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 106s 529ms/step - loss: 4.5637 - val_loss: 4.6904\n",
      "Number of images: 1025\n",
      "Presicion: 0.0582\n",
      "Recall: 0.5087\n",
      "F1 score: 0.1045\n",
      "F1 score: 0.10446718220769766\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 108s 541ms/step - loss: 4.5694 - val_loss: 4.7980\n",
      "Number of images: 1025\n",
      "Presicion: 0.0655\n",
      "Recall: 0.4955\n",
      "F1 score: 0.1157\n",
      "F1 score: 0.11574601929684351\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 105s 523ms/step - loss: 4.5113 - val_loss: 4.6173\n",
      "Number of images: 1025\n",
      "Presicion: 0.0728\n",
      "Recall: 0.5162\n",
      "F1 score: 0.1275\n",
      "F1 score: 0.12754291487552483\n",
      "Improve F1 score from 0.12530000233643773 to 0.12754291487552483\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 4.5283 - val_loss: 4.7278\n",
      "Number of images: 1025\n",
      "Presicion: 0.0472\n",
      "Recall: 0.5105\n",
      "F1 score: 0.0864\n",
      "F1 score: 0.0863910336611749\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 104s 518ms/step - loss: 4.5057 - val_loss: 4.6700\n",
      "Number of images: 1025\n",
      "Presicion: 0.0603\n",
      "Recall: 0.5292\n",
      "F1 score: 0.1083\n",
      "F1 score: 0.10832630734994776\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 107s 535ms/step - loss: 4.5112 - val_loss: 4.6754\n",
      "Number of images: 1025\n",
      "Presicion: 0.0677\n",
      "Recall: 0.5182\n",
      "F1 score: 0.1198\n",
      "F1 score: 0.11976608545981708\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 107s 535ms/step - loss: 4.4528 - val_loss: 4.5985\n",
      "Number of images: 1025\n",
      "Presicion: 0.0436\n",
      "Recall: 0.5168\n",
      "F1 score: 0.0804\n",
      "F1 score: 0.0803682751347398\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 107s 534ms/step - loss: 4.4610 - val_loss: 4.5362\n",
      "Number of images: 1025\n",
      "Presicion: 0.0547\n",
      "Recall: 0.5291\n",
      "F1 score: 0.0992\n",
      "F1 score: 0.09922625328860975\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 4.4269 - val_loss: 4.5300\n",
      "Number of images: 1025\n",
      "Presicion: 0.0459\n",
      "Recall: 0.5223\n",
      "F1 score: 0.0843\n",
      "F1 score: 0.08433113235744377\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 108s 538ms/step - loss: 4.3870 - val_loss: 4.4760\n",
      "Number of images: 1025\n",
      "Presicion: 0.0569\n",
      "Recall: 0.5291\n",
      "F1 score: 0.1028\n",
      "F1 score: 0.10280111659903614\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 104s 519ms/step - loss: 4.3846 - val_loss: 4.5520\n",
      "Number of images: 1025\n",
      "Presicion: 0.05\n",
      "Recall: 0.5337\n",
      "F1 score: 0.0914\n",
      "F1 score: 0.0913938948371052\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 103s 517ms/step - loss: 4.3537 - val_loss: 4.5429\n",
      "Number of images: 1025\n",
      "Presicion: 0.06\n",
      "Recall: 0.5308\n",
      "F1 score: 0.1078\n",
      "F1 score: 0.10782491504435292\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 105s 527ms/step - loss: 4.3785 - val_loss: 4.4980\n",
      "Number of images: 1025\n",
      "Presicion: 0.0519\n",
      "Recall: 0.5329\n",
      "F1 score: 0.0946\n",
      "F1 score: 0.09459645511621187\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 106s 529ms/step - loss: 4.2896 - val_loss: 4.5509\n",
      "Number of images: 1025\n",
      "Presicion: 0.0591\n",
      "Recall: 0.5326\n",
      "F1 score: 0.1063\n",
      "F1 score: 0.10632973715665106\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 106s 530ms/step - loss: 4.3561 - val_loss: 4.4421\n",
      "Number of images: 1025\n",
      "Presicion: 0.0531\n",
      "Recall: 0.5404\n",
      "F1 score: 0.0967\n",
      "F1 score: 0.09667421932119233\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 105s 525ms/step - loss: 4.3200 - val_loss: 4.4942\n",
      "Number of images: 1025\n",
      "Presicion: 0.0588\n",
      "Recall: 0.5303\n",
      "F1 score: 0.1058\n",
      "F1 score: 0.10580122141689387\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 106s 530ms/step - loss: 4.3435 - val_loss: 4.3862\n",
      "Number of images: 1025\n",
      "Presicion: 0.0619\n",
      "Recall: 0.5482\n",
      "F1 score: 0.1112\n",
      "F1 score: 0.11117302108470582\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 105s 527ms/step - loss: 4.3146 - val_loss: 4.4750\n",
      "Number of images: 1025\n",
      "Presicion: 0.0506\n",
      "Recall: 0.5452\n",
      "F1 score: 0.0925\n",
      "F1 score: 0.09252757901877247\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 105s 526ms/step - loss: 4.3052 - val_loss: 4.4639\n",
      "Number of images: 1025\n",
      "Presicion: 0.0461\n",
      "Recall: 0.5365\n",
      "F1 score: 0.0849\n",
      "F1 score: 0.08494564090533492\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 105s 526ms/step - loss: 4.2842 - val_loss: 4.5461\n",
      "Number of images: 1025\n",
      "Presicion: 0.0459\n",
      "Recall: 0.5322\n",
      "F1 score: 0.0845\n",
      "F1 score: 0.08450189559397517\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 106s 529ms/step - loss: 4.2635 - val_loss: 4.3823\n",
      "Number of images: 1025\n",
      "Presicion: 0.059\n",
      "Recall: 0.5384\n",
      "F1 score: 0.1064\n",
      "F1 score: 0.10638880586669357\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 104s 518ms/step - loss: 4.2711 - val_loss: 4.4273\n",
      "Number of images: 1025\n",
      "Presicion: 0.0449\n",
      "Recall: 0.5375\n",
      "F1 score: 0.0829\n",
      "F1 score: 0.08292717907313023\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 4.2403 - val_loss: 4.4368\n",
      "Number of images: 1025\n",
      "Presicion: 0.0464\n",
      "Recall: 0.5443\n",
      "F1 score: 0.0855\n",
      "F1 score: 0.08553719620457179\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 106s 529ms/step - loss: 4.2425 - val_loss: 4.3908\n",
      "Number of images: 1025\n",
      "Presicion: 0.0485\n",
      "Recall: 0.5501\n",
      "F1 score: 0.0891\n",
      "F1 score: 0.08905809328539882\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 103s 515ms/step - loss: 4.2297 - val_loss: 4.3491\n",
      "Number of images: 1025\n",
      "Presicion: 0.0406\n",
      "Recall: 0.5428\n",
      "F1 score: 0.0755\n",
      "F1 score: 0.07554806583584221\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 105s 525ms/step - loss: 4.1763 - val_loss: 4.3214\n",
      "Number of images: 1025\n",
      "Presicion: 0.0463\n",
      "Recall: 0.5334\n",
      "F1 score: 0.0852\n",
      "F1 score: 0.08515470228932663\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 106s 531ms/step - loss: 4.2197 - val_loss: 4.3873\n",
      "Number of images: 1025\n",
      "Presicion: 0.053\n",
      "Recall: 0.5478\n",
      "F1 score: 0.0967\n",
      "F1 score: 0.0966577807793589\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 106s 530ms/step - loss: 4.1676 - val_loss: 4.4257\n",
      "Number of images: 1025\n",
      "Presicion: 0.0976\n",
      "Recall: 0.4522\n",
      "F1 score: 0.1605\n",
      "F1 score: 0.16053495175172158\n",
      "Improve F1 score from 0.12754291487552483 to 0.16053495175172158\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 106s 532ms/step - loss: 4.1834 - val_loss: 4.4102\n",
      "Number of images: 1025\n",
      "Presicion: 0.0962\n",
      "Recall: 0.4845\n",
      "F1 score: 0.1605\n",
      "F1 score: 0.16054250018301444\n",
      "Improve F1 score from 0.16053495175172158 to 0.16054250018301444\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 4.1657 - val_loss: 4.2994\n",
      "Number of images: 1025\n",
      "Presicion: 0.0825\n",
      "Recall: 0.5176\n",
      "F1 score: 0.1423\n",
      "F1 score: 0.14234932497426167\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 107s 537ms/step - loss: 4.1983 - val_loss: 4.2700\n",
      "Number of images: 1025\n",
      "Presicion: 0.0687\n",
      "Recall: 0.5395\n",
      "F1 score: 0.1218\n",
      "F1 score: 0.12180386873972354\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 108s 538ms/step - loss: 4.1397 - val_loss: 4.2505\n",
      "Number of images: 1025\n",
      "Presicion: 0.0677\n",
      "Recall: 0.5158\n",
      "F1 score: 0.1197\n",
      "F1 score: 0.11973453910410259\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 107s 534ms/step - loss: 4.1237 - val_loss: 4.2286\n",
      "Number of images: 1025\n",
      "Presicion: 0.0586\n",
      "Recall: 0.5409\n",
      "F1 score: 0.1058\n",
      "F1 score: 0.10582068056596275\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 104s 520ms/step - loss: 4.1466 - val_loss: 4.2822\n",
      "Number of images: 1025\n",
      "Presicion: 0.0652\n",
      "Recall: 0.4959\n",
      "F1 score: 0.1152\n",
      "F1 score: 0.11520135908681493\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 106s 530ms/step - loss: 4.1260 - val_loss: 4.3143\n",
      "Number of images: 1025\n",
      "Presicion: 0.075\n",
      "Recall: 0.515\n",
      "F1 score: 0.131\n",
      "F1 score: 0.13097205806880008\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 106s 530ms/step - loss: 4.1452 - val_loss: 4.1956\n",
      "Number of images: 1025\n",
      "Presicion: 0.0574\n",
      "Recall: 0.5568\n",
      "F1 score: 0.104\n",
      "F1 score: 0.10403013114469771\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 106s 531ms/step - loss: 4.1377 - val_loss: 4.1839\n",
      "Number of images: 1025\n",
      "Presicion: 0.0452\n",
      "Recall: 0.5643\n",
      "F1 score: 0.0836\n",
      "F1 score: 0.08363587573394975\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 108s 539ms/step - loss: 4.1146 - val_loss: 4.2107\n",
      "Number of images: 1025\n",
      "Presicion: 0.0554\n",
      "Recall: 0.5354\n",
      "F1 score: 0.1004\n",
      "F1 score: 0.10040287050645944\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 4.0947 - val_loss: 4.1731\n",
      "Number of images: 1025\n",
      "Presicion: 0.0549\n",
      "Recall: 0.5454\n",
      "F1 score: 0.0997\n",
      "F1 score: 0.09969573428297668\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 106s 532ms/step - loss: 4.0991 - val_loss: 4.3789\n",
      "Number of images: 1025\n",
      "Presicion: 0.062\n",
      "Recall: 0.5213\n",
      "F1 score: 0.1108\n",
      "F1 score: 0.11076934296538557\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 106s 531ms/step - loss: 4.0883 - val_loss: 4.1292\n",
      "Number of images: 1025\n",
      "Presicion: 0.1042\n",
      "Recall: 0.5185\n",
      "F1 score: 0.1735\n",
      "F1 score: 0.17349747798074405\n",
      "Improve F1 score from 0.16054250018301444 to 0.17349747798074405\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 105s 525ms/step - loss: 4.0543 - val_loss: 4.1304\n",
      "Number of images: 1025\n",
      "Presicion: 0.1445\n",
      "Recall: 0.4831\n",
      "F1 score: 0.2225\n",
      "F1 score: 0.22246702130305435\n",
      "Improve F1 score from 0.17349747798074405 to 0.22246702130305435\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 108s 540ms/step - loss: 4.0422 - val_loss: 4.1291\n",
      "Number of images: 1025\n",
      "Presicion: 0.0452\n",
      "Recall: 0.5436\n",
      "F1 score: 0.0834\n",
      "F1 score: 0.0834391735791333\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 108s 539ms/step - loss: 4.0523 - val_loss: 4.1243\n",
      "Number of images: 1025\n",
      "Presicion: 0.0518\n",
      "Recall: 0.5391\n",
      "F1 score: 0.0946\n",
      "F1 score: 0.094585368889033\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 107s 534ms/step - loss: 4.0459 - val_loss: 4.2289\n",
      "Number of images: 1025\n",
      "Presicion: 0.0681\n",
      "Recall: 0.5376\n",
      "F1 score: 0.1209\n",
      "F1 score: 0.12085966920060796\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 4.0457 - val_loss: 4.1431\n",
      "Number of images: 1025\n",
      "Presicion: 0.0496\n",
      "Recall: 0.5503\n",
      "F1 score: 0.091\n",
      "F1 score: 0.091042485467021\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 106s 531ms/step - loss: 4.0282 - val_loss: 4.1881\n",
      "Number of images: 1025\n",
      "Presicion: 0.087\n",
      "Recall: 0.5012\n",
      "F1 score: 0.1482\n",
      "F1 score: 0.14823726340792728\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 107s 534ms/step - loss: 4.0214 - val_loss: 4.1034\n",
      "Number of images: 1025\n",
      "Presicion: 0.1806\n",
      "Recall: 0.459\n",
      "F1 score: 0.2592\n",
      "F1 score: 0.2591843767098839\n",
      "Improve F1 score from 0.22246702130305435 to 0.2591843767098839\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 3.9950 - val_loss: 4.2192\n",
      "Number of images: 1025\n",
      "Presicion: 0.1271\n",
      "Recall: 0.4302\n",
      "F1 score: 0.1962\n",
      "F1 score: 0.19624686035031685\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 106s 531ms/step - loss: 3.9615 - val_loss: 4.1399\n",
      "Number of images: 1025\n",
      "Presicion: 0.1011\n",
      "Recall: 0.4942\n",
      "F1 score: 0.1679\n",
      "F1 score: 0.167870157795762\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 107s 535ms/step - loss: 3.9902 - val_loss: 4.0832\n",
      "Number of images: 1025\n",
      "Presicion: 0.0857\n",
      "Recall: 0.5092\n",
      "F1 score: 0.1467\n",
      "F1 score: 0.14670399048795807\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 106s 529ms/step - loss: 3.9884 - val_loss: 4.1126\n",
      "Number of images: 1025\n",
      "Presicion: 0.0963\n",
      "Recall: 0.4849\n",
      "F1 score: 0.1607\n",
      "F1 score: 0.16072451792979964\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 107s 535ms/step - loss: 3.9610 - val_loss: 4.1091\n",
      "Number of images: 1025\n",
      "Presicion: 0.0712\n",
      "Recall: 0.5149\n",
      "F1 score: 0.1251\n",
      "F1 score: 0.1251120388085739\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 105s 527ms/step - loss: 3.9695 - val_loss: 4.0817\n",
      "Number of images: 1025\n",
      "Presicion: 0.1438\n",
      "Recall: 0.4767\n",
      "F1 score: 0.221\n",
      "F1 score: 0.22098711577110342\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 106s 532ms/step - loss: 3.9283 - val_loss: 4.0608\n",
      "Number of images: 1025\n",
      "Presicion: 0.1025\n",
      "Recall: 0.4905\n",
      "F1 score: 0.1696\n",
      "F1 score: 0.16956882800436818\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 107s 533ms/step - loss: 3.9719 - val_loss: 4.0711\n",
      "Number of images: 1025\n",
      "Presicion: 0.1226\n",
      "Recall: 0.486\n",
      "F1 score: 0.1958\n",
      "F1 score: 0.19583348926588234\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 106s 532ms/step - loss: 3.9585 - val_loss: 4.1636\n",
      "Number of images: 1025\n",
      "Presicion: 0.1271\n",
      "Recall: 0.4903\n",
      "F1 score: 0.2019\n",
      "F1 score: 0.20189535600988007\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 106s 530ms/step - loss: 3.9375 - val_loss: 4.0146\n",
      "Number of images: 1025\n",
      "Presicion: 0.1109\n",
      "Recall: 0.4981\n",
      "F1 score: 0.1814\n",
      "F1 score: 0.18136030804919015\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 107s 534ms/step - loss: 3.9279 - val_loss: 4.1011\n",
      "Number of images: 1025\n",
      "Presicion: 0.1057\n",
      "Recall: 0.4991\n",
      "F1 score: 0.1745\n",
      "F1 score: 0.17450342219354797\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 106s 531ms/step - loss: 3.9493 - val_loss: 4.0400\n",
      "Number of images: 1025\n",
      "Presicion: 0.0773\n",
      "Recall: 0.5348\n",
      "F1 score: 0.135\n",
      "F1 score: 0.13501332400493674\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 106s 531ms/step - loss: 3.8948 - val_loss: 4.0041\n",
      "Number of images: 1025\n",
      "Presicion: 0.0656\n",
      "Recall: 0.5493\n",
      "F1 score: 0.1172\n",
      "F1 score: 0.11721707823410192\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 107s 534ms/step - loss: 3.9575 - val_loss: 4.0102\n",
      "Number of images: 1025\n",
      "Presicion: 0.0581\n",
      "Recall: 0.543\n",
      "F1 score: 0.1049\n",
      "F1 score: 0.10489867570037817\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 106s 532ms/step - loss: 3.9424 - val_loss: 4.0191\n",
      "Number of images: 1025\n",
      "Presicion: 0.0636\n",
      "Recall: 0.5264\n",
      "F1 score: 0.1134\n",
      "F1 score: 0.11343331481485029\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 105s 523ms/step - loss: 3.9268 - val_loss: 3.9727\n",
      "Number of images: 1025\n",
      "Presicion: 0.0872\n",
      "Recall: 0.5383\n",
      "F1 score: 0.1501\n",
      "F1 score: 0.15012764338603282\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 106s 532ms/step - loss: 3.8856 - val_loss: 3.9723\n",
      "Number of images: 1025\n",
      "Presicion: 0.2212\n",
      "Recall: 0.4422\n",
      "F1 score: 0.2948\n",
      "F1 score: 0.29484485463521015\n",
      "Improve F1 score from 0.2591843767098839 to 0.29484485463521015\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 107s 534ms/step - loss: 3.8758 - val_loss: 3.9866\n",
      "Number of images: 1025\n",
      "Presicion: 0.1306\n",
      "Recall: 0.4947\n",
      "F1 score: 0.2067\n",
      "F1 score: 0.20669236746755204\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 107s 537ms/step - loss: 3.8733 - val_loss: 4.0034\n",
      "Number of images: 1025\n",
      "Presicion: 0.0587\n",
      "Recall: 0.5221\n",
      "F1 score: 0.1055\n",
      "F1 score: 0.10545650587195604\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 106s 531ms/step - loss: 3.8577 - val_loss: 3.9513\n",
      "Number of images: 1025\n",
      "Presicion: 0.1618\n",
      "Recall: 0.4671\n",
      "F1 score: 0.2403\n",
      "F1 score: 0.2403379012338213\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 107s 534ms/step - loss: 3.8665 - val_loss: 3.9756\n",
      "Number of images: 1025\n",
      "Presicion: 0.1665\n",
      "Recall: 0.447\n",
      "F1 score: 0.2427\n",
      "F1 score: 0.2426533955249221\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 106s 529ms/step - loss: 3.8258 - val_loss: 3.9747\n",
      "Number of images: 1025\n",
      "Presicion: 0.2459\n",
      "Recall: 0.4284\n",
      "F1 score: 0.3124\n",
      "F1 score: 0.31244775071555064\n",
      "Improve F1 score from 0.29484485463521015 to 0.31244775071555064\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 106s 530ms/step - loss: 3.8875 - val_loss: 3.9628\n",
      "Number of images: 1025\n",
      "Presicion: 0.2559\n",
      "Recall: 0.4025\n",
      "F1 score: 0.3129\n",
      "F1 score: 0.31285696492721454\n",
      "Improve F1 score from 0.31244775071555064 to 0.31285696492721454\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 106s 532ms/step - loss: 3.8472 - val_loss: 4.0086\n",
      "Number of images: 1025\n",
      "Presicion: 0.1277\n",
      "Recall: 0.4727\n",
      "F1 score: 0.2011\n",
      "F1 score: 0.20105521135084253\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 106s 530ms/step - loss: 3.8289 - val_loss: 3.8890\n",
      "Number of images: 1025\n",
      "Presicion: 0.2265\n",
      "Recall: 0.4628\n",
      "F1 score: 0.3041\n",
      "F1 score: 0.3040966173266364\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 106s 529ms/step - loss: 3.8132 - val_loss: 3.9188\n",
      "Number of images: 1025\n",
      "Presicion: 0.2142\n",
      "Recall: 0.4653\n",
      "F1 score: 0.2933\n",
      "F1 score: 0.2933254904709649\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 106s 530ms/step - loss: 3.8219 - val_loss: 3.9277\n",
      "Number of images: 1025\n",
      "Presicion: 0.148\n",
      "Recall: 0.4462\n",
      "F1 score: 0.2222\n",
      "F1 score: 0.22224063114981932\n"
     ]
    }
   ],
   "source": [
    "lr_list = [0.01, 0.001, 0.0001]\n",
    "\n",
    "for lr in lr_list:\n",
    "    # 1: Build the Keras model.\n",
    "    K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "    print('TRAINING MODEL WITH LEARNING RATE:', lr)\n",
    "    \n",
    "    model = ssd_300(image_size=(img_height, img_width, img_channels),\n",
    "                n_classes=n_classes,\n",
    "                mode='training',\n",
    "                alpha=1.0,\n",
    "                scales=scales,\n",
    "                aspect_ratios_per_layer=aspect_ratios,\n",
    "                two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                steps=steps,\n",
    "                offsets=offsets,\n",
    "                clip_boxes=clip_boxes,\n",
    "                variances=variances,\n",
    "                normalize_coords=normalize_coords,\n",
    "                subtract_mean=mean_color,\n",
    "                divide_by_stddev=divide_by_stddev,\n",
    "                swap_channels=swap_channels)\n",
    "\n",
    "    adam = Adam(lr=lr)\n",
    "    ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "    model.compile(optimizer=adam, loss=ssd_loss.compute_loss)\n",
    "    \n",
    "    # Define model callbacks.\n",
    "    main_path = '/home/aldo/Downloads/'\n",
    "    # TODO: Set the filepath under which you want to save the model.\n",
    "\n",
    "    csv_logger = CSVLogger(filename=main_path + 'model_' + str(lr) + '.csv',\n",
    "                           separator=',',\n",
    "                           append=True)\n",
    "\n",
    "\n",
    "    f1_callback = f1_call(0.20, \n",
    "                           0.45, \n",
    "                           200, \n",
    "                           normalize_coords, \n",
    "                           img_height, \n",
    "                           img_width, \n",
    "                           (1, 2006, 14),\n",
    "                           main_path + 'f1_' + str(lr) + '.csv',\n",
    "                           main_path + 'model.h5',\n",
    "                           label_csv='/home/aldo/Documents/data-cic/preprocess_data/PASCAL_val.csv',\n",
    "                           path_img='/home/aldo/Documents/data-cic/PASCAL',\n",
    "                           verborse=True)\n",
    "\n",
    "\n",
    "    callbacks = [csv_logger,\n",
    "                 f1_callback]\n",
    "    \n",
    "    initial_epoch   = 0\n",
    "    final_epoch     = 100\n",
    "    steps_per_epoch = 200\n",
    "\n",
    "    history = model.fit_generator(generator=train_generator,\n",
    "                                  steps_per_epoch=steps_per_epoch,\n",
    "                                  epochs=final_epoch,\n",
    "                                  callbacks=callbacks,\n",
    "                                  validation_data=val_generator,\n",
    "                                  validation_steps=ceil(val_dataset_size/batch_size),\n",
    "                                  initial_epoch=initial_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f746c412f28>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "mob_01 = pd.read_csv(main_path + 'model_0.01.csv')\n",
    "mob_001 = pd.read_csv(main_path + 'model_0.001.csv')\n",
    "mob_0001 = pd.read_csv(main_path + 'model_0.0001.csv')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(mob_01['epoch'][10:], mob_01['val_loss'][10:], color='r')\n",
    "ax.plot(mob_001['epoch'][10:], mob_001['val_loss'][10:], color='b')\n",
    "ax.plot(mob_0001['epoch'][10:], mob_0001['val_loss'][10:], color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f74f6e7e6d8>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mob_01_f1 = pd.read_csv(main_path + 'f1_0.01.csv')\n",
    "mob_001_f1 = pd.read_csv(main_path + 'f1_0.001.csv')\n",
    "mob_0001_f1 = pd.read_csv(main_path + 'f1_0.0001.csv')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(mob_01_f1['epoch'], mob_01_f1['f1 score'], color='r')\n",
    "ax.plot(mob_001_f1['epoch'], mob_001_f1['f1 score'], color='b')\n",
    "ax.plot(mob_0001_f1['epoch'], mob_0001_f1['f1 score'], color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING MODEL WITH ALPHA: 1.0\n",
      "Epoch 1/80\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 567s 567ms/step - loss: 6.6649\n",
      "Epoch 2/80\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 574s 574ms/step - loss: 5.1164\n",
      "Epoch 3/80\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 564s 564ms/step - loss: 4.9450\n",
      "Epoch 4/80\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 540s 540ms/step - loss: 4.8143\n",
      "Epoch 5/80\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 545s 545ms/step - loss: 4.6769\n",
      "Epoch 6/80\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 560s 560ms/step - loss: 4.6001\n",
      "Epoch 7/80\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 554s 554ms/step - loss: 4.5212\n",
      "Epoch 8/80\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 532s 532ms/step - loss: 4.4328\n",
      "Epoch 9/80\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 539s 539ms/step - loss: 4.3691\n",
      "Epoch 10/80\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 536s 536ms/step - loss: 4.3016\n",
      "Epoch 11/80\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 554s 554ms/step - loss: 4.2519\n",
      "Epoch 12/80\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 559s 559ms/step - loss: 4.1933\n",
      "Epoch 13/80\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 538s 538ms/step - loss: 4.1515\n",
      "Epoch 14/80\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 536s 536ms/step - loss: 4.1062\n",
      "Epoch 15/80\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 4.0682\n",
      "Epoch 16/80\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 528s 528ms/step - loss: 4.0233\n",
      "Epoch 17/80\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 532s 532ms/step - loss: 3.9925\n",
      "Epoch 18/80\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 530s 530ms/step - loss: 3.9528\n",
      "Epoch 19/80\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 552s 552ms/step - loss: 3.9196\n",
      "Epoch 20/80\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 540s 540ms/step - loss: 3.9103\n",
      "Epoch 21/80\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 535s 535ms/step - loss: 3.8880\n",
      "Epoch 22/80\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 532s 532ms/step - loss: 3.8294\n",
      "Epoch 23/80\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 536s 536ms/step - loss: 3.8193\n",
      "Epoch 24/80\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 537s 537ms/step - loss: 3.8086\n",
      "Epoch 25/80\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 535s 535ms/step - loss: 3.7860\n",
      "Epoch 26/80\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 533s 533ms/step - loss: 3.7777\n",
      "Epoch 27/80\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 531s 531ms/step - loss: 3.7106\n",
      "Epoch 28/80\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 534s 534ms/step - loss: 3.7012\n",
      "Epoch 29/80\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 540s 540ms/step - loss: 3.6913\n",
      "Epoch 30/80\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 533s 533ms/step - loss: 3.6918\n",
      "Epoch 31/80\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 531s 531ms/step - loss: 3.6500\n",
      "Epoch 32/80\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 531s 531ms/step - loss: 3.6177\n",
      "Epoch 33/80\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 531s 531ms/step - loss: 3.6038\n",
      "Epoch 34/80\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 542s 542ms/step - loss: 3.6089\n",
      "Epoch 35/80\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 535s 535ms/step - loss: 3.5658\n",
      "Epoch 36/80\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 533s 533ms/step - loss: 3.5595\n",
      "Epoch 37/80\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 536s 536ms/step - loss: 3.5652\n",
      "Epoch 38/80\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 535s 535ms/step - loss: 3.5225\n",
      "Epoch 39/80\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 535s 535ms/step - loss: 3.5171\n",
      "Epoch 40/80\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 532s 532ms/step - loss: 3.4992\n",
      "Epoch 41/80\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 537s 537ms/step - loss: 3.4935\n",
      "Epoch 42/80\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 535s 535ms/step - loss: 3.4869\n",
      "Epoch 43/80\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 534s 534ms/step - loss: 3.4740\n",
      "Epoch 44/80\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 537s 537ms/step - loss: 3.4531\n",
      "Epoch 45/80\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 536s 536ms/step - loss: 3.4397\n",
      "Epoch 46/80\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 533s 533ms/step - loss: 3.4296\n",
      "Epoch 47/80\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 536s 536ms/step - loss: 3.4268\n",
      "Epoch 48/80\n",
      "\n",
      "Epoch 00048: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 535s 535ms/step - loss: 3.3892\n",
      "Epoch 49/80\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 534s 534ms/step - loss: 3.3969\n",
      "Epoch 50/80\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 536s 536ms/step - loss: 3.3850\n",
      "Epoch 51/80\n",
      "\n",
      "Epoch 00051: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 537s 537ms/step - loss: 3.3815\n",
      "Epoch 52/80\n",
      "\n",
      "Epoch 00052: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 536s 536ms/step - loss: 3.3639\n",
      "Epoch 53/80\n",
      "\n",
      "Epoch 00053: LearningRateScheduler setting learning rate to 0.0001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 535s 535ms/step - loss: 3.3593\n",
      "Epoch 54/80\n",
      "\n",
      "Epoch 00054: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 535s 535ms/step - loss: 3.3270\n",
      "Epoch 55/80\n",
      "\n",
      "Epoch 00055: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 534s 534ms/step - loss: 3.3432\n",
      "Epoch 56/80\n",
      "\n",
      "Epoch 00056: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 538s 538ms/step - loss: 3.3386\n",
      "Epoch 57/80\n",
      "\n",
      "Epoch 00057: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 532s 532ms/step - loss: 3.3098\n",
      "Epoch 58/80\n",
      "\n",
      "Epoch 00058: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 533s 533ms/step - loss: 3.3137\n",
      "Epoch 59/80\n",
      "\n",
      "Epoch 00059: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 534s 534ms/step - loss: 3.2836\n",
      "Epoch 60/80\n",
      "\n",
      "Epoch 00060: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 533s 533ms/step - loss: 3.2970\n",
      "Epoch 61/80\n",
      "\n",
      "Epoch 00061: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 533s 533ms/step - loss: 3.2046\n",
      "Epoch 62/80\n",
      "\n",
      "Epoch 00062: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 534s 534ms/step - loss: 3.1874\n",
      "Epoch 63/80\n",
      "\n",
      "Epoch 00063: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 537s 537ms/step - loss: 3.1720\n",
      "Epoch 64/80\n",
      "\n",
      "Epoch 00064: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 534s 534ms/step - loss: 3.1651\n",
      "Epoch 65/80\n",
      "\n",
      "Epoch 00065: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 535s 535ms/step - loss: 3.1562\n",
      "Epoch 66/80\n",
      "\n",
      "Epoch 00066: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 534s 534ms/step - loss: 3.1401\n",
      "Epoch 67/80\n",
      "\n",
      "Epoch 00067: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 537s 537ms/step - loss: 3.1423\n",
      "Epoch 68/80\n",
      "\n",
      "Epoch 00068: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 538s 538ms/step - loss: 3.1471\n",
      "Epoch 69/80\n",
      "\n",
      "Epoch 00069: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 533s 533ms/step - loss: 3.1424\n",
      "Epoch 70/80\n",
      "\n",
      "Epoch 00070: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 537s 537ms/step - loss: 3.1399\n",
      "Epoch 71/80\n",
      "\n",
      "Epoch 00071: LearningRateScheduler setting learning rate to 1e-06.\n",
      "1000/1000 [==============================] - 531s 531ms/step - loss: 3.1106\n",
      "Epoch 72/80\n",
      "\n",
      "Epoch 00072: LearningRateScheduler setting learning rate to 1e-06.\n",
      "1000/1000 [==============================] - 534s 534ms/step - loss: 3.1377\n",
      "Epoch 73/80\n",
      "\n",
      "Epoch 00073: LearningRateScheduler setting learning rate to 1e-06.\n",
      "1000/1000 [==============================] - 534s 534ms/step - loss: 3.1274\n",
      "Epoch 74/80\n",
      "\n",
      "Epoch 00074: LearningRateScheduler setting learning rate to 1e-06.\n",
      "1000/1000 [==============================] - 538s 538ms/step - loss: 3.1229\n",
      "Epoch 75/80\n",
      "\n",
      "Epoch 00075: LearningRateScheduler setting learning rate to 1e-06.\n",
      "1000/1000 [==============================] - 535s 535ms/step - loss: 3.1298\n",
      "Epoch 76/80\n",
      "\n",
      "Epoch 00076: LearningRateScheduler setting learning rate to 1e-06.\n",
      "1000/1000 [==============================] - 532s 532ms/step - loss: 3.1170\n",
      "Epoch 77/80\n",
      "\n",
      "Epoch 00077: LearningRateScheduler setting learning rate to 1e-06.\n",
      "1000/1000 [==============================] - 534s 534ms/step - loss: 3.1203\n",
      "Epoch 78/80\n",
      "\n",
      "Epoch 00078: LearningRateScheduler setting learning rate to 1e-06.\n",
      "1000/1000 [==============================] - 533s 533ms/step - loss: 3.1344\n",
      "Epoch 79/80\n",
      "\n",
      "Epoch 00079: LearningRateScheduler setting learning rate to 1e-06.\n",
      "1000/1000 [==============================] - 534s 534ms/step - loss: 3.1316\n",
      "Epoch 80/80\n",
      "\n",
      "Epoch 00080: LearningRateScheduler setting learning rate to 1e-06.\n",
      "1000/1000 [==============================] - 533s 533ms/step - loss: 3.1134\n",
      "TRAINING MODEL WITH ALPHA: 0.6\n",
      "Epoch 1/80\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 531s 531ms/step - loss: 6.7617\n",
      "Epoch 2/80\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 528s 528ms/step - loss: 5.1454\n",
      "Epoch 3/80\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 530s 530ms/step - loss: 4.9546\n",
      "Epoch 4/80\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 531s 531ms/step - loss: 4.8300\n",
      "Epoch 5/80\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 531s 531ms/step - loss: 4.7464\n",
      "Epoch 6/80\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 4.6391\n",
      "Epoch 7/80\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 525s 525ms/step - loss: 4.5816\n",
      "Epoch 8/80\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 528s 528ms/step - loss: 4.4922\n",
      "Epoch 9/80\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 530s 530ms/step - loss: 4.4351\n",
      "Epoch 10/80\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 4.3850\n",
      "Epoch 11/80\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 530s 530ms/step - loss: 4.3253\n",
      "Epoch 12/80\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 4.2892\n",
      "Epoch 13/80\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 4.2484\n",
      "Epoch 14/80\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 4.2199\n",
      "Epoch 15/80\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 4.1714\n",
      "Epoch 16/80\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 527s 527ms/step - loss: 4.1275\n",
      "Epoch 17/80\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 527s 527ms/step - loss: 4.1026\n",
      "Epoch 18/80\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 4.0717\n",
      "Epoch 19/80\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 528s 528ms/step - loss: 4.0566\n",
      "Epoch 20/80\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 530s 530ms/step - loss: 4.0323\n",
      "Epoch 21/80\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 530s 530ms/step - loss: 3.9921\n",
      "Epoch 22/80\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 528s 528ms/step - loss: 3.9756\n",
      "Epoch 23/80\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 534s 534ms/step - loss: 3.9807\n",
      "Epoch 24/80\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 530s 530ms/step - loss: 3.9225\n",
      "Epoch 25/80\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 527s 527ms/step - loss: 3.9086\n",
      "Epoch 26/80\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 526s 526ms/step - loss: 3.8898\n",
      "Epoch 27/80\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 528s 528ms/step - loss: 3.8886\n",
      "Epoch 28/80\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 530s 530ms/step - loss: 3.8881\n",
      "Epoch 29/80\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 530s 530ms/step - loss: 3.8446\n",
      "Epoch 30/80\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 528s 528ms/step - loss: 3.8301\n",
      "Epoch 31/80\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 3.8095\n",
      "Epoch 32/80\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 528s 528ms/step - loss: 3.7972\n",
      "Epoch 33/80\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 528s 528ms/step - loss: 3.7650\n",
      "Epoch 34/80\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 528s 528ms/step - loss: 3.7589\n",
      "Epoch 35/80\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 528s 528ms/step - loss: 3.7468\n",
      "Epoch 36/80\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 526s 526ms/step - loss: 3.7343\n",
      "Epoch 37/80\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 533s 533ms/step - loss: 3.7145\n",
      "Epoch 38/80\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 526s 526ms/step - loss: 3.7054\n",
      "Epoch 39/80\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 3.6922\n",
      "Epoch 40/80\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 528s 528ms/step - loss: 3.6790\n",
      "Epoch 41/80\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 3.6643\n",
      "Epoch 42/80\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 531s 531ms/step - loss: 3.6649\n",
      "Epoch 43/80\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 527s 527ms/step - loss: 3.6421\n",
      "Epoch 44/80\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 3.6357\n",
      "Epoch 45/80\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 3.6288\n",
      "Epoch 46/80\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 532s 532ms/step - loss: 3.6153\n",
      "Epoch 47/80\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 527s 527ms/step - loss: 3.6078\n",
      "Epoch 48/80\n",
      "\n",
      "Epoch 00048: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 532s 532ms/step - loss: 3.5774\n",
      "Epoch 49/80\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 527s 527ms/step - loss: 3.5773\n",
      "Epoch 50/80\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 527s 527ms/step - loss: 3.5586\n",
      "Epoch 51/80\n",
      "\n",
      "Epoch 00051: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 530s 530ms/step - loss: 3.5686\n",
      "Epoch 52/80\n",
      "\n",
      "Epoch 00052: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 527s 527ms/step - loss: 3.5464\n",
      "Epoch 53/80\n",
      "\n",
      "Epoch 00053: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 530s 530ms/step - loss: 3.5297\n",
      "Epoch 54/80\n",
      "\n",
      "Epoch 00054: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 530s 530ms/step - loss: 3.5145\n",
      "Epoch 55/80\n",
      "\n",
      "Epoch 00055: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 530s 530ms/step - loss: 3.5336\n",
      "Epoch 56/80\n",
      "\n",
      "Epoch 00056: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 528s 528ms/step - loss: 3.5056\n",
      "Epoch 57/80\n",
      "\n",
      "Epoch 00057: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 526s 526ms/step - loss: 3.4748\n",
      "Epoch 58/80\n",
      "\n",
      "Epoch 00058: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 528s 528ms/step - loss: 3.4849\n",
      "Epoch 59/80\n",
      "\n",
      "Epoch 00059: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 526s 526ms/step - loss: 3.4798\n",
      "Epoch 60/80\n",
      "\n",
      "Epoch 00060: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 530s 530ms/step - loss: 3.4809\n",
      "Epoch 61/80\n",
      "\n",
      "Epoch 00061: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 528s 528ms/step - loss: 3.4097\n",
      "Epoch 62/80\n",
      "\n",
      "Epoch 00062: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 527s 527ms/step - loss: 3.4025\n",
      "Epoch 63/80\n",
      "\n",
      "Epoch 00063: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 527s 527ms/step - loss: 3.3763\n",
      "Epoch 64/80\n",
      "\n",
      "Epoch 00064: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 527s 527ms/step - loss: 3.3617\n",
      "Epoch 65/80\n",
      "\n",
      "Epoch 00065: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 527s 527ms/step - loss: 3.3680\n",
      "Epoch 66/80\n",
      "\n",
      "Epoch 00066: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 526s 526ms/step - loss: 3.3651\n",
      "Epoch 67/80\n",
      "\n",
      "Epoch 00067: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 3.3702\n",
      "Epoch 68/80\n",
      "\n",
      "Epoch 00068: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 531s 531ms/step - loss: 3.3688\n",
      "Epoch 69/80\n",
      "\n",
      "Epoch 00069: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 3.3594\n",
      "Epoch 70/80\n",
      "\n",
      "Epoch 00070: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 527s 527ms/step - loss: 3.3556\n",
      "Epoch 71/80\n",
      "\n",
      "Epoch 00071: LearningRateScheduler setting learning rate to 1e-06.\n",
      "1000/1000 [==============================] - 527s 527ms/step - loss: 3.3400\n",
      "Epoch 72/80\n",
      "\n",
      "Epoch 00072: LearningRateScheduler setting learning rate to 1e-06.\n",
      "1000/1000 [==============================] - 530s 530ms/step - loss: 3.3537\n",
      "Epoch 73/80\n",
      "\n",
      "Epoch 00073: LearningRateScheduler setting learning rate to 1e-06.\n",
      "1000/1000 [==============================] - 531s 531ms/step - loss: 3.3592\n",
      "Epoch 74/80\n",
      "\n",
      "Epoch 00074: LearningRateScheduler setting learning rate to 1e-06.\n",
      "1000/1000 [==============================] - 531s 531ms/step - loss: 3.3523\n",
      "Epoch 75/80\n",
      "\n",
      "Epoch 00075: LearningRateScheduler setting learning rate to 1e-06.\n",
      "1000/1000 [==============================] - 527s 527ms/step - loss: 3.3334\n",
      "Epoch 76/80\n",
      "\n",
      "Epoch 00076: LearningRateScheduler setting learning rate to 1e-06.\n",
      "1000/1000 [==============================] - 530s 530ms/step - loss: 3.3659\n",
      "Epoch 77/80\n",
      "\n",
      "Epoch 00077: LearningRateScheduler setting learning rate to 1e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 525s 525ms/step - loss: 3.3553\n",
      "Epoch 78/80\n",
      "\n",
      "Epoch 00078: LearningRateScheduler setting learning rate to 1e-06.\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 3.3528\n",
      "Epoch 79/80\n",
      "\n",
      "Epoch 00079: LearningRateScheduler setting learning rate to 1e-06.\n",
      "1000/1000 [==============================] - 527s 527ms/step - loss: 3.3371\n",
      "Epoch 80/80\n",
      "\n",
      "Epoch 00080: LearningRateScheduler setting learning rate to 1e-06.\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 3.3401\n",
      "TRAINING MODEL WITH ALPHA: 0.25\n",
      "Epoch 1/80\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 532s 532ms/step - loss: 7.0223\n",
      "Epoch 2/80\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 527s 527ms/step - loss: 5.5081\n",
      "Epoch 3/80\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 525s 525ms/step - loss: 5.1324\n",
      "Epoch 4/80\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 526s 526ms/step - loss: 5.0073\n",
      "Epoch 5/80\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 527s 527ms/step - loss: 4.9313\n",
      "Epoch 6/80\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 528s 528ms/step - loss: 4.8778\n",
      "Epoch 7/80\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 530s 530ms/step - loss: 4.8314\n",
      "Epoch 8/80\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 525s 525ms/step - loss: 4.7937\n",
      "Epoch 9/80\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 528s 528ms/step - loss: 4.7470\n",
      "Epoch 10/80\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 528s 528ms/step - loss: 4.7106\n",
      "Epoch 11/80\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 525s 525ms/step - loss: 4.6800\n",
      "Epoch 12/80\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 528s 528ms/step - loss: 4.6295\n",
      "Epoch 13/80\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 533s 533ms/step - loss: 4.6056\n",
      "Epoch 14/80\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 525s 525ms/step - loss: 4.5746\n",
      "Epoch 15/80\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 526s 526ms/step - loss: 4.5450\n",
      "Epoch 16/80\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 4.5122\n",
      "Epoch 17/80\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 530s 530ms/step - loss: 4.4975\n",
      "Epoch 18/80\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 530s 530ms/step - loss: 4.4574\n",
      "Epoch 19/80\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 531s 531ms/step - loss: 4.4481\n",
      "Epoch 20/80\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 526s 526ms/step - loss: 4.3967\n",
      "Epoch 21/80\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 4.3755\n",
      "Epoch 22/80\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 527s 527ms/step - loss: 4.3609\n",
      "Epoch 23/80\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 526s 526ms/step - loss: 4.3496\n",
      "Epoch 24/80\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 544s 544ms/step - loss: 4.3272\n",
      "Epoch 25/80\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 539s 539ms/step - loss: 4.3044\n",
      "Epoch 26/80\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 538s 538ms/step - loss: 4.2657\n",
      "Epoch 27/80\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 538s 538ms/step - loss: 4.2563\n",
      "Epoch 28/80\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 535s 535ms/step - loss: 4.2473\n",
      "Epoch 29/80\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 532s 532ms/step - loss: 4.2163\n",
      "Epoch 30/80\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 534s 534ms/step - loss: 4.2118\n",
      "Epoch 31/80\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 530s 530ms/step - loss: 4.1909\n",
      "Epoch 32/80\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 534s 534ms/step - loss: 4.1818\n",
      "Epoch 33/80\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 535s 535ms/step - loss: 4.1629\n",
      "Epoch 34/80\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 535s 535ms/step - loss: 4.1510\n",
      "Epoch 35/80\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 538s 538ms/step - loss: 4.1399\n",
      "Epoch 36/80\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 537s 537ms/step - loss: 4.1405\n",
      "Epoch 37/80\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 533s 533ms/step - loss: 4.1324\n",
      "Epoch 38/80\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 531s 531ms/step - loss: 4.0873\n",
      "Epoch 39/80\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 532s 532ms/step - loss: 4.1106\n",
      "Epoch 40/80\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 535s 535ms/step - loss: 4.0821\n",
      "Epoch 41/80\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 531s 531ms/step - loss: 4.0677\n",
      "Epoch 42/80\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 535s 535ms/step - loss: 4.0700\n",
      "Epoch 43/80\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 534s 534ms/step - loss: 4.0442\n",
      "Epoch 44/80\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 531s 531ms/step - loss: 4.0401\n",
      "Epoch 45/80\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 528s 528ms/step - loss: 4.0375\n",
      "Epoch 46/80\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 526s 526ms/step - loss: 4.0206\n",
      "Epoch 47/80\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 4.0166\n",
      "Epoch 48/80\n",
      "\n",
      "Epoch 00048: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 531s 531ms/step - loss: 4.0040\n",
      "Epoch 49/80\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 527s 527ms/step - loss: 3.9984\n",
      "Epoch 50/80\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 528s 528ms/step - loss: 3.9959\n",
      "Epoch 51/80\n",
      "\n",
      "Epoch 00051: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 526s 526ms/step - loss: 3.9842\n",
      "Epoch 52/80\n",
      "\n",
      "Epoch 00052: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 527s 527ms/step - loss: 3.9839\n",
      "Epoch 53/80\n",
      "\n",
      "Epoch 00053: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 3.9631\n",
      "Epoch 54/80\n",
      "\n",
      "Epoch 00054: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 526s 526ms/step - loss: 3.9651\n",
      "Epoch 55/80\n",
      "\n",
      "Epoch 00055: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 528s 528ms/step - loss: 3.9509\n",
      "Epoch 56/80\n",
      "\n",
      "Epoch 00056: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 528s 528ms/step - loss: 3.9384\n",
      "Epoch 57/80\n",
      "\n",
      "Epoch 00057: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 527s 527ms/step - loss: 3.9417\n",
      "Epoch 58/80\n",
      "\n",
      "Epoch 00058: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 530s 530ms/step - loss: 3.9384\n",
      "Epoch 59/80\n",
      "\n",
      "Epoch 00059: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 526s 526ms/step - loss: 3.9151\n",
      "Epoch 60/80\n",
      "\n",
      "Epoch 00060: LearningRateScheduler setting learning rate to 0.0001.\n",
      "1000/1000 [==============================] - 526s 526ms/step - loss: 3.9241\n",
      "Epoch 61/80\n",
      "\n",
      "Epoch 00061: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 538s 538ms/step - loss: 3.8944\n",
      "Epoch 62/80\n",
      "\n",
      "Epoch 00062: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 527s 527ms/step - loss: 3.8651\n",
      "Epoch 63/80\n",
      "\n",
      "Epoch 00063: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 527s 527ms/step - loss: 3.8603\n",
      "Epoch 64/80\n",
      "\n",
      "Epoch 00064: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 3.8729\n",
      "Epoch 65/80\n",
      "\n",
      "Epoch 00065: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 530s 530ms/step - loss: 3.8735\n",
      "Epoch 66/80\n",
      "\n",
      "Epoch 00066: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 528s 528ms/step - loss: 3.8611\n",
      "Epoch 67/80\n",
      "\n",
      "Epoch 00067: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 526s 526ms/step - loss: 3.8680\n",
      "Epoch 68/80\n",
      "\n",
      "Epoch 00068: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 531s 531ms/step - loss: 3.8567\n",
      "Epoch 69/80\n",
      "\n",
      "Epoch 00069: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 526s 526ms/step - loss: 3.8480\n",
      "Epoch 70/80\n",
      "\n",
      "Epoch 00070: LearningRateScheduler setting learning rate to 1e-05.\n",
      "1000/1000 [==============================] - 527s 527ms/step - loss: 3.8507\n",
      "Epoch 71/80\n",
      "\n",
      "Epoch 00071: LearningRateScheduler setting learning rate to 1e-06.\n",
      "1000/1000 [==============================] - 530s 530ms/step - loss: 3.8567\n",
      "Epoch 72/80\n",
      "\n",
      "Epoch 00072: LearningRateScheduler setting learning rate to 1e-06.\n",
      "1000/1000 [==============================] - 531s 531ms/step - loss: 3.8603\n",
      "Epoch 73/80\n",
      "\n",
      "Epoch 00073: LearningRateScheduler setting learning rate to 1e-06.\n",
      "1000/1000 [==============================] - 527s 527ms/step - loss: 3.8401\n",
      "Epoch 74/80\n",
      "\n",
      "Epoch 00074: LearningRateScheduler setting learning rate to 1e-06.\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 3.8487\n",
      "Epoch 75/80\n",
      "\n",
      "Epoch 00075: LearningRateScheduler setting learning rate to 1e-06.\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 3.8608\n",
      "Epoch 76/80\n",
      "\n",
      "Epoch 00076: LearningRateScheduler setting learning rate to 1e-06.\n",
      "1000/1000 [==============================] - 527s 527ms/step - loss: 3.8366\n",
      "Epoch 77/80\n",
      "\n",
      "Epoch 00077: LearningRateScheduler setting learning rate to 1e-06.\n",
      "1000/1000 [==============================] - 526s 526ms/step - loss: 3.8351\n",
      "Epoch 78/80\n",
      "\n",
      "Epoch 00078: LearningRateScheduler setting learning rate to 1e-06.\n",
      "1000/1000 [==============================] - 528s 528ms/step - loss: 3.8425\n",
      "Epoch 79/80\n",
      "\n",
      "Epoch 00079: LearningRateScheduler setting learning rate to 1e-06.\n",
      "1000/1000 [==============================] - 529s 529ms/step - loss: 3.8365\n",
      "Epoch 80/80\n",
      "\n",
      "Epoch 00080: LearningRateScheduler setting learning rate to 1e-06.\n",
      "1000/1000 [==============================] - 533s 533ms/step - loss: 3.8506\n"
     ]
    }
   ],
   "source": [
    "alphas = [1.0, 0.6, 0.25]\n",
    "\n",
    "for alpha in alphas:\n",
    "    # 1: Build the Keras model.\n",
    "    K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "    print('TRAINING MODEL WITH ALPHA:', alpha)\n",
    "    \n",
    "    model = ssd_300(image_size=(img_height, img_width, img_channels),\n",
    "                n_classes=n_classes,\n",
    "                mode='training',\n",
    "                alpha=alpha,\n",
    "                scales=scales,\n",
    "                aspect_ratios_per_layer=aspect_ratios,\n",
    "                two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                steps=steps,\n",
    "                offsets=offsets,\n",
    "                clip_boxes=clip_boxes,\n",
    "                variances=variances,\n",
    "                normalize_coords=normalize_coords,\n",
    "                subtract_mean=mean_color,\n",
    "                divide_by_stddev=divide_by_stddev,\n",
    "                swap_channels=swap_channels)\n",
    "\n",
    "    adam = Adam(lr=0.001)\n",
    "    ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "    model.compile(optimizer=adam, loss=ssd_loss.compute_loss)\n",
    "    \n",
    "    # Define model callbacks.\n",
    "    main_path = '/home/aldo/Documents/'\n",
    "    # TODO: Set the filepath under which you want to save the model.\n",
    "\n",
    "    csv_logger = CSVLogger(filename=main_path + 'data-cic/history/light_models/PASCAL/mobilenet_v2_alpha_' + str(alpha) + '.csv',\n",
    "                           separator=',',\n",
    "                           append=True)\n",
    "\n",
    "    learning_rate_scheduler = LearningRateScheduler(schedule=lr_schedule, verbose=1)\n",
    "\n",
    "\n",
    "    callbacks = [csv_logger,\n",
    "                 learning_rate_scheduler]\n",
    "    \n",
    "    initial_epoch   = 0\n",
    "    final_epoch     = 80\n",
    "    steps_per_epoch = 1000\n",
    "\n",
    "    history = model.fit_generator(generator=train_generator,\n",
    "                                  steps_per_epoch=steps_per_epoch,\n",
    "                                  epochs=final_epoch,\n",
    "                                  callbacks=callbacks,\n",
    "                                  initial_epoch=initial_epoch)\n",
    "    \n",
    "    model.save(main_path + 'weights/light_models/PASCAL/mobilenet_v2_alpha_' + str(alpha) + '.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test2]",
   "language": "python",
   "name": "conda-env-test2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
